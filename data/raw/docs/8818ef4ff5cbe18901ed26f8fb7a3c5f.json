{
  "doc_id": "8818ef4ff5cbe18901ed26f8fb7a3c5f",
  "source": "pytorch_docs",
  "title": "torch.compile Troubleshooting \u2014 PyTorch 2.9 documentation",
  "text": "\n## torch.compile Troubleshooting#\n\nCreated On: Nov 28, 2022 | Last Updated On: Aug 14, 2025\nYou\u2019re trying to usetorch.compileon your PyTorch model to enhance its performance\nbut it\u2019s not working as expected. Perhaps performance isn\u2019t improving, crashes are happening, or compilation time is too long. This article provides tips, workarounds, and debugging tools to help you overcome these challenges.\ntorch.compile\nContents\nSetting Expectations\nCompile times\nTerminology\nGraph break\nGuards\nRecompilation\nDynamic Shapes\nLogging Tools\ntlparse / TORCH_TRACE\nTORCH_LOGS\ntlparse vs. TORCH_LOGS\nSimple Workarounds\nWhere to apply torch.compile?\nDisabling and Suppressing Errors\nResolving graph breaks\nData-dependent operations\nCustom ops\nPrinting\nIncorrect code\nDealing with recompilations\nIs dynamic shapes enabled?\nChanging the cache size limit\nWrapping constants with tensors\nReporting Issues\nAblation\nBisecting\nCreating a reproducer\nMinifier\nDebugging Deeper\nTorchDynamo\nLogging what Dynamo is tracing\nBreakpointing Dynamo tracing\nBytecode generation errors\nAOTAutograd\nSummary of TORCH_LOGS options\nRelated Articles\n\n## Setting Expectations#\n\ntorch.compileis designed as a general-purpose PyTorch compiler.\nUnlike the previous compiler solution, TorchScript,torch.compilerequires fewer code changes, meaning models typically don\u2019t need to be rewritten from scratch.\nIt also manages unsupported code more gracefully - unsupported code results in a lost optimization opportunity rather than a crash.\ntorch.compile\ntorch.compile\nIn the ideal world, one can simply applytorch.compileto any PyTorch model and enjoy automatic speedups.\nHowever, in reality, code complexities can lead to one of three scenarios:\ntorch.compile\ntorch.compileworks seamlessly, providing speedups.\ntorch.compile\nSome code modifications are necessary.torch.compiledoesn\u2019t crash or take too long,\nbut you might not be seeing significant performance gains.\ntorch.compile\nExtensive changes to your code are required.\nWe anticipate most code will fall under scenarios (1) and (2).\nThis document provides tips, arranged by level of involvement, to help address code issues in scenario (2).\n\n## Compile times#\n\ntorch.compilefunctions as a just-in-time compiler, so the initial one or two runs\nof the compiled function are expected to be significantly slower. Recompilations, which can occur under certain conditions (detailed below),\nwill also make runs slower. Varioustorch.compilecomponents cache results to\nreduce compilation time for future invocations, even in different processes.\nCold-start (uncached) compilation time typically ranges from seconds to minutes for common or benchmarked models.\nLarger models may take upwards of 30 minutes to a few hours.\ntorch.compile\ntorch.compile\n\n## Terminology#\n\nThe following terms are relevant to troubleshootingtorch.compileproblems.\ntorch.compile\n\n## Graph break#\n\ntorch.compiletraces your code and attempts to capture your PyTorch code into a\nsingle computation graph of PyTorch operators (FX graph). However, this is not always possible.\nWhen encountering code that can\u2019t be traced, a \u201cgraph break\u201d occurs.\nA graph break involves compiling the FX graph has been determined so far, running the unsupported code,\nthen resuming tracing after the unsupported code with a new FX graph.\nBecause the computation graph is broken up, we lose optimization opportunities,\nso model code should avoid graph breaks whenever possible.\nGraph breaks occur on things like:\ntorch.compile\nData-dependent if-statements\nMany Python built-in functions\nC functions\nBelow is an example of a graph break due to the functioncopy.deepcopyfrom a Python builtin library\n(exact output may differ).\ncopy.deepcopy\n\n```python\nimport torch\n\n@torch.compile\ndef fn(x):\n    x = x + 1\n    with open(\"test.txt\", \"r\") as f:\n        return x + len(f.read())\n\nfn(torch.ones(3, 3))\n\n```\n\n\n```python\n$TORCH_LOGS=\"graph_breaks\" python playground.py\nGraph break in user code at /data/users/williamwen/pytorch/playground.py:7\nReason: Unsupported: builtin: open [<class 'torch._dynamo.variables.constant.ConstantVariable'>, <class 'torch._dynamo.variables.constant.ConstantVariable'>] False\nUser code traceback:\nFile \"/data/users/williamwen/pytorch/playground.py\", line 7, in fn\n    with open(\"test.txt\", \"r\") as f:\nTraceback (most recent call last):\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/symbolic_convert.py\", line 635, in wrapper\n    return inner_fn(self, inst)\n        ^^^^^^^^^^^^^^^^^^^^\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/symbolic_convert.py\", line 2414, in CALL\n    self._call(inst)\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/symbolic_convert.py\", line 2408, in _call\n    self.call_function(fn, args, kwargs)\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/symbolic_convert.py\", line 962, in call_function\n    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/variables/builtin.py\", line 997, in call_function\n    return handler(tx, args, kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/variables/builtin.py\", line 831, in <lambda>\n    return lambda *args: unimplemented(error_msg)\n                        ^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/exc.py\", line 313, in unimplemented\n    raise Unsupported(msg, case_name=case_name)\ntorch._dynamo.exc.Unsupported: builtin: open [<class 'torch._dynamo.variables.constant.ConstantVariable'>, <class 'torch._dynamo.variables.constant.ConstantVariable'>] False\n\n```\n\n\n## Guards#\n\ntorch.compilemakes some assumptions about runtime values as we trace through code.\nDuring tracing, we generate \u201cguards\u201d, which are runtime checks for these assumptions.\nGuards are run in future calls to the compiled function to determine if we can reuse previously compiled code.\nExamples of runtime checks are constant values, types, and object IDs.\ntorch.compile\nBelow is an example of generated guards. TheTENSOR_MATCHguard checks for the input\u2019s type, device, dtype, shape, etc.\nTENSOR_MATCH\n\n```python\nimport torch\n\n@torch.compile\ndef fn(x):\n    return x + 1\n\nfn(torch.ones(3, 3))\n\n```\n\n\n```python\n$ TORCH_LOGS=\"guards\" python playground.py\nGUARDS:\n\nTREE_GUARD_MANAGER:\n+- RootGuardManager\n| +- DEFAULT_DEVICE: utils_device.CURRENT_DEVICE == None                           # _dynamo/output_graph.py:471 in init_ambient_guards\n| +- GLOBAL_STATE: ___check_global_state()\n| +- TORCH_FUNCTION_MODE_STACK: ___check_torch_function_mode_stack()\n| +- GuardManager: source=L['x'], accessed_by=DictGetItemGuardAccessor(x)\n| | +- TENSOR_MATCH: check_tensor(L['x'], Tensor, DispatchKeySet(CPU, BackendSelect, ADInplaceOrView, AutogradCPU), torch.float32, device=None, requires_grad=False, size=[3, 3], stride=[3, 1])  # return x + 1  # playground.py:6 in fn\n| | +- NO_HASATTR: hasattr(L['x'], '_dynamo_dynamic_indices') == False           # return x + 1  # playground.py:6 in fn\n\n```\n\n\n## Recompilation#\n\nIf the guards fail for every instance of previously compiled code,\nthentorch.compilemust \u201crecompile\u201d the function, requiring the original code to be traced again.\ntorch.compile\nIn the example below, recompilation is necessary because the guard checking the tensor argument\u2019s shape failed.\n\n```python\nimport torch\n\n@torch.compile\ndef fn(x):\n    return x + 1\n\nfn(torch.ones(3, 3))\nfn(torch.ones(4, 4))\n\n```\n\n\n```python\n$ TORCH_LOGS=\"recompiles\" python playground.py\nRecompiling function fn in /data/users/williamwen/pytorch/playground.py:3\n    triggered by the following guard failure(s):\n    - 0/0: tensor 'L['x']' size mismatch at index 0. expected 3, actual 4\n\n```\n\n\n## Dynamic Shapes#\n\ntorch.compileinitially assumes tensor shapes are static/constant and guards based on these assumptions.\nBy using \u201cdynamic shapes,\u201d we can gettorch.compileto produce compiled code that can accept\ntensor inputs with different shapes - we avoid recompiling every time shapes differ.\nBy default, automatic dynamic shapes are enabledtorch.compile(dynamic=None)-\nif compilation fails due to shape mismatch, recompilation is attempted with dynamic shapes.\nDynamic shapes can also be fully enableddynamic=Trueor disableddynamic=False.\ntorch.compile\ntorch.compile\ntorch.compile(dynamic=None)\ndynamic=True\ndynamic=False\nBelow, we enable dynamic shapes and note that we no longer need to recompile.\n\n```python\nimport torch\n\n@torch.compile(dynamic=True)\ndef fn(x):\n    return x + 1\n\nfn(torch.ones(3, 3))\nfn(torch.ones(4, 4))\n\n```\n\n\n```python\n$ TORCH_LOGS=\"dynamic,recompiles\" python playground.py\ncreate_symbol s0 = 3 for L['x'].size()[0] [2, int_oo] at playground.py:5 in fn (_dynamo/variables/builder.py:2718 in <lambda>), for more info run with TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL=\"s0\"\nproduce_guards\nproduce_guards\n\n```\n\nFor more information on dynamic shapes, seeThe dynamic shapes manual.\n\n## Logging Tools#\n\n\n## tlparse / TORCH_TRACE#\n\ntlparse/TORCH_TRACEare a pair of tools that produce compilation reports that look like this:https://web.mit.edu/~ezyang/Public/bhack-20240609-tlparse/index.html.\ntlparse\nTORCH_TRACE\nTraces are very easy to collect. To collect a trace, run your reproduction command with\n\n```python\nTORCH_TRACE=\"/tmp/tracedir\" python foo.py\npip install tlparse\ntlparse /tmp/tracedir\n\n```\n\nThis approach works even if you are running a distributed job, providing a trace for each rank.\nIt will open your browser with HTML similar to what\u2019s generated above.\nIf you are making a bug report for a complicated problem that you don\u2019t have a standalone reproduction for,\nyou can still greatly assist PyTorch developers by attaching the trace log generated in/tmp/tracedir.\n/tmp/tracedir\nWarning\nThe trace log contains all of your model code.\nDo not share the trace log if the model you are working on is sensitive. The trace log does NOT contain weights.\nThe output oftlparseis primarily aimed for PyTorch developers,\nand the log format is easy to upload and share on GitHub.\nHowever,  as a non-PyTorch developer, you can still extract useful information from it.\nWe recommend starting with the inline help text in the report, which explains its contents.\nHere are some insights you can gain from atlparse:\ntlparse\ntlparse\nWhat model code was compiled by looking at the stack trie?\nThis is especially useful if you\u2019re not familiar with the codebase being compiled!\nHow many graph breaks / distinct compilation regions are there?\n(Each distinct compile is its own color coded block like[0/0]).\nFrames that are potentially graph-broken are light green[2/4].\nIf there are a lot of frames, that is suspicious, and suggests that you had some catastrophic graph breaks,\nor maybe your code isn\u2019t a good match fortorch.compile.\ntorch.compile\nHow many times did I recompile a particular frame? Something that recompiled a lot will look like:[10/0][10/1][10/2]- if something is being recompiled a lot, that is very suspicious and worth looking into, even if it isn\u2019t the root cause of your problem.\nWas there a compilation error? Frames that errored will look like[0/1].\nWhat intermediate compiler products did I generate for a given frame?\nFor example, you can look at the high-level generated FX graph or the generated Triton code.\nIs there relevant information for a particular frame? You can find these incompilation_metrics.\ncompilation_metrics\n\n## TORCH_LOGS#\n\nYou can use theTORCH_LOGSenvironment variable to selectively enable parts of thetorch.compilestack to log.TORCH_LOGSis in fact the source of logs fortlparse. The format of theTORCH_LOGSenvironment variable looks like this:\nTORCH_LOGS\ntorch.compile\nTORCH_LOGS\ntlparse\nTORCH_LOGS\n\n```python\nTORCH_LOGS=\"<option1>,<option2>,...\" python foo.py\n\n```\n\nUseful high-level options include:\ngraph_breaks: logs locations of graph breaks in user code and the reason for the graph break\ngraph_breaks\nguards: logs guards that are generated\nguards\nrecompiles: logs which function recompiled and the guards that failed, leading to the recompilation\nrecompiles\ndynamic: logs related to dynamic shapes\ndynamic\nAlso, you can programmatically set logging options usingtorch._logging.set_logs:\ntorch._logging.set_logs\n\n```python\nimport logging\ntorch._logging.set_logs(graph_breaks=True)\n...\n\n```\n\nMoreTORCH_LOGSoptions areSummary of TORCH_LOGS options.\nFor the full list of options, seetorch._loggingandtorch._logging.set_logs.\nTORCH_LOGS\n\n## tlparse vs. TORCH_LOGS#\n\nGenerally, we suggest first usingtlparsewhen encountering issues.tlparseis ideal for debugging large models and gaining a high-level overview of how your model was compiled.\nOn the other hand,TORCH_LOGSis preferred for small examples and fine-grained debugging detail,\nwhen we already have an idea of whichtorch.compilecomponent is causing the problem.\ntlparse\ntlparse\nTORCH_LOGS\ntorch.compile\n\n## Simple Workarounds#\n\nHere, we describe some workarounds totorch.compileissues involving small code modifications\nor changing sometorch.compilesettings.\ntorch.compile\ntorch.compile\n\n## Where to apply torch.compile?#\n\nWe recommend applyingtorch.compileto the highest-level function that doesn\u2019t cause excessive problems.\nTypically, it is your train or eval step with the optimizer but without the loop, your top-levelnn.Module,\nor some sub-nn.Module``s.``torch.compilespecifically doesn\u2019t handle distributed wrapper modules like\nDDP or FSDP very well, so consider applyingtorch.compileto the inner module passed to the wrapper.\ntorch.compile\nnn.Module\nnn.Module``s.``torch.compile\ntorch.compile\n\n```python\n# inference\nmodel = ...\nopt_model = torch.compile(model)\n\nfor _ in range(N_ITERS):\n    inp = ...\n    out = opt_model(inp)\n\n```\n\n\n```python\n# training\nmodel = ...\nopt = torch.optim.Adam(model.parameters())\n\n@torch.compile\ndef train(mod, data):\n    opt.zero_grad(True)\n    pred = mod(data[0])\n    loss = torch.nn.CrossEntropyLoss()(pred, data[1])\n    loss.backward()\n    opt.step()\n\nfor _ in range(N_ITERS):\n    inp = ...\n    train(model, inp)\n\n```\n\n\n```python\n# DistributedDataParallel\nmodel = ...\nopt_model = torch.compile(model)\nmodel_ddp = DistributedDataParallel(opt_model, ...)\n\nfor _ in range(N_ITERS):\n    inp = ...\n    out = model_ddp(inp)\n\n```\n\n\n## Disabling and Suppressing Errors#\n\nFor some model architectures, there are portions of the model which are particularly difficult to compile\n- either there are many graph breaks, or there are crashes. You may want to explicitly disable these\nportions of the model which are problematic so that you can applytorch.compileto the parts that work.\nYou can do this by using the@torch.compiler.disabledecorator. Whentorch.compileattempts to call a\ndisabled function, it breaks the graph and skips tracing the disabled function, resuming tracing after the call.\nBy default, all recursive calls made from a disabled function are also disabled. Use therecursive=Falseoption to allow compilation for recursive calls.\ntorch.compile\n@torch.compiler.disable\ntorch.compile\nrecursive=False\n\n```python\ndef bad1_inner(...):\n    # skipped\n\n@torch.compiler.disable\ndef bad1_outer(...):\n    # skipped\n    bad1_inner(...)\n\ndef bad2_inner(...)\n    # traced\n\n@torch.compiler.disable(recursive=False)\ndef bad2_outer(...):\n    # skipped\n    bad2_inner(...)\n\n@torch.compile\ndef fn(...):\n    # graph break\n    bad1_outer(...)\n        ...\n    # graph break\n    bad2_outer(...)\n\n```\n\nFor example, we usetorch.compiler.disableto disabletorch.compileon sparse architecture in\nrecommendation models, as the sparse arch is difficult to compile. Preprocessing and logging functions\nare other examples of functions that typically cause a lot of graph breaks and do not get value from being compiled.\ntorch.compiler.disable\ntorch.compile\nIf you are experiencing compiler crashes and you want to continue regardless, you can settorch._dynamo.config.suppress_errors=True. When the compiler crashes, we will just skip tracing\nthe function and try again later. This is not best practice - it is better to eventually manually add\ndisable annotations as necessary.\ntorch._dynamo.config.suppress_errors=True\n\n## Resolving graph breaks#\n\nTo maximize optimization opportunities, it\u2019s important to reduce the number of graph breaks.\nRecall that you can see what graph breaks are happening usingtlparseorTORCH_LOGS=\"graph_breaks\".\nIn general, graph breaks are caused by one of the following:\ntlparse\nTORCH_LOGS=\"graph_breaks\"\nYou\u2019re trying to do something that fundamentally cannot be traced, such as data-dependent control flow.\nYou\u2019re trying to do something not yet supported. .\nFor example, we currently have limited support for tracing code that uses the built-in Pythoninspectmodule.\ninspect\nYour code has an error in it. For example, you may have tried calling a function with an incorrect number of arguments.\nGraph break logs will tell you the user code location and reason for the graph break.\nUnfortunately, many graph breaks are not actionable without a deeper understanding of Dynamo.\nIt can even be challenging to determine which of the three causes was the true cause of your graph break.\nWe are working on making graph break messages more actionable.\nAdditionally, the impact of lost optimization opportunities differs between graph breaks.\nFor example, graph breaks that happen in the middle of your model\u2019sforwardare likely to have a more negatie impact than\ngraph breaks in a preprocessing part at the beginning of theforward. So it is not crucial to preventevery singlebreak, but rather to prevent the ones that cause significant performance hits.\nforward\nforward\nIf a graph break message doesn\u2019t suggest any action, you suspect that the cause of your graph break is (2),\nand you believe that the graph break is causing performance hits,\nthen please report the graph break as an issue. If a function has many graph breaks,\nconsider disabling compilation on that function, as the overhead cost for the graph breaks may become prohibitive.\nBelow are some common graph breaks and some workarounds.\ntorch.compilegraph breaks on data-dependent operations such as data-dependent control flow\n(if-statements, loops with tensors) and direct tensor data accesses (.item,.data_ptr).\ntorch.compile\n.item\n.data_ptr\n\n```python\nimport torch\n\n@torch.compile\ndef fn(x):\n    y = x.sum()\n    if y > 0:\n        return x + y.item()\n    return x - y.item()\n\nfn(torch.ones(3, 3))\n\n```\n\n\n```python\n$ TORCH_LOGS=\"graph_breaks\" python playground.py\nGraph break in user code at /data/users/williamwen/pytorch/playground.py:6\nReason: Data-dependent jump\nUser code traceback:\nFile \"/data/users/williamwen/pytorch/playground.py\", line 6, in fn\n    if y > 0:\n\nGraph break in user code at /data/users/williamwen/pytorch/playground.py:7\nReason: Unsupported: Tensor.item\nUser code traceback:\nFile \"/data/users/williamwen/pytorch/playground.py\", line 7, in torch_dynamo_resume_in_fn_at_6\n    return x + y.item()\nTraceback (most recent call last):\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/symbolic_convert.py\", line 616, in wrapper\n    return inner_fn(self, inst)\n        ^^^^^^^^^^^^^^^^^^^^\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/symbolic_convert.py\", line 2288, in CALL\n    self._call(inst)\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/symbolic_convert.py\", line 2282, in _call\n    self.call_function(fn, args, kwargs)\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/symbolic_convert.py\", line 838, in call_function\n    self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/variables/misc.py\", line 1038, in call_function\n    return self.obj.call_method(tx, self.name, args, kwargs)\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/variables/tensor.py\", line 527, in call_method\n    result = handler_method(*args, **kwargs)\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/variables/tensor.py\", line 773, in method_item\n    unimplemented(\"Tensor.item\")\nFile \"/data/users/williamwen/pytorch/torch/_dynamo/exc.py\", line 304, in unimplemented\n    raise Unsupported(msg, case_name=case_name)\ntorch._dynamo.exc.Unsupported: Tensor.item\n\n```\n\nThe general workaround for these graph breaks is to avoid doing data-dependent operations. Some specific workarounds are:\nIf your control flow doesn\u2019t actually depend on data values, consider modifying your code to perform control flow on constants.\n\n```python\n# old\nx = torch.randn(3, 3)\n@torch.compile\ndef fn(y):\n    if x.sum() > 0:\n        return y + x\n    else:\n        return y - x\n\n# new\nx = torch.randn(3, 3)\ncond = (x.sum() > 0).item()\n@torch.compile\ndef fn(y):\n    if cond:\n        return y + x\n    else:\n        return y - x\n\n```\n\nUse higher-order ops liketorch.cond(https://pytorch.org/docs/main/cond.html) in place of data-dependent control flow\ntorch.cond\n\n```python\n# old\n@torch.compile\ndef fn(x):\n    if x.sum() > 0:\n        return x + 1\n    return x - 1\n\n# new\n@torch.compile\ndef fn(x):\n    return torch.cond(\n        x.sum() > 0,\n        lambda x: x + 1,\n        lambda x: x - 1,\n        (x,),\n    )\n\n```\n\nIf you have a.item()call, trytorch._dynamo.config.capture_scalar_outputs=TrueorTORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1\n.item()\ntorch._dynamo.config.capture_scalar_outputs=True\nTORCHDYNAMO_CAPTURE_SCALAR_OUTPUTS=1\nWrap problematic parts of the function in a custom op\nIf you have code thattorch.compilehas trouble tracing through, either due to missing support or fundamental incompatibility,\nyou can consider wrapping the problematic code in a custom op.\ntorch.compile\nCustom ops require a little bit of additional work to get them to be compatible withtorch.compile.\nSeehttps://pytorch.org/tutorials/advanced/custom_ops_landing_page.htmlfor more details.\ntorch.compile\nPrinting/logging/issuing warnings will result in a graph break. If you have a function that makes many logging calls,\nfor example, a function that logs data about a training iteration, consider applyingtorch.compiler.disableon it.\ntorch.compiler.disable\nAlternatively, you can try usingtorch._dynamo.config.reorderable_logging_functions.\nThis config is used to reorder logging functions so that they are called at the end of the traced function,\nthus avoiding a graph break. However, the logged contents may differ if, for example, a mutation occurs.\ntorch._dynamo.config.reorderable_logging_functions\n\n```python\nimport torch\n\ntorch._dynamo.config.reorderable_logging_functions.add(print)\n\n@torch.compile\ndef fn(x):\n    x += 1\n    print(\"log!\")\n    return torch.sin(x)\n\nfn(torch.ones(3, 3))\n\n```\n\n\n```python\n$ TORCH_LOGS=\"graph_breaks\" python playground.py\nlog!\n\n```\n\nYour code may be wrong, or is otherwise encountering an error from outsidetorch.compile.\nIn the code below, we made a typo in thetorch.sincall by providing an extra argument.\ntorch.compile\ntorch.sin\n\n```python\nimport torch\n\n@torch.compile\ndef fn(x):\n    y = torch.sin(x, x)\n    return y\n\nfn(torch.ones(3, 3))\n\n```\n\n\n```python\n$ TORCH_LOGS=\"graph_breaks\" python playground.py\nGraph break in user code at /data/users/williamwen/pytorch/playground.py:5\nReason: Unsupported: TypeError <built-in method sin of type object at 0x7fd6fd764600>: sin() takes 1 positional argument but 2 were given\nUser code traceback:\nFile \"/data/users/williamwen/pytorch/playground.py\", line 5, in fn\n    y = torch.sin(x, x)\n...\n\n```\n\nIt can be difficult to tell from the logs if the error is caused by your code or because of atorch.compilebug.\nIn order to differentiate, we recommend trying to run your code withouttorch.compileto see if you still get the error.\ntorch.compile\ntorch.compile\n\n## Dealing with recompilations#\n\nYou can view recompilations and their reasons usingtlparseorTORCH_LOGS=recompiles.\ntlparse\nTORCH_LOGS=recompiles\nRecompilations due to mismatched shapes are in the form:\n\n```python\ntensor 'L['x']' size mismatch at index 0. expected 3, actual 4\n\n```\n\nMake sure that thedynamicoption oftorch.compileis not set toFalse.\nThe default option,dynamic=None, will only attempt dynamic shapes after the first compilation.\nYou can setdynamic=Trueto upfront compile as dynamic as possible.\ndynamic\ntorch.compile\nFalse\ndynamic=None\ndynamic=True\nFor more information on dynamic shapes, seeThe dynamic shapes manual.\nThere is a limit to how many times a function can be recompiled, determined bytorch._dynamo.config.recompile_limitandtorch._dynamo.config.accumulated_recompile_limit.\nIf either limit is exceeded, then we will not attempt to compile the function again and instead will run the function eagerly.torch.compilewill also issue a warning containing the affected function and which limit was hit.\nIn the example below, each function call results in a recompile attempt.\nWhen we hit the cache size limit (8), we stop attempting to recompile.\ntorch._dynamo.config.recompile_limit\ntorch._dynamo.config.accumulated_recompile_limit\ntorch.compile\n\n```python\nimport torch\n\n@torch.compile(dynamic=False)\ndef fn(x):\n    return x + 1\n\nfor i in range(1, 10):\n    fn(torch.ones(i))\n\n```\n\n\n```python\n$ python playground.py\ntorch._dynamo hit config.recompile_limit (8)\n    function: 'fn' (/data/users/williamwen/pytorch/playground.py:5)\n    last reason: 0/0: tensor 'L['x']' size mismatch at index 0. expected 1, actual 9\n\n```\n\nIf you know that the number of recompilations has a reasonable constant upper bound, you can raise the cache size limit.\nIf the cost of recompilation outweighs the benefit of compilation, then you can consider lowering the cache size limit.\nBy default,int/floatvariables are treated as constants and are guarded as such.\nIn the below example, we have a recompilation for each function call.\nint\nfloat\n\n```python\nimport torch\n\n@torch.compile\ndef fn(x, c):\n    return x + c\n\nfor i in range(1, 10):\n    fn(torch.ones(i), 0.5 + i)\n\n```\n\n\n```python\n$ TORCH_LOGS=\"recompiles\" python playground.py\nRecompiling function fn in /data/users/williamwen/pytorch/playground.py:3\n    triggered by the following guard failure(s):\n    - 0/7: L['c'] == 8.5\n    - 0/6: L['c'] == 7.5\n    - 0/5: L['c'] == 6.5\n    - 0/4: L['c'] == 5.5\n    - 0/3: L['c'] == 4.5\n    - 0/2: L['c'] == 3.5\n    - 0/1: L['c'] == 2.5\n    - 0/0: L['c'] == 1.5\ntorch._dynamo hit config.recompile_limit (8)\n    function: 'fn' (/data/users/williamwen/pytorch/playground.py:3)\n    last reason: 0/0: L['c'] == 1.5\n\n```\n\nIn particular, for LR schedulers, initializing with a constant can lead to recompilations:\n\n```python\nimport torch\n\nmod = torch.nn.Linear(3, 3)\nopt = torch.optim.Adam(mod.parameters(), lr=0.01)\nsched = torch.optim.lr_scheduler.ExponentialLR(opt, 0.9)\n\n@torch.compile\ndef fn(inp):\n    opt.zero_grad(True)\n    out = mod(inp).sum()\n    out.backward()\n    opt.step()\n    sched.step()\n\nfor i in range(1, 10):\n    fn(torch.ones(3, 3))\n\n```\n\n\n```python\n$ TORCH_LOGS=\"recompiles\" python playground.py\nRecompiling function step in /data/users/williamwen/pytorch/torch/optim/adam.py:189\n    triggered by the following guard failure(s):\n    - 3/7: L['self'].param_groups[0]['lr'] == 0.004782969000000002\n    - 3/6: L['self'].param_groups[0]['lr'] == 0.005314410000000002\n    - 3/5: L['self'].param_groups[0]['lr'] == 0.005904900000000002\n    - 3/4: L['self'].param_groups[0]['lr'] == 0.006561000000000002\n    - 3/3: L['self'].param_groups[0]['lr'] == 0.007290000000000001\n    - 3/2: L['self'].param_groups[0]['lr'] == 0.008100000000000001\n    - 3/1: L['self'].param_groups[0]['lr'] == 0.009000000000000001\n    - 3/0: L['self'].param_groups[0]['lr'] == 0.01\ntorch._dynamo hit config.recompile_limit (8)\n    function: 'step' (/data/users/williamwen/pytorch/torch/optim/adam.py:189)\n    last reason: 3/0: L['self'].param_groups[0]['lr'] == 0.01\n\n```\n\nIn both examples, we can wrap float variables in tensors in order to prevent recompilations.\n\n```python\n# first example\nfor i in range(1, 10):\n    fn(torch.ones(i), torch.tensor(0.5 + i))\n\n# second example\nopt = torch.optim.Adam(mod.parameters(), lr=torch.tensor(0.01))\nsched = torch.optim.lr_scheduler.ExponentialLR(opt, torch.tensor(0.9))\n\n```\n\n\n## Reporting Issues#\n\nIf the workarounds provided above were not enough to gettorch.compileworking,\nthen you should consider reporting the issue to PyTorch.\nBut there are a few things that you can do to make our lives significantly easier.\ntorch.compile\n\n## Ablation#\n\nCheck which component of thetorch.compilestack is the one causing the issue using thebackend=option fortorch.compile.\nIn particular, try:\ntorch.compile\nbackend=\ntorch.compile\ntorch.compile(fn,backend=\"eager\"), which only runs TorchDynamo, the graph capture component oftorch.compile.\ntorch.compile(fn,backend=\"eager\")\ntorch.compile\ntorch.compile(fn,backend=\"aot_eager\"), which runs TorchDynamo and AOTAutograd, which additionally generates the backward graph during compilation.\ntorch.compile(fn,backend=\"aot_eager\")\ntorch.compile(fn,backend=\"aot_eager_decomp_partition\"), which runs TorchDynamo and AOTAutograd with operator decompositions/partitions.\ntorch.compile(fn,backend=\"aot_eager_decomp_partition\")\ntorch.compile(fn,backend=\"inductor\"), which runs TorchDynamo, AOTAutograd, and TorchInductor, the backend ML compiler that generates compiled kernels.\ntorch.compile(fn,backend=\"inductor\")\nIf you only fail with the Inductor backend, you can additionally test various Inductor modes:\ntorch.compile(fn,backend=\"inductor\",mode=\"default\")\ntorch.compile(fn,backend=\"inductor\",mode=\"default\")\ntorch.compile(fn,backend=\"inductor\",mode=\"reduce-overhead\")\ntorch.compile(fn,backend=\"inductor\",mode=\"reduce-overhead\")\ntorch.compile(fn,backend=\"inductor\",mode=\"max-autotune\")\ntorch.compile(fn,backend=\"inductor\",mode=\"max-autotune\")\nYou can also check if dynamic shapes is causing issues with any backend:\ntorch.compile(fn,dynamic=True)(always use dynamic shapes)\ntorch.compile(fn,dynamic=True)\ntorch.compile(fn,dynamic=False)(never use dynamic shapes)\ntorch.compile(fn,dynamic=False)\ntorch.compile(fn,dynamic=None)(automatic dynamic shapes)\ntorch.compile(fn,dynamic=None)\n\n## Bisecting#\n\nDid you try on the latest nightly? Did something work in the past but now no longer works?\nCan you bisect to determine the first nightly where your issue occurs?\nBisecting is especially helpful for performance, accuracy, or compile time regressions,\nwhere it is not immediately obvious where the problem originates from.\n\n## Creating a reproducer#\n\nCreating reproducers is a lot of work, and it is perfectly fine if you do not have the time to do it.\nHowever, if you are a motivated user unfamiliar with the internals oftorch.compile,\ncreating a standalone reproducer can have a huge impact on our ability to fix the bug.\nWithout a reproducer, your bug report must contain enough information for us to identify the root cause of the problem and write a reproducer from scratch.\ntorch.compile\nHere\u2019s a list of useful reproducers, ranked from most to least preferred:\nSelf-contained, small reproducer:A script with no external dependencies, under 100 lines of code, that reproduces the problem when run.\nSelf-contained, large reproducer:Even if it\u2019s large, being self-contained is a huge advantage!\nNon-self-contained reproducer with manageable dependencies:For example, if you can reproduce the problem by running a script afterpipinstalltransformers,\nthat\u2019s manageable. We can likely run it and investigate.\npipinstalltransformers\nNon-self-contained reproducer requiring substantial setup:This might involve downloading datasets,\nmultiple environment setup steps, or specific system library versions requiring a Docker image.\nThe more complex the setup, the harder it is for us to recreate the environment.\nNote\n\n```python\nDocker simplifies setup but complicates changes to the environment, so it's not a perfect solution, though we'll use it if necessary.\n\n```\n\nSomewhat orthogonally, a reproducer that can be run in a single process is better than a reproducer\nthat requires multiprocess training (but once again, if you only have a multiprocess reproducer, we\u2019ll take it!).\nAdditionally, below is a non-exhaustive list of aspects to check in your\nissue that you can attempt to replicate in your reproducer:\nAutograd. Did you have tensor inputs withrequires_grad=True? Did you callbackward()on the output?\nrequires_grad=True\nbackward()\nDynamic shapes. Did you setdynamic=True? Or did you run the test code multiple times with varying shapes?\ndynamic=True\nCustom operators. Is there a custom operator involved in the real workflow?\nCan you replicate some of its important characteristics using the Python custom operator API?\nConfiguration. Did you set all the same configuration?\nThis includestorch._dynamo.configandtorch._inductor.configsettings,\nas well as arguments totorch.compilelikebackend/mode.\ntorch._dynamo.config\ntorch._inductor.config\ntorch.compile\nbackend\nmode\nContext managers. Did you replicate any active context managers?\nThis could betorch.no_grad, automatic mixed precision,TorchFunctionMode/TorchDispatchMode,\nactivation checkpointing, compiled autograd etc.\ntorch.no_grad\nTorchFunctionMode\nTorchDispatchMode\nTensor subclasses. Is there a tensor subclass involved?\n\n## Minifier#\n\nThe minifier is an earlytorch.compiletool that, given an FX graph that crashes when we attempt to run or compile it,\nfinds a subgraph that also crashes and outputs the code that performs that subgraph\u2019s operations.\nEssentially, the minifier finds a minimal repro for a certain class oftorch.compile-related crashes.\nThis assumes that we were able to successfully trace through code.\ntorch.compile\ntorch.compile\nUnfortunately, most of the time nowadays, the minifier doesn\u2019t work as expected, and alternative methods may be necessary.\nThis is likely because bugs that can be automatically reproduced in this manner are generally easier to fix\nand have already been addressed, leaving more complex issues that do not reproduce easily.\nHowever, it is straightforward to attempt using the minifier, so it is worth trying even if it may not succeed.\nInstructions for operating the minifier can be foundhere.\nIf the compiler is crashing, you can setTORCHDYNAMO_REPRO_AFTER=\"dynamo\"orTORCHDYNAMO_REPRO_AFTER=\"aot\"Theaotoption is more likely to succeed, although it may not identify theAOTAutogradissues. This will generate therepro.pyfile which may help to diagnose the problem.\nFor accuracy-related issues, consider settingTORCHDYNAMO_REPRO_LEVEL=4. Please note that this may not always successfully identify the problematic subgraph.\nTORCHDYNAMO_REPRO_AFTER=\"dynamo\"\nTORCHDYNAMO_REPRO_AFTER=\"aot\"\naot\nAOTAutograd\nrepro.py\nTORCHDYNAMO_REPRO_LEVEL=4\n\n## Debugging Deeper#\n\nThis section provides tools and techniques for independently debuggingtorch.compileissues\nor for gaining a deeper understanding of thetorch.compilestack.\nThese methods are more involved than those presented above and are used by PyTorch developers regularly\nto debug realtorch.compileissues.\ntorch.compile\ntorch.compile\ntorch.compile\nBelow is a high-level overview of the stack:\n\nThe stack comprises three main components: TorchDynamo, AOTAutograd, and Inductor.\nOur debugging strategy involves first identifying the component in which the error occurs\nand then individually debugging the component. To determine the component responsible for the issue,\nsee theAblationsection underReportingIssuesabove. For guidance on debugging a specific component, consult the sections below.\nAblation\nReportingIssues\n\n## TorchDynamo#\n\nTheTORCH_LOGS=trace_bytecodeoption enables you to view the precise bytecode instructions that Dynamo is tracing,\nas well as a symbolic representation of the Python interpreter stack. When encountering a graph break or crash,\nit is advisable to inspect the last few bytecode instructions traced.\nTORCH_LOGS=trace_bytecode\nYou can also useTORCH_LOGS=trace_sourceto see which lines of source code Dynamo is tracing through.\nThis is useful in combination withtrace_bytecodeto see the line of source code each traced bytecode instruction corresponds to.\nTORCH_LOGS=trace_source\ntrace_bytecode\nFinally, you can useTORCH_LOGS=graph_codeto see the Python code representing the FX graph that Dynamo traced.\nYou can view this code to double check that the correct ops are being traced.\nTORCH_LOGS=graph_code\n\n```python\nimport torch\n\ndef g(x, y):\n    return x + y\n\n@torch.compile(backend=\"eager\")\ndef f(x):\n    x = torch.sin(x)\n    x = g(x, x)\n    return x\n\nf(torch.ones(3, 3))\n\n```\n\n\n```python\n$ TORCH_LOGS=\"trace_bytecode,trace_source,graph_code\" python playground.py\nTRACE starts_line /data/users/williamwen/pytorch/playground.py:6 in f ()\n    @torch.compile(backend=\"eager\")\nTRACE RESUME 0 []\nTRACE starts_line /data/users/williamwen/pytorch/playground.py:8 in f (f)\n        x = torch.sin(x)\nTRACE LOAD_GLOBAL torch []\nTRACE LOAD_ATTR sin [NullVariable(), PythonModuleVariable(<module 'torch' from '/data/users/williamwen/pytorch/torch/__init__.py'>)]\nTRACE LOAD_FAST x [NullVariable(), TorchInGraphFunctionVariable(<built-in method sin of type object at 0x7f00f6964600>)]\nTRACE CALL 1 [NullVariable(), TorchInGraphFunctionVariable(<built-in method sin of type object at 0x7f00f6964600>), LazyVariableTracker()]\nTRACE STORE_FAST x [TensorVariable()]\nTRACE starts_line /data/users/williamwen/pytorch/playground.py:9 in f (f)\n        x = g(x, x)\nTRACE LOAD_GLOBAL g []\nTRACE LOAD_FAST x [NullVariable(), UserFunctionVariable()]\nTRACE LOAD_FAST x [NullVariable(), UserFunctionVariable(), TensorVariable()]\nTRACE CALL 2 [NullVariable(), UserFunctionVariable(), TensorVariable(), TensorVariable()]\nTRACE starts_line /data/users/williamwen/pytorch/playground.py:3 in g (g) (inline depth: 1)\n    def g(x, y):\nTRACE RESUME 0 []\nTRACE starts_line /data/users/williamwen/pytorch/playground.py:4 in g (g) (inline depth: 1)\n        return x + y\nTRACE LOAD_FAST x []\nTRACE LOAD_FAST y [TensorVariable()]\nTRACE BINARY_OP 0 [TensorVariable(), TensorVariable()]\nTRACE RETURN_VALUE None [TensorVariable()]\nTRACE STORE_FAST x [TensorVariable()]\nTRACE starts_line /data/users/williamwen/pytorch/playground.py:10 in f (f)\n        return x\nTRACE LOAD_FAST x []\nTRACE RETURN_VALUE None [TensorVariable()]\nTRACED GRAPH\n===== __compiled_fn_1 =====\n/data/users/williamwen/pytorch/torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module):\n    def forward(self, L_x_: \"f32[3, 3][3, 1]cpu\"):\n        l_x_ = L_x_\n\n        # File: /data/users/williamwen/pytorch/playground.py:8 in f, code: x = torch.sin(x)\n        x: \"f32[3, 3][3, 1]cpu\" = torch.sin(l_x_);  l_x_ = None\n\n        # File: /data/users/williamwen/pytorch/playground.py:4 in g, code: return x + y\n        x_1: \"f32[3, 3][3, 1]cpu\" = x + x;  x = None\n        return (x_1,)\n\n```\n\nInserting a breakpoint in Dynamo/user code is helpful at times to see what the state of Dynamo is when tracing through user code.\nUnfortunately, inserting a breakpoint in the normal Python fashion will result in a graph break in TorchDynamo,\nso we will not be able to view the state of Dynamo at the point where we intended to breakpoint.\nThe first method for setting a breakpoint is to insert it within the Dynamo source code. Three recommended locations to place a breakpoint are:\nIntorch/_dynamo/symbolic_convert.py, breakpoint at functions that are named after the problematic bytecode instruction,\nsuch asdefCALL_FUNCTIONanddefSTORE_ATTR. You can conditionally breakpoint depending on inputs,\nfor example, theargvalof the instruction, or the name of the object at the top of the stack since some bytecode opcodes are frequently used.\ntorch/_dynamo/symbolic_convert.py\ndefCALL_FUNCTION\ndefSTORE_ATTR\nargval\nBreakpoint where the graph break or error originates from. Typically, graph breaks are emitted from a call tounimplemented(...).\nunimplemented(...)\nBreakpoint intorch/_dynamo/variables/builder.py,function:_wrap. You will likely have to conditionally breakpoint on the input.\nThis function determines how to symbolically represent a given value. Consider breakpointing here if you suspect that a value is represented incorrectly.\ntorch/_dynamo/variables/builder.py,function:_wrap\nThe second way to insert a breakpoint is to usetorch._dynamo.comptime.comptime.breakpoint:\ntorch._dynamo.comptime.comptime.breakpoint\n\n```python\nfrom torch._dynamo.comptime import comptime\n\n@torch.compile\ndef f(...):\n    ...\n    comptime.breakpoint()\n    ...\n\n```\n\nA comptime breakpoint is convenient as it enables you to inspect the Dynamo state at a specific location within the user code being traced.\nIt does not require you to insert a breakpoint in the Dynamo source or to conditionally breakpoint based on variables.\nWhen a comptime breakpoint is triggered, you can do the following:\nctx.print_bt()to print the user stack trace\nctx.print_bt()\nctx.print_locals()to print all current locals\nctx.print_locals()\nctx.print_graph()to print the currently traced graph\nctx.print_graph()\nctx.disas()to print the currently traced function\u2019s bytecode\nctx.disas()\nUse standardpdbcommands, such asbt/u/d/n/s/r, - you can go up thepdbstack to inspect more Dynamo internals\npdb\nbt/u/d/n/s/r\npdb\n\n```python\nimport torch\nfrom torch._dynamo.comptime import comptime\n\n@torch.compile(backend=\"eager\")\ndef f(x):\n    y = x + 1\n    comptime.breakpoint()\n    y = y + 1\n    return y\n\nf(torch.ones(3, 3))\n\n```\n\n\n```python\n$ python playground.py\n--Return--\n> /data/users/williamwen/pytorch/torch/_dynamo/comptime.py(392)inner()->None\n-> builtins.breakpoint()\n(Pdb) ctx.print_bt()\nFile \"/data/users/williamwen/pytorch/playground.py\", line 7, in f\n    comptime.breakpoint()\n\n(Pdb) ctx.print_locals()\nx = FakeTensor(..., size=(3, 3))\ny = FakeTensor(..., size=(3, 3))\n(Pdb) bt\n...\n/data/users/williamwen/pytorch/torch/_dynamo/symbolic_convert.py(826)call_function()\n-> self.push(fn.call_function(self, args, kwargs))  # type: ignore[arg-type]\n/data/users/williamwen/pytorch/torch/_dynamo/variables/misc.py(331)call_function()\n-> func(ComptimeContext(tx))\n> /data/users/williamwen/pytorch/torch/_dynamo/comptime.py(392)inner()->None\n-> builtins.breakpoint()\n(Pdb) ctx.print_graph()\n\n\n\ndef forward(self, L_x_: \"f32[3, 3]\"):\n    l_x_ = L_x_\n\n    # File: /data/users/williamwen/pytorch/playground.py:6 in f, code: y = x + 1\n    y: \"f32[3, 3]\" = l_x_ + 1;  l_x_ = y = None\n\n```\n\nAlthough uncommon, Dynamo may generate incorrect bytecode. This may occur if you determine the following:\nAblation reveals the error is happening at the TorchDynamo level\nThe error is not being emitted from TorchDynamo stack frames\nThe error looks more like a user error rather than a Dynamo error, or is a segmentation fault\nThe error does not occur withouttorch.compile\ntorch.compile\nBytecode generation bugs are generally tricky to fix and we recommend submitting an issue instead of trying to fix those yourself.\nIf you are interested in seeing the bytecode that Dynamo generates, you can useTORCH_LOGS=bytecode.\nYou can see a high-level overview on what bytecode Dynamo generateshere.\nTORCH_LOGS=bytecode\n\n## AOTAutograd#\n\nAOTAutograd errors are typically difficult to debug - we recommend just submitting an issue.\nAOTAutograd logging output is primarily helpful to see what the input to Inductor is.\n\n## Summary of TORCH_LOGS options#\n\nA summary of helpfulTORCH_LOGSoptions is:\nTORCH_LOGS\nOption\nDescription\n+all\nOutput debug logs from alltorch.compilecomponents\ntorch.compile\n+dynamo\nOutput debug logs from TorchDynamo\n+aot\nOutput debug logs from AOTAutograd\n+inductor\nOutput debug logs from TorchInductor\ndynamic\nOutput logs from dynamic shapes\ngraph_code\nOutput the Python code for the FX graph that Dynamo generated\ngraph_sizes\nOutput the tensor sizes of the FX graph that Dynamo generated\ntrace_bytecode\nOutput the bytecode instructions that Dynamo is tracing through and the symbolic interpreter stack Dynamo is keeping track of\ntrace_source\nOutput the line of code in the original source that Dynamo is currently tracing through\nbytecode\nOutput Dynamo-generated bytecode\nguards\nOutput generated guards\nrecompiles\nOutput recompilation reasons (only the first guard check that fails)\nrecompiles_verbose\nOutput all guard checks that fail when a recompilation occurs\naot_graphs\nOutput graph generated by AOTAutograd\naot_joint_graphs\nOutput the joint forward-backward graph generated by AOTAutograd\noutput_code\nOutput code generated by Inductor\nkernel_code\nOutput code generated by Inductor on a per-kernel basis\nschedule\nOutput Inductor scheduling logs\nperf_hints\nOutput Inductor perf hint logs\nfusion\nOutput Inductor fusion logs\nFor the full list of options, seetorch._loggingandtorch._logging.set_logs.\n\n## Related Articles#\n\ntorch.compile tutorial\ntorch.compile fine-grained APIs\ntorch.compile FAQ\ntorch.compiler namespace overview\ntorch.compiler API reference\nProfiling torch.compile\ntorch.compile missing manual\nThe dynamic shapes manual\nTorchInductor caching tutorial",
  "url": "https://pytorch.org/docs/stable/torch.compiler_troubleshooting.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}