{
  "doc_id": "0e19ad2e9f1303125d35c66086b2bbe3",
  "source": "pytorch_docs",
  "title": "torch.utils.dlpack \u2014 PyTorch 2.9 documentation",
  "text": "\n## torch.utils.dlpack#\n\nCreated On: Jul 11, 2018 | Last Updated On: Jun 13, 2025\nConverts a tensor from an external library into atorch.Tensor.\ntorch.Tensor\nThe returned PyTorch tensor will share the memory with the input tensor\n(which may have come from another library). Note that in-place operations\nwill therefore also affect the data of the input tensor. This may lead to\nunexpected issues (e.g., other libraries may have read-only flags or\nimmutable data structures), so the user should only do this if they know\nfor sure that this is fine.\next_tensor(object with__dlpack__attribute, or a DLPack capsule) \u2013The tensor or DLPack capsule to convert.Ifext_tensoris a tensor (or ndarray) object, it must support\nthe__dlpack__protocol (i.e., have aext_tensor.__dlpack__method). Otherwiseext_tensormay be a DLPack capsule, which is\nan opaquePyCapsuleinstance, typically produced by ato_dlpackfunction or method.\n__dlpack__\nThe tensor or DLPack capsule to convert.\nIfext_tensoris a tensor (or ndarray) object, it must support\nthe__dlpack__protocol (i.e., have aext_tensor.__dlpack__method). Otherwiseext_tensormay be a DLPack capsule, which is\nan opaquePyCapsuleinstance, typically produced by ato_dlpackfunction or method.\next_tensor\n__dlpack__\next_tensor.__dlpack__\next_tensor\nPyCapsule\nto_dlpack\ndevice(torch.deviceorstrorNone) \u2013 An optional PyTorch device\nspecifying where to place the new tensor. If None (default), the\nnew tensor will be on the same device asext_tensor.\next_tensor\ncopy(boolorNone) \u2013 An optional boolean indicating whether or not to copyself. If None, PyTorch will copy only if necessary.\nself\nTensor\nExamples:\n\n```python\n>>> import torch.utils.dlpack\n>>> t = torch.arange(4)\n\n# Convert a tensor directly (supported in PyTorch >= 1.10)\n>>> t2 = torch.from_dlpack(t)\n>>> t2[:2] = -1  # show that memory is shared\n>>> t2\ntensor([-1, -1,  2,  3])\n>>> t\ntensor([-1, -1,  2,  3])\n\n# The old-style DLPack usage, with an intermediate capsule object\n>>> capsule = torch.utils.dlpack.to_dlpack(t)\n>>> capsule\n<capsule object \"dltensor\" at ...>\n>>> t3 = torch.from_dlpack(capsule)\n>>> t3\ntensor([-1, -1,  2,  3])\n>>> t3[0] = -9  # now we're sharing memory between 3 tensors\n>>> t3\ntensor([-9, -1,  2,  3])\n>>> t2\ntensor([-9, -1,  2,  3])\n>>> t\ntensor([-9, -1,  2,  3])\n\n```\n\nReturns an opaque object (a \u201cDLPack capsule\u201d) representing the tensor.\nNote\nto_dlpackis a legacy DLPack interface. The capsule it returns\ncannot be used for anything in Python other than use it as input tofrom_dlpack. The more idiomatic use of DLPack is to callfrom_dlpackdirectly on the tensor object - this works when that\nobject has a__dlpack__method, which PyTorch and most other\nlibraries indeed have now.\nto_dlpack\nfrom_dlpack\nfrom_dlpack\n__dlpack__\nWarning\nOnly callfrom_dlpackonce per capsule produced withto_dlpack.\nBehavior when a capsule is consumed multiple times is undefined.\nfrom_dlpack\nto_dlpack\ntensor\u2013 a tensor to be exported\nThe DLPack capsule shares the tensor\u2019s memory.",
  "url": "https://pytorch.org/docs/stable/dlpack.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}