{
  "doc_id": "e34e5ddc62d22ef8db87f6d02b575fc4",
  "source": "pytorch_docs",
  "title": "python.control-flow \u2014 PyTorch 2.9 documentation",
  "text": "\n## python.control-flow#\n\n\n## dynamic_shape_if_guard#\n\nNote\nTags:torch.dynamic-shape,python.control-flow\nSupport Level: SUPPORTED\nOriginal source code:\n\n```python\n# mypy: allow-untyped-defs\nimport torch\n\nclass DynamicShapeIfGuard(torch.nn.Module):\n    \"\"\"\n    `if` statement with backed dynamic shape predicate will be specialized into\n    one particular branch and generate a guard. However, export will fail if the\n    the dimension is marked as dynamic shape from higher level API.\n    \"\"\"\n\n    def forward(self, x):\n        if x.shape[0] == 3:\n            return x.cos()\n\n        return x.sin()\n\nexample_args = (torch.randn(3, 2, 2),)\ntags = {\"torch.dynamic-shape\", \"python.control-flow\"}\nmodel = DynamicShapeIfGuard()\n\n\ntorch.export.export(model, example_args)\n\n```\n\nResult:\n\n```python\nExportedProgram:\n    class GraphModule(torch.nn.Module):\n        def forward(self, x: \"f32[3, 2, 2]\"):\n                 cos: \"f32[3, 2, 2]\" = torch.ops.aten.cos.default(x);  x = None\n            return (cos,)\n\nGraph signature:\n    # inputs\n    x: USER_INPUT\n\n    # outputs\n    cos: USER_OUTPUT\n\nRange constraints: {}\n\n```\n\n\n## list_unpack#\n\nNote\nTags:python.data-structure,python.control-flow\nSupport Level: SUPPORTED\nOriginal source code:\n\n```python\n# mypy: allow-untyped-defs\n\nimport torch\n\nclass ListUnpack(torch.nn.Module):\n    \"\"\"\n    Lists are treated as static construct, therefore unpacking should be\n    erased after tracing.\n    \"\"\"\n\n    def forward(self, args: list[torch.Tensor]):\n        \"\"\"\n        Lists are treated as static construct, therefore unpacking should be\n        erased after tracing.\n        \"\"\"\n        x, *y = args\n        return x + y[0]\n\nexample_args = ([torch.randn(3, 2), torch.tensor(4), torch.tensor(5)],)\ntags = {\"python.control-flow\", \"python.data-structure\"}\nmodel = ListUnpack()\n\n\ntorch.export.export(model, example_args)\n\n```\n\nResult:\n\n```python\nExportedProgram:\n    class GraphModule(torch.nn.Module):\n        def forward(self, args_0: \"f32[3, 2]\", args_1: \"i64[]\", args_2: \"i64[]\"):\n                 add: \"f32[3, 2]\" = torch.ops.aten.add.Tensor(args_0, args_1);  args_0 = args_1 = None\n            return (add,)\n\nGraph signature:\n    # inputs\n    args_0: USER_INPUT\n    args_1: USER_INPUT\n    args_2: USER_INPUT\n\n    # outputs\n    add: USER_OUTPUT\n\nRange constraints: {}\n\n```\n\n\n## static_for_loop#\n\nNote\nTags:python.control-flow\nSupport Level: SUPPORTED\nOriginal source code:\n\n```python\n# mypy: allow-untyped-defs\nimport torch\n\nclass StaticForLoop(torch.nn.Module):\n    \"\"\"\n    A for loop with constant number of iterations should be unrolled in the exported graph.\n    \"\"\"\n\n    def forward(self, x):\n        # constant\n        ret = [i + x for i in range(10)]\n        return ret\n\nexample_args = (torch.randn(3, 2),)\ntags = {\"python.control-flow\"}\nmodel = StaticForLoop()\n\n\ntorch.export.export(model, example_args)\n\n```\n\nResult:\n\n```python\nExportedProgram:\n    class GraphModule(torch.nn.Module):\n        def forward(self, x: \"f32[3, 2]\"):\n                 add: \"f32[3, 2]\" = torch.ops.aten.add.Tensor(x, 0)\n            add_1: \"f32[3, 2]\" = torch.ops.aten.add.Tensor(x, 1)\n            add_2: \"f32[3, 2]\" = torch.ops.aten.add.Tensor(x, 2)\n            add_3: \"f32[3, 2]\" = torch.ops.aten.add.Tensor(x, 3)\n            add_4: \"f32[3, 2]\" = torch.ops.aten.add.Tensor(x, 4)\n            add_5: \"f32[3, 2]\" = torch.ops.aten.add.Tensor(x, 5)\n            add_6: \"f32[3, 2]\" = torch.ops.aten.add.Tensor(x, 6)\n            add_7: \"f32[3, 2]\" = torch.ops.aten.add.Tensor(x, 7)\n            add_8: \"f32[3, 2]\" = torch.ops.aten.add.Tensor(x, 8)\n            add_9: \"f32[3, 2]\" = torch.ops.aten.add.Tensor(x, 9);  x = None\n            return (add, add_1, add_2, add_3, add_4, add_5, add_6, add_7, add_8, add_9)\n\nGraph signature:\n    # inputs\n    x: USER_INPUT\n\n    # outputs\n    add: USER_OUTPUT\n    add_1: USER_OUTPUT\n    add_2: USER_OUTPUT\n    add_3: USER_OUTPUT\n    add_4: USER_OUTPUT\n    add_5: USER_OUTPUT\n    add_6: USER_OUTPUT\n    add_7: USER_OUTPUT\n    add_8: USER_OUTPUT\n    add_9: USER_OUTPUT\n\nRange constraints: {}\n\n```\n\n\n## static_if#\n\nNote\nTags:python.control-flow\nSupport Level: SUPPORTED\nOriginal source code:\n\n```python\n# mypy: allow-untyped-defs\nimport torch\n\nclass StaticIf(torch.nn.Module):\n    \"\"\"\n    `if` statement with static predicate value should be traced through with the\n    taken branch.\n    \"\"\"\n\n    def forward(self, x):\n        if len(x.shape) == 3:\n            return x + torch.ones(1, 1, 1)\n\n        return x\n\nexample_args = (torch.randn(3, 2, 2),)\ntags = {\"python.control-flow\"}\nmodel = StaticIf()\n\n\ntorch.export.export(model, example_args)\n\n```\n\nResult:\n\n```python\nExportedProgram:\n    class GraphModule(torch.nn.Module):\n        def forward(self, x: \"f32[3, 2, 2]\"):\n                 ones: \"f32[1, 1, 1]\" = torch.ops.aten.ones.default([1, 1, 1], device = device(type='cpu'), pin_memory = False)\n            add: \"f32[3, 2, 2]\" = torch.ops.aten.add.Tensor(x, ones);  x = ones = None\n            return (add,)\n\nGraph signature:\n    # inputs\n    x: USER_INPUT\n\n    # outputs\n    add: USER_OUTPUT\n\nRange constraints: {}\n\n```\n",
  "url": "https://pytorch.org/docs/stable/generated/exportdb/python.control-flow.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}