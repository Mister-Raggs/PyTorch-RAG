{
  "doc_id": "c189e78cf3fbeaa5820eb65d1f9f4a66",
  "source": "pytorch_docs",
  "title": "torch.testing \u2014 PyTorch 2.9 documentation",
  "text": "\n## torch.testing#\n\nCreated On: May 07, 2021 | Last Updated On: Jun 10, 2025\nAsserts thatactualandexpectedare close.\nactual\nexpected\nIfactualandexpectedare strided, non-quantized, real-valued, and finite, they are considered close if\nactual\nexpected\nNon-finite values (-infandinf) are only considered close if and only if they are equal.NaN\u2019s are\nonly considered equal to each other ifequal_nanisTrue.\n-inf\ninf\nNaN\nequal_nan\nTrue\nIn addition, they are only considered close if they have the same\ndevice(ifcheck_deviceisTrue),\ndevice\ncheck_device\nTrue\ndtype(ifcheck_dtypeisTrue),\ndtype\ncheck_dtype\nTrue\nlayout(ifcheck_layoutisTrue), and\nlayout\ncheck_layout\nTrue\nstride (ifcheck_strideisTrue).\ncheck_stride\nTrue\nIf eitheractualorexpectedis a meta tensor, only the attribute checks will be performed.\nactual\nexpected\nIfactualandexpectedare sparse (either having COO, CSR, CSC, BSR, or BSC layout), their strided members are\nchecked individually. Indices, namelyindicesfor COO,crow_indicesandcol_indicesfor CSR and BSR,\norccol_indicesandrow_indicesfor CSC and BSC layouts, respectively,\nare always checked for equality whereas the values are checked for closeness according to the definition above.\nactual\nexpected\nindices\ncrow_indices\ncol_indices\nccol_indices\nrow_indices\nIfactualandexpectedare quantized, they are considered close if they have the sameqscheme()and the result ofdequantize()is close according to the\ndefinition above.\nactual\nexpected\nqscheme()\ndequantize()\nactualandexpectedcan beTensor\u2019s or any tensor-or-scalar-likes from whichtorch.Tensor\u2019s can be constructed withtorch.as_tensor(). Except for Python scalars the input types\nhave to be directly related. In addition,actualandexpectedcan beSequence\u2019s\norMapping\u2019s in which case they are considered close if their structure matches and all\ntheir elements are considered close according to the above definition.\nactual\nexpected\nTensor\ntorch.Tensor\ntorch.as_tensor()\nactual\nexpected\nSequence\nMapping\nNote\nPython scalars are an exception to the type relation requirement, because theirtype(), i.e.int,float, andcomplex, is equivalent to thedtypeof a tensor-like. Thus,\nPython scalars of different types can be checked, but requirecheck_dtype=False.\ntype()\nint\nfloat\ncomplex\ndtype\ncheck_dtype=False\nactual(Any) \u2013 Actual input.\nexpected(Any) \u2013 Expected input.\nallow_subclasses(bool) \u2013 IfTrue(default) and except for Python scalars, inputs of directly related types\nare allowed. Otherwise type equality is required.\nTrue\nrtol(Optional[float]) \u2013 Relative tolerance. If specifiedatolmust also be specified. If omitted, default\nvalues based on thedtypeare selected with the below table.\natol\ndtype\natol(Optional[float]) \u2013 Absolute tolerance. If specifiedrtolmust also be specified. If omitted, default\nvalues based on thedtypeare selected with the below table.\nrtol\ndtype\nequal_nan(Union[bool,str]) \u2013 IfTrue, twoNaNvalues will be considered equal.\nTrue\nNaN\ncheck_device(bool) \u2013 IfTrue(default), asserts that corresponding tensors are on the samedevice. If this check is disabled, tensors on differentdevice\u2019s are moved to the CPU before being compared.\nTrue\ndevice\ndevice\ncheck_dtype(bool) \u2013 IfTrue(default), asserts that corresponding tensors have the samedtype. If this\ncheck is disabled, tensors with differentdtype\u2019s are promoted  to a commondtype(according totorch.promote_types()) before being compared.\nTrue\ndtype\ndtype\ndtype\ntorch.promote_types()\ncheck_layout(bool) \u2013 IfTrue(default), asserts that corresponding tensors have the samelayout. If this\ncheck is disabled, tensors with differentlayout\u2019s are converted to strided tensors before being\ncompared.\nTrue\nlayout\nlayout\ncheck_stride(bool) \u2013 IfTrueand corresponding tensors are strided, asserts that they have the same stride.\nTrue\nmsg(Optional[Union[str,Callable[[str],str]]]) \u2013 Optional error message to use in case a failure occurs during\nthe comparison. Can also passed as callable in which case it will be called with the generated message and\nshould return the new message.\nValueError\u2013 If notorch.Tensorcan be constructed from an input.\ntorch.Tensor\nValueError\u2013 If onlyrtoloratolis specified.\nrtol\natol\nAssertionError\u2013 If corresponding inputs are not Python scalars and are not directly related.\nAssertionError\u2013 Ifallow_subclassesisFalse, but corresponding inputs are not Python scalars and have\n    different types.\nallow_subclasses\nFalse\nAssertionError\u2013 If the inputs areSequence\u2019s, but their length does not match.\nSequence\nAssertionError\u2013 If the inputs areMapping\u2019s, but their set of keys do not match.\nMapping\nAssertionError\u2013 If corresponding tensors do not have the sameshape.\nshape\nAssertionError\u2013 Ifcheck_layoutisTrue, but corresponding tensors do not have the samelayout.\ncheck_layout\nTrue\nlayout\nAssertionError\u2013 If only one of corresponding tensors is quantized.\nAssertionError\u2013 If corresponding tensors are quantized, but have differentqscheme()\u2019s.\nqscheme()\nAssertionError\u2013 Ifcheck_deviceisTrue, but corresponding tensors are not on the samedevice.\ncheck_device\nTrue\ndevice\nAssertionError\u2013 Ifcheck_dtypeisTrue, but corresponding tensors do not have the samedtype.\ncheck_dtype\nTrue\ndtype\nAssertionError\u2013 Ifcheck_strideisTrue, but corresponding strided tensors do not have the same stride.\ncheck_stride\nTrue\nAssertionError\u2013 If the values of corresponding tensors are not close according to the definition above.\nThe following table displays the defaultrtolandatolfor differentdtype\u2019s. In case of mismatchingdtype\u2019s, the maximum of both tolerances is used.\nrtol\natol\ndtype\ndtype\ndtype\ndtype\nrtol\nrtol\natol\natol\nfloat16\nfloat16\n1e-3\n1e-3\n1e-5\n1e-5\nbfloat16\nbfloat16\n1.6e-2\n1.6e-2\n1e-5\n1e-5\nfloat32\nfloat32\n1.3e-6\n1.3e-6\n1e-5\n1e-5\nfloat64\nfloat64\n1e-7\n1e-7\n1e-7\n1e-7\ncomplex32\ncomplex32\n1e-3\n1e-3\n1e-5\n1e-5\ncomplex64\ncomplex64\n1.3e-6\n1.3e-6\n1e-5\n1e-5\ncomplex128\ncomplex128\n1e-7\n1e-7\n1e-7\n1e-7\nquint8\nquint8\n1.3e-6\n1.3e-6\n1e-5\n1e-5\nquint2x4\nquint2x4\n1.3e-6\n1.3e-6\n1e-5\n1e-5\nquint4x2\nquint4x2\n1.3e-6\n1.3e-6\n1e-5\n1e-5\nqint8\nqint8\n1.3e-6\n1.3e-6\n1e-5\n1e-5\nqint32\nqint32\n1.3e-6\n1.3e-6\n1e-5\n1e-5\nother\n0.0\n0.0\n0.0\n0.0\nNote\nassert_close()is highly configurable with strict default settings. Users are encouraged\ntopartial()it to fit their use case. For example, if an equality check is needed, one might\ndefine anassert_equalthat uses zero tolerances for everydtypeby default:\nassert_close()\npartial()\nassert_equal\ndtype\n\n```python\n>>> import functools\n>>> assert_equal = functools.partial(torch.testing.assert_close, rtol=0, atol=0)\n>>> assert_equal(1e-9, 1e-10)\nTraceback (most recent call last):\n...\nAssertionError: Scalars are not equal!\n\nExpected 1e-10 but got 1e-09.\nAbsolute difference: 9.000000000000001e-10\nRelative difference: 9.0\n\n```\n\nExamples\n\n```python\n>>> # tensor to tensor comparison\n>>> expected = torch.tensor([1e0, 1e-1, 1e-2])\n>>> actual = torch.acos(torch.cos(expected))\n>>> torch.testing.assert_close(actual, expected)\n\n```\n\n\n```python\n>>> # scalar to scalar comparison\n>>> import math\n>>> expected = math.sqrt(2.0)\n>>> actual = 2.0 / math.sqrt(2.0)\n>>> torch.testing.assert_close(actual, expected)\n\n```\n\n\n```python\n>>> # numpy array to numpy array comparison\n>>> import numpy as np\n>>> expected = np.array([1e0, 1e-1, 1e-2])\n>>> actual = np.arccos(np.cos(expected))\n>>> torch.testing.assert_close(actual, expected)\n\n```\n\n\n```python\n>>> # sequence to sequence comparison\n>>> import numpy as np\n>>> # The types of the sequences do not have to match. They only have to have the same\n>>> # length and their elements have to match.\n>>> expected = [torch.tensor([1.0]), 2.0, np.array(3.0)]\n>>> actual = tuple(expected)\n>>> torch.testing.assert_close(actual, expected)\n\n```\n\n\n```python\n>>> # mapping to mapping comparison\n>>> from collections import OrderedDict\n>>> import numpy as np\n>>> foo = torch.tensor(1.0)\n>>> bar = 2.0\n>>> baz = np.array(3.0)\n>>> # The types and a possible ordering of mappings do not have to match. They only\n>>> # have to have the same set of keys and their elements have to match.\n>>> expected = OrderedDict([(\"foo\", foo), (\"bar\", bar), (\"baz\", baz)])\n>>> actual = {\"baz\": baz, \"bar\": bar, \"foo\": foo}\n>>> torch.testing.assert_close(actual, expected)\n\n```\n\n\n```python\n>>> expected = torch.tensor([1.0, 2.0, 3.0])\n>>> actual = expected.clone()\n>>> # By default, directly related instances can be compared\n>>> torch.testing.assert_close(torch.nn.Parameter(actual), expected)\n>>> # This check can be made more strict with allow_subclasses=False\n>>> torch.testing.assert_close(\n...     torch.nn.Parameter(actual), expected, allow_subclasses=False\n... )\nTraceback (most recent call last):\n...\nTypeError: No comparison pair was able to handle inputs of type\n<class 'torch.nn.parameter.Parameter'> and <class 'torch.Tensor'>.\n>>> # If the inputs are not directly related, they are never considered close\n>>> torch.testing.assert_close(actual.numpy(), expected)\nTraceback (most recent call last):\n...\nTypeError: No comparison pair was able to handle inputs of type <class 'numpy.ndarray'>\nand <class 'torch.Tensor'>.\n>>> # Exceptions to these rules are Python scalars. They can be checked regardless of\n>>> # their type if check_dtype=False.\n>>> torch.testing.assert_close(1.0, 1, check_dtype=False)\n\n```\n\n\n```python\n>>> # NaN != NaN by default.\n>>> expected = torch.tensor(float(\"Nan\"))\n>>> actual = expected.clone()\n>>> torch.testing.assert_close(actual, expected)\nTraceback (most recent call last):\n...\nAssertionError: Scalars are not close!\n\nExpected nan but got nan.\nAbsolute difference: nan (up to 1e-05 allowed)\nRelative difference: nan (up to 1.3e-06 allowed)\n>>> torch.testing.assert_close(actual, expected, equal_nan=True)\n\n```\n\n\n```python\n>>> expected = torch.tensor([1.0, 2.0, 3.0])\n>>> actual = torch.tensor([1.0, 4.0, 5.0])\n>>> # The default error message can be overwritten.\n>>> torch.testing.assert_close(\n...     actual, expected, msg=\"Argh, the tensors are not close!\"\n... )\nTraceback (most recent call last):\n...\nAssertionError: Argh, the tensors are not close!\n>>> # If msg is a callable, it can be used to augment the generated message with\n>>> # extra information\n>>> torch.testing.assert_close(\n...     actual, expected, msg=lambda msg: f\"Header\\n\\n{msg}\\n\\nFooter\"\n... )\nTraceback (most recent call last):\n...\nAssertionError: Header\n\nTensor-likes are not close!\n\nMismatched elements: 2 / 3 (66.7%)\nGreatest absolute difference: 2.0 at index (1,) (up to 1e-05 allowed)\nGreatest relative difference: 1.0 at index (1,) (up to 1.3e-06 allowed)\n\nFooter\n\n```\n\nCreates a tensor with the givenshape,device, anddtype, and filled with\nvalues uniformly drawn from[low,high).\nshape\ndevice\ndtype\n[low,high)\nIfloworhighare specified and are outside the range of thedtype\u2019s representable\nfinite values then they are clamped to the lowest or highest representable finite value, respectively.\nIfNone, then the following table describes the default values forlowandhigh,\nwhich depend ondtype.\nlow\nhigh\ndtype\nNone\nlow\nhigh\ndtype\ndtype\ndtype\nlow\nlow\nhigh\nhigh\nboolean type\n0\n0\n2\n2\nunsigned integral type\n0\n0\n10\n10\nsigned integral types\n-9\n-9\n10\n10\nfloating types\n-9\n-9\n9\n9\ncomplex types\n-9\n-9\n9\n9\nshape(Tuple[int,...]) \u2013 Single integer or a sequence of integers defining the shape of the output tensor.\ndtype(torch.dtype) \u2013 The data type of the returned tensor.\ntorch.dtype\ndevice(Union[str,torch.device]) \u2013 The device of the returned tensor.\nlow(Optional[Number]) \u2013 Sets the lower limit (inclusive) of the given range. If a number is provided it is\nclamped to the least representable finite value of the given dtype. WhenNone(default),\nthis value is determined based on thedtype(see the table above). Default:None.\nNone\ndtype\nNone\nhigh(Optional[Number]) \u2013Sets the upper limit (exclusive) of the given range. If a number is provided it is\nclamped to the greatest representable finite value of the given dtype. WhenNone(default) this value\nis determined based on thedtype(see the table above). Default:None.Deprecated since version 2.1:Passinglow==hightomake_tensor()for floating or complex types is deprecated\nsince 2.1 and will be removed in 2.3. Usetorch.full()instead.\nSets the upper limit (exclusive) of the given range. If a number is provided it is\nclamped to the greatest representable finite value of the given dtype. WhenNone(default) this value\nis determined based on thedtype(see the table above). Default:None.\nNone\ndtype\nNone\nDeprecated since version 2.1:Passinglow==hightomake_tensor()for floating or complex types is deprecated\nsince 2.1 and will be removed in 2.3. Usetorch.full()instead.\nlow==high\nmake_tensor()\ntorch.full()\nrequires_grad(Optional[bool]) \u2013 If autograd should record operations on the returned tensor. Default:False.\nFalse\nnoncontiguous(Optional[bool]) \u2013 IfTrue, the returned tensor will be noncontiguous. This argument is\nignored if the constructed tensor has fewer than two elements. Mutually exclusive withmemory_format.\nmemory_format\nexclude_zero(Optional[bool]) \u2013 IfTruethen zeros are replaced with the dtype\u2019s small positive value\ndepending on thedtype. For bool and integer types zero is replaced with one. For floating\npoint types it is replaced with the dtype\u2019s smallest positive normal number (the \u201ctiny\u201d value of thedtype\u2019sfinfo()object), and for complex types it is replaced with a complex number\nwhose real and imaginary parts are both the smallest positive normal number representable by the complex\ntype. DefaultFalse.\nTrue\ndtype\ndtype\nfinfo()\nFalse\nmemory_format(Optional[torch.memory_format]) \u2013 The memory format of the returned tensor. Mutually exclusive\nwithnoncontiguous.\nnoncontiguous\nValueError\u2013 Ifrequires_grad=Trueis passed for integraldtype\nrequires_grad=True\nValueError\u2013 Iflow>=high.\nlow>=high\nValueError\u2013 If eitherloworhighisnan.\nlow\nhigh\nnan\nValueError\u2013 If bothnoncontiguousandmemory_formatare passed.\nnoncontiguous\nmemory_format\nTypeError\u2013 Ifdtypeisn\u2019t supported by this function.\ndtype\nTensor\nExamples\n\n```python\n>>> from torch.testing import make_tensor\n>>> # Creates a float tensor with values in [-1, 1)\n>>> make_tensor((3,), device=\"cpu\", dtype=torch.float32, low=-1, high=1)\ntensor([ 0.1205, 0.2282, -0.6380])\n>>> # Creates a bool tensor on CUDA\n>>> make_tensor((2, 2), device=\"cuda\", dtype=torch.bool)\ntensor([[False, False],\n        [False, True]], device='cuda:0')\n\n```\n\nWarning\ntorch.testing.assert_allclose()is deprecated since1.12and will be removed in a future release.\nPlease usetorch.testing.assert_close()instead. You can find detailed upgrade instructionshere.\ntorch.testing.assert_allclose()\n1.12\ntorch.testing.assert_close()",
  "url": "https://pytorch.org/docs/stable/testing.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}