{
  "doc_id": "9c0cdcbe3770cc22864c6787b6e7b7a1",
  "source": "pytorch_docs",
  "title": "Automatic Mixed Precision examples \u2014 PyTorch 2.9 documentation",
  "text": "\n## Automatic Mixed Precision examples#\n\nCreated On: Feb 13, 2020 | Last Updated On: Sep 13, 2024\nOrdinarily, \u201cautomatic mixed precision training\u201d means training withtorch.autocastandtorch.amp.GradScalertogether.\ntorch.autocast\ntorch.amp.GradScaler\nInstances oftorch.autocastenable autocasting for chosen regions.\nAutocasting automatically chooses the precision for operations to improve performance\nwhile maintaining accuracy.\ntorch.autocast\nInstances oftorch.amp.GradScalerhelp perform the steps of\ngradient scaling conveniently.  Gradient scaling improves convergence for networks withfloat16(by default on CUDA and XPU)\ngradients by minimizing gradient underflow, as explainedhere.\ntorch.amp.GradScaler\nfloat16\ntorch.autocastandtorch.amp.GradScalerare modular.\nIn the samples below, each is used as its individual documentation suggests.\ntorch.autocast\ntorch.amp.GradScaler\n(Samples here are illustrative.  See theAutomatic Mixed Precision recipefor a runnable walkthrough.)\nTypical Mixed Precision Training\nWorking with Unscaled Gradients\nGradient clipping\nWorking with Scaled Gradients\nGradient accumulation\nGradient penalty\nWorking with Multiple Models, Losses, and Optimizers\nWorking with Multiple GPUs\nDataParallel in a single process\nDistributedDataParallel, one GPU per process\nDistributedDataParallel, multiple GPUs per process\nAutocast and Custom Autograd Functions\nFunctions with multiple inputs or autocastable ops\nFunctions that need a particulardtype\ndtype\n\n## Typical Mixed Precision Training#\n\n\n```python\n# Creates model and optimizer in default precision\nmodel = Net().cuda()\noptimizer = optim.SGD(model.parameters(), ...)\n\n# Creates a GradScaler once at the beginning of training.\nscaler = GradScaler()\n\nfor epoch in epochs:\n    for input, target in data:\n        optimizer.zero_grad()\n\n        # Runs the forward pass with autocasting.\n        with autocast(device_type='cuda', dtype=torch.float16):\n            output = model(input)\n            loss = loss_fn(output, target)\n\n        # Scales loss.  Calls backward() on scaled loss to create scaled gradients.\n        # Backward passes under autocast are not recommended.\n        # Backward ops run in the same dtype autocast chose for corresponding forward ops.\n        scaler.scale(loss).backward()\n\n        # scaler.step() first unscales the gradients of the optimizer's assigned params.\n        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,\n        # otherwise, optimizer.step() is skipped.\n        scaler.step(optimizer)\n\n        # Updates the scale for next iteration.\n        scaler.update()\n\n```\n\n\n## Working with Unscaled Gradients#\n\nAll gradients produced byscaler.scale(loss).backward()are scaled.  If you wish to modify or inspect\nthe parameters\u2019.gradattributes betweenbackward()andscaler.step(optimizer),  you should\nunscale them first.  For example, gradient clipping manipulates a set of gradients such that their global norm\n(seetorch.nn.utils.clip_grad_norm_()) or maximum magnitude (seetorch.nn.utils.clip_grad_value_())\nis<=<=<=some user-imposed threshold.  If you attempted to clipwithoutunscaling, the gradients\u2019 norm/maximum\nmagnitude would also be scaled, so your requested threshold (which was meant to be the threshold forunscaledgradients) would be invalid.\nscaler.scale(loss).backward()\n.grad\nbackward()\nscaler.step(optimizer)\ntorch.nn.utils.clip_grad_norm_()\ntorch.nn.utils.clip_grad_value_()\nscaler.unscale_(optimizer)unscales gradients held byoptimizer\u2019s assigned parameters.\nIf your model or models contain other parameters that were assigned to another optimizer\n(sayoptimizer2), you may callscaler.unscale_(optimizer2)separately to unscale those\nparameters\u2019 gradients as well.\nscaler.unscale_(optimizer)\noptimizer\noptimizer2\nscaler.unscale_(optimizer2)\n\n## Gradient clipping#\n\nCallingscaler.unscale_(optimizer)before clipping enables you to clip unscaled gradients as usual:\nscaler.unscale_(optimizer)\n\n```python\nscaler = GradScaler()\n\nfor epoch in epochs:\n    for input, target in data:\n        optimizer.zero_grad()\n        with autocast(device_type='cuda', dtype=torch.float16):\n            output = model(input)\n            loss = loss_fn(output, target)\n        scaler.scale(loss).backward()\n\n        # Unscales the gradients of optimizer's assigned params in-place\n        scaler.unscale_(optimizer)\n\n        # Since the gradients of optimizer's assigned params are unscaled, clips as usual:\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n\n        # optimizer's gradients are already unscaled, so scaler.step does not unscale them,\n        # although it still skips optimizer.step() if the gradients contain infs or NaNs.\n        scaler.step(optimizer)\n\n        # Updates the scale for next iteration.\n        scaler.update()\n\n```\n\nscalerrecords thatscaler.unscale_(optimizer)was already called for this optimizer\nthis iteration, soscaler.step(optimizer)knows not to redundantly unscale gradients before\n(internally) callingoptimizer.step().\nscaler\nscaler.unscale_(optimizer)\nscaler.step(optimizer)\noptimizer.step()\nWarning\nunscale_should only be called once per optimizer perstepcall,\nand only after all gradients for that optimizer\u2019s assigned parameters have been accumulated.\nCallingunscale_twice for a given optimizer between eachsteptriggers a RuntimeError.\nunscale_\nstep\nunscale_\nstep\n\n## Working with Scaled Gradients#\n\n\n## Gradient accumulation#\n\nGradient accumulation adds gradients over an effective batch of sizebatch_per_iter*iters_to_accumulate(*num_procsif distributed).  The scale should be calibrated for the effective batch, which means inf/NaN checking,\nstep skipping if inf/NaN grads are found, and scale updates should occur at effective-batch granularity.\nAlso, grads should remain scaled, and the scale factor should remain constant, while grads for a given effective\nbatch are accumulated.  If grads are unscaled (or the scale factor changes) before accumulation is complete,\nthe next backward pass will add scaled grads to unscaled grads (or grads scaled by a different factor)\nafter which it\u2019s impossible to recover the accumulated unscaled gradsstepmust apply.\nbatch_per_iter*iters_to_accumulate\n*num_procs\nstep\nTherefore, if you want tounscale_grads (e.g., to allow clipping unscaled grads),\ncallunscale_just beforestep, after all (scaled) grads for the upcomingstephave been accumulated.  Also, only callupdateat the end of iterations\nwhere you calledstepfor a full effective batch:\nunscale_\nunscale_\nstep\nstep\nupdate\nstep\n\n```python\nscaler = GradScaler()\n\nfor epoch in epochs:\n    for i, (input, target) in enumerate(data):\n        with autocast(device_type='cuda', dtype=torch.float16):\n            output = model(input)\n            loss = loss_fn(output, target)\n            loss = loss / iters_to_accumulate\n\n        # Accumulates scaled gradients.\n        scaler.scale(loss).backward()\n\n        if (i + 1) % iters_to_accumulate == 0:\n            # may unscale_ here if desired (e.g., to allow clipping unscaled gradients)\n\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n\n```\n\n\n## Gradient penalty#\n\nA gradient penalty implementation commonly creates gradients usingtorch.autograd.grad(), combines them to create the penalty value,\nand adds the penalty value to the loss.\ntorch.autograd.grad()\nHere\u2019s an ordinary example of an L2 penalty without gradient scaling or autocasting:\n\n```python\nfor epoch in epochs:\n    for input, target in data:\n        optimizer.zero_grad()\n        output = model(input)\n        loss = loss_fn(output, target)\n\n        # Creates gradients\n        grad_params = torch.autograd.grad(outputs=loss,\n                                          inputs=model.parameters(),\n                                          create_graph=True)\n\n        # Computes the penalty term and adds it to the loss\n        grad_norm = 0\n        for grad in grad_params:\n            grad_norm += grad.pow(2).sum()\n        grad_norm = grad_norm.sqrt()\n        loss = loss + grad_norm\n\n        loss.backward()\n\n        # clip gradients here, if desired\n\n        optimizer.step()\n\n```\n\nTo implement a gradient penaltywithgradient scaling, theoutputsTensor(s)\npassed totorch.autograd.grad()should be scaled.  The resulting gradients\nwill therefore be scaled, and should be unscaled before being combined to create the\npenalty value.\noutputs\ntorch.autograd.grad()\nAlso, the penalty term computation is part of the forward pass, and therefore should be\ninside anautocastcontext.\nautocast\nHere\u2019s how that looks for the same L2 penalty:\n\n```python\nscaler = GradScaler()\n\nfor epoch in epochs:\n    for input, target in data:\n        optimizer.zero_grad()\n        with autocast(device_type='cuda', dtype=torch.float16):\n            output = model(input)\n            loss = loss_fn(output, target)\n\n        # Scales the loss for autograd.grad's backward pass, producing scaled_grad_params\n        scaled_grad_params = torch.autograd.grad(outputs=scaler.scale(loss),\n                                                 inputs=model.parameters(),\n                                                 create_graph=True)\n\n        # Creates unscaled grad_params before computing the penalty. scaled_grad_params are\n        # not owned by any optimizer, so ordinary division is used instead of scaler.unscale_:\n        inv_scale = 1./scaler.get_scale()\n        grad_params = [p * inv_scale for p in scaled_grad_params]\n\n        # Computes the penalty term and adds it to the loss\n        with autocast(device_type='cuda', dtype=torch.float16):\n            grad_norm = 0\n            for grad in grad_params:\n                grad_norm += grad.pow(2).sum()\n            grad_norm = grad_norm.sqrt()\n            loss = loss + grad_norm\n\n        # Applies scaling to the backward call as usual.\n        # Accumulates leaf gradients that are correctly scaled.\n        scaler.scale(loss).backward()\n\n        # may unscale_ here if desired (e.g., to allow clipping unscaled gradients)\n\n        # step() and update() proceed as usual.\n        scaler.step(optimizer)\n        scaler.update()\n\n```\n\n\n## Working with Multiple Models, Losses, and Optimizers#\n\nIf your network has multiple losses, you must callscaler.scaleon each of them individually.\nIf your network has multiple optimizers, you may callscaler.unscale_on any of them individually,\nand you must callscaler.stepon each of them individually.\nscaler.scale\nscaler.unscale_\nscaler.step\nHowever,scaler.updateshould only be called once,\nafter all optimizers used this iteration have been stepped:\nscaler.update\n\n```python\nscaler = torch.amp.GradScaler()\n\nfor epoch in epochs:\n    for input, target in data:\n        optimizer0.zero_grad()\n        optimizer1.zero_grad()\n        with autocast(device_type='cuda', dtype=torch.float16):\n            output0 = model0(input)\n            output1 = model1(input)\n            loss0 = loss_fn(2 * output0 + 3 * output1, target)\n            loss1 = loss_fn(3 * output0 - 5 * output1, target)\n\n        # (retain_graph here is unrelated to amp, it's present because in this\n        # example, both backward() calls share some sections of graph.)\n        scaler.scale(loss0).backward(retain_graph=True)\n        scaler.scale(loss1).backward()\n\n        # You can choose which optimizers receive explicit unscaling, if you\n        # want to inspect or modify the gradients of the params they own.\n        scaler.unscale_(optimizer0)\n\n        scaler.step(optimizer0)\n        scaler.step(optimizer1)\n\n        scaler.update()\n\n```\n\nEach optimizer checks its gradients for infs/NaNs and makes an independent decision\nwhether or not to skip the step.  This may result in one optimizer skipping the step\nwhile the other one does not.  Since step skipping occurs rarely (every several hundred iterations)\nthis should not impede convergence.  If you observe poor convergence after adding gradient scaling\nto a multiple-optimizer model, please report a bug.\n\n## Working with Multiple GPUs#\n\nThe issues described here only affectautocast.GradScaler\u2018s usage is unchanged.\nautocast\nGradScaler\n\n## DataParallel in a single process#\n\nEven iftorch.nn.DataParallelspawns threads to run the forward pass on each device.\nThe autocast state is propagated in each one and the following will work:\ntorch.nn.DataParallel\n\n```python\nmodel = MyModel()\ndp_model = nn.DataParallel(model)\n\n# Sets autocast in the main thread\nwith autocast(device_type='cuda', dtype=torch.float16):\n    # dp_model's internal threads will autocast.\n    output = dp_model(input)\n    # loss_fn also autocast\n    loss = loss_fn(output)\n\n```\n\n\n## DistributedDataParallel, one GPU per process#\n\ntorch.nn.parallel.DistributedDataParallel\u2019s documentation recommends one GPU per process for best\nperformance.  In this case,DistributedDataParalleldoes not spawn threads internally,\nso usages ofautocastandGradScalerare not affected.\ntorch.nn.parallel.DistributedDataParallel\nDistributedDataParallel\nautocast\nGradScaler\n\n## DistributedDataParallel, multiple GPUs per process#\n\nHeretorch.nn.parallel.DistributedDataParallelmay spawn a side thread to run the forward pass on each\ndevice, liketorch.nn.DataParallel.The fix is the same:\napply autocast as part of your model\u2019sforwardmethod to ensure it\u2019s enabled in side threads.\ntorch.nn.parallel.DistributedDataParallel\ntorch.nn.DataParallel\nforward\n\n## Autocast and Custom Autograd Functions#\n\nIf your network usescustom autograd functions(subclasses oftorch.autograd.Function), changes are required for\nautocast compatibility if any function\ntorch.autograd.Function\ntakes multiple floating-point Tensor inputs,\nwraps any autocastable op (see theAutocast Op Reference), or\nrequires a particulardtype(for example, if it wrapsCUDA extensionsthat were only compiled fordtype).\ndtype\ndtype\nIn all cases, if you\u2019re importing the function and can\u2019t alter its definition, a safe fallback\nis to disable autocast and force execution infloat32( ordtype) at any points of use where errors occur:\nfloat32\ndtype\n\n```python\nwith autocast(device_type='cuda', dtype=torch.float16):\n    ...\n    with autocast(device_type='cuda', dtype=torch.float16, enabled=False):\n        output = imported_function(input1.float(), input2.float())\n\n```\n\nIf you\u2019re the function\u2019s author (or can alter its definition) a better solution is to use thetorch.amp.custom_fwd()andtorch.amp.custom_bwd()decorators as shown in\nthe relevant case below.\ntorch.amp.custom_fwd()\ntorch.amp.custom_bwd()\n\n## Functions with multiple inputs or autocastable ops#\n\nApplycustom_fwdandcustom_bwd(with no arguments) toforwardandbackwardrespectively.  These ensureforwardexecutes with the current autocast state andbackwardexecutes with the same autocast state asforward(which can prevent type mismatch errors):\ncustom_fwd\ncustom_bwd\nforward\nbackward\nforward\nbackward\nforward\n\n```python\nclass MyMM(torch.autograd.Function):\n    @staticmethod\n    @custom_fwd\n    def forward(ctx, a, b):\n        ctx.save_for_backward(a, b)\n        return a.mm(b)\n    @staticmethod\n    @custom_bwd\n    def backward(ctx, grad):\n        a, b = ctx.saved_tensors\n        return grad.mm(b.t()), a.t().mm(grad)\n\n```\n\nNowMyMMcan be invoked anywhere, without disabling autocast or manually casting inputs:\nMyMM\n\n```python\nmymm = MyMM.apply\n\nwith autocast(device_type='cuda', dtype=torch.float16):\n    output = mymm(input1, input2)\n\n```\n\n\n## Functions that need a particulardtype#\n\ndtype\nConsider a custom function that requirestorch.float32inputs.\nApplycustom_fwd(device_type='cuda',cast_inputs=torch.float32)toforwardandcustom_bwd(device_type='cuda')tobackward.\nIfforwardruns in an autocast-enabled region, the decorators cast floating-point Tensor\ninputs tofloat32on designated device assigned by the argumentdevice_type,CUDAin this example, and locally disable autocast duringforwardandbackward:\ntorch.float32\ncustom_fwd(device_type='cuda',cast_inputs=torch.float32)\nforward\ncustom_bwd(device_type='cuda')\nbackward\nforward\nfloat32\nforward\nbackward\n\n```python\nclass MyFloat32Func(torch.autograd.Function):\n    @staticmethod\n    @custom_fwd(device_type='cuda', cast_inputs=torch.float32)\n    def forward(ctx, input):\n        ctx.save_for_backward(input)\n        ...\n        return fwd_output\n    @staticmethod\n    @custom_bwd(device_type='cuda')\n    def backward(ctx, grad):\n        ...\n\n```\n\nNowMyFloat32Funccan be invoked anywhere, without manually disabling autocast or casting inputs:\nMyFloat32Func\n\n```python\nfunc = MyFloat32Func.apply\n\nwith autocast(device_type='cuda', dtype=torch.float16):\n    # func will run in float32, regardless of the surrounding autocast state\n    output = func(input)\n\n```\n",
  "url": "https://pytorch.org/docs/stable/notes/amp_examples.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}