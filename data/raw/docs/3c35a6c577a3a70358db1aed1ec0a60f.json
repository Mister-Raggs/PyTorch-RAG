{
  "doc_id": "3c35a6c577a3a70358db1aed1ec0a60f",
  "source": "pytorch_docs",
  "title": "torch.package \u2014 PyTorch 2.9 documentation",
  "text": "\n## torch.package#\n\nCreated On: Jun 10, 2025 | Last Updated On: Jul 15, 2025\ntorch.packageadds support for creating packages containing both artifacts and arbitrary\nPyTorch code. These packages can be saved, shared, used to load and execute models\nat a later date or on a different machine, and can even be deployed to production usingtorch::deploy.\ntorch.package\ntorch::deploy\nThis document contains tutorials, how-to guides, explanations, and an API reference that\nwill help you learn more abouttorch.packageand how to use it.\ntorch.package\nWarning\nThis module depends on thepicklemodule which is not secure. Only unpackage data you trust.\npickle\nIt is possible to construct malicious pickle data which willexecute arbitrary code during unpickling.\nNever unpackage data that could have come from an untrusted source, or that could have been tampered with.\nFor more information, review thedocumentationfor thepicklemodule.\npickle\nTutorials\nPackaging your first model\nHow do I\u2026\nSee what is inside a package?\nSee why a given module was included as a dependency?\nInclude arbitrary resources with my package and access them later?\nCustomize how a class is packaged?\nTest in my source code whether or not it is executing inside a package?\nPatch code into a package?\nAccess package contents from packaged code?\nDistinguish between packaged code and non-packaged code?\nRe-export an imported object?\nExplanation\ntorch.packageFormat Overview\ntorch.package\nHowtorch.packagefinds your code\u2019s dependencies\ntorch.package\nDependency Management\ntorch.packagesharp edges\ntorch.package\nHowtorch.packagekeeps packages isolated from each other\ntorch.package\nAPI Reference\n\n## Tutorials#\n\n\n## Packaging your first model#\n\nA tutorial that guides you through packaging and unpackaging a simple model is availableon Colab.\nAfter completing this exercise, you will be familiar with the basic API for creating and using\nTorch packages.\n\n## How do I\u2026#\n\n\n## See what is inside a package?#\n\nThe container format for atorch.packageis ZIP, so any tools that work with standard ZIP files should\nwork for exploring the contents. Some common ways to interact with ZIP files:\ntorch.package\nunzipmy_package.ptwill unzip thetorch.packagearchive to disk, where you can freely inspect its contents.\nunzipmy_package.pt\ntorch.package\n\n```python\n$ unzip my_package.pt && tree my_package\nmy_package\n\u251c\u2500\u2500 .data\n\u2502   \u251c\u2500\u2500 94304870911616.storage\n\u2502   \u251c\u2500\u2500 94304900784016.storage\n\u2502   \u251c\u2500\u2500 extern_modules\n\u2502   \u2514\u2500\u2500 version\n\u251c\u2500\u2500 models\n\u2502   \u2514\u2500\u2500 model_1.pkl\n\u2514\u2500\u2500 torchvision\n    \u2514\u2500\u2500 models\n        \u251c\u2500\u2500 resnet.py\n        \u2514\u2500\u2500 utils.py\n~ cd my_package && cat torchvision/models/resnet.py\n...\n\n```\n\nThe Pythonzipfilemodule provides a standard way to read and write ZIP archive contents.\nzipfile\n\n```python\nfrom zipfile import ZipFile\nwith ZipFile(\"my_package.pt\") as myzip:\n    file_bytes = myzip.read(\"torchvision/models/resnet.py\")\n    # edit file_bytes in some way\n    myzip.writestr(\"torchvision/models/resnet.py\", new_file_bytes)\n\n```\n\nvim has the ability to natively read ZIP archives. You can even edit files and :writethem back into the archive!\nwrite\n\n```python\n# add this to your .vimrc to treat `*.pt` files as zip files\nau BufReadCmd *.pt call zip#Browse(expand(\"<amatch>\"))\n\n~ vi my_package.pt\n\n```\n\nfile_structure()\nPackageImporterprovides afile_structure()method, which will return a printable\nand queryableDirectoryobject. TheDirectoryobject is a simple directory structure that you can use to explore the\ncurrent contents of atorch.package.\nPackageImporter\nfile_structure()\nDirectory\nDirectory\ntorch.package\nTheDirectoryobject itself is directly printable and will print out a file tree representation. To filter what is returned,\nuse the glob-styleincludeandexcludefiltering arguments.\nDirectory\ninclude\nexclude\n\n```python\nwith PackageExporter('my_package.pt') as pe:\n    pe.save_pickle('models', 'model_1.pkl', mod)\n\nimporter = PackageImporter('my_package.pt')\n# can limit printed items with include/exclude args\nprint(importer.file_structure(include=[\"**/utils.py\", \"**/*.pkl\"], exclude=\"**/*.storage\"))\nprint(importer.file_structure()) # will print out all files\n\n```\n\nOutput:\n\n```python\n# filtered with glob pattern:\n#    include=[\"**/utils.py\", \"**/*.pkl\"], exclude=\"**/*.storage\"\n\u2500\u2500\u2500 my_package.pt\n    \u251c\u2500\u2500 models\n    \u2502   \u2514\u2500\u2500 model_1.pkl\n    \u2514\u2500\u2500 torchvision\n        \u2514\u2500\u2500 models\n            \u2514\u2500\u2500 utils.py\n\n# all files\n\u2500\u2500\u2500 my_package.pt\n    \u251c\u2500\u2500 .data\n    \u2502   \u251c\u2500\u2500 94304870911616.storage\n    \u2502   \u251c\u2500\u2500 94304900784016.storage\n    \u2502   \u251c\u2500\u2500 extern_modules\n    \u2502   \u2514\u2500\u2500 version\n    \u251c\u2500\u2500 models\n    \u2502   \u2514\u2500\u2500 model_1.pkl\n    \u2514\u2500\u2500 torchvision\n        \u2514\u2500\u2500 models\n            \u251c\u2500\u2500 resnet.py\n            \u2514\u2500\u2500 utils.py\n\n```\n\nYou can also queryDirectoryobjects with thehas_file()method.\nDirectory\nhas_file()\n\n```python\nimporter_file_structure = importer.file_structure()\nfound: bool = importer_file_structure.has_file(\"package_a/subpackage.py\")\n\n```\n\n\n## See why a given module was included as a dependency?#\n\nSay there is a given modulefoo, and you want to know why yourPackageExporteris pulling infooas a dependency.\nfoo\nPackageExporter\nfoo\nPackageExporter.get_rdeps()will return all modules that directly depend onfoo.\nPackageExporter.get_rdeps()\nfoo\nIf you would like to see how a given modulesrcdepends onfoo, thePackageExporter.all_paths()method will\nreturn a DOT-formatted graph showing all the dependency paths betweensrcandfoo.\nsrc\nfoo\nPackageExporter.all_paths()\nsrc\nfoo\nIf you would just like to see the whole dependency graph of your :class:PackageExporter, you can usePackageExporter.dependency_graph_string().\nPackageExporter\nPackageExporter.dependency_graph_string()\n\n## Include arbitrary resources with my package and access them later?#\n\nPackageExporterexposes three methods,save_pickle,save_textandsave_binarythat allow you to save\nPython objects, text, and binary data to a package.\nPackageExporter\nsave_pickle\nsave_text\nsave_binary\n\n```python\nwith torch.PackageExporter(\"package.pt\") as exporter:\n    # Pickles the object and saves to `my_resources/tensor.pkl` in the archive.\n    exporter.save_pickle(\"my_resources\", \"tensor.pkl\", torch.randn(4))\n    exporter.save_text(\"config_stuff\", \"words.txt\", \"a sample string\")\n    exporter.save_binary(\"raw_data\", \"binary\", my_bytes)\n\n\n```\n\nPackageImporterexposes complementary methods namedload_pickle,load_textandload_binarythat allow you to load\nPython objects, text and binary data from a package.\nPackageImporter\nload_pickle\nload_text\nload_binary\n\n```python\nimporter = torch.PackageImporter(\"package.pt\")\nmy_tensor = importer.load_pickle(\"my_resources\", \"tensor.pkl\")\ntext = importer.load_text(\"config_stuff\", \"words.txt\")\nbinary = importer.load_binary(\"raw_data\", \"binary\")\n\n```\n\n\n## Customize how a class is packaged?#\n\ntorch.packageallows for the customization of how classes are packaged. This behavior is accessed through defining the method__reduce_package__on a class and by defining a corresponding de-packaging function. This is similar to defining__reduce__for\nPython\u2019s normal pickling process.\ntorch.package\n__reduce_package__\n__reduce__\nSteps:\nDefine the method__reduce_package__(self,exporter:PackageExporter)on the target class. This method should do the work to save the class instance inside of the package, and should return a tuple of the corresponding de-packaging function with the arguments needed to invoke the de-packaging function. This method is called by thePackageExporterwhen it encounters an instance of the target class.\n__reduce_package__(self,exporter:PackageExporter)\nPackageExporter\nDefine a de-packaging function for the class. This de-packaging function should do the work to reconstruct and return an instance of the class. The function signature\u2019s first parameter should be aPackageImporterinstance, and the rest of the parameters are user defined.\nPackageImporter\n\n```python\n# foo.py [Example of customizing how class Foo is packaged]\nfrom torch.package import PackageExporter, PackageImporter\nimport time\n\n\nclass Foo:\n    def __init__(self, my_string: str):\n        super().__init__()\n        self.my_string = my_string\n        self.time_imported = 0\n        self.time_exported = 0\n\n    def __reduce_package__(self, exporter: PackageExporter):\n        \"\"\"\n        Called by ``torch.package.PackageExporter``'s Pickler's ``persistent_id`` when\n        saving an instance of this object. This method should do the work to save this\n        object inside of the ``torch.package`` archive.\n\n        Returns function w/ arguments to load the object from a\n        ``torch.package.PackageImporter``'s Pickler's ``persistent_load`` function.\n        \"\"\"\n\n        # use this pattern to ensure no naming conflicts with normal dependencies,\n        # anything saved under this module name shouldn't conflict with other\n        # items in the package\n        generated_module_name = f\"foo-generated._{exporter.get_unique_id()}\"\n        exporter.save_text(\n            generated_module_name,\n            \"foo.txt\",\n            self.my_string + \", with exporter modification!\",\n        )\n        time_exported = time.clock_gettime(1)\n\n        # returns de-packaging function w/ arguments to invoke with\n        return (unpackage_foo, (generated_module_name, time_exported,))\n\n\ndef unpackage_foo(\n    importer: PackageImporter, generated_module_name: str, time_exported: float\n) -> Foo:\n    \"\"\"\n    Called by ``torch.package.PackageImporter``'s Pickler's ``persistent_load`` function\n    when depickling a Foo object.\n    Performs work of loading and returning a Foo instance from a ``torch.package`` archive.\n    \"\"\"\n    time_imported = time.clock_gettime(1)\n    foo = Foo(importer.load_text(generated_module_name, \"foo.txt\"))\n    foo.time_imported = time_imported\n    foo.time_exported = time_exported\n    return foo\n\n\n```\n\n\n```python\n# example of saving instances of class Foo\n\nimport torch\nfrom torch.package import PackageImporter, PackageExporter\nimport foo\n\nfoo_1 = foo.Foo(\"foo_1 initial string\")\nfoo_2 = foo.Foo(\"foo_2 initial string\")\nwith PackageExporter('foo_package.pt') as pe:\n    # save as normal, no extra work necessary\n    pe.save_pickle('foo_collection', 'foo1.pkl', foo_1)\n    pe.save_pickle('foo_collection', 'foo2.pkl', foo_2)\n\npi = PackageImporter('foo_package.pt')\nprint(pi.file_structure())\nimported_foo = pi.load_pickle('foo_collection', 'foo1.pkl')\nprint(f\"foo_1 string: '{imported_foo.my_string}'\")\nprint(f\"foo_1 export time: {imported_foo.time_exported}\")\nprint(f\"foo_1 import time: {imported_foo.time_imported}\")\n\n```\n\n\n```python\n# output of running above script\n\u2500\u2500\u2500 foo_package\n    \u251c\u2500\u2500 foo-generated\n    \u2502   \u251c\u2500\u2500 _0\n    \u2502   \u2502   \u2514\u2500\u2500 foo.txt\n    \u2502   \u2514\u2500\u2500 _1\n    \u2502       \u2514\u2500\u2500 foo.txt\n    \u251c\u2500\u2500 foo_collection\n    \u2502   \u251c\u2500\u2500 foo1.pkl\n    \u2502   \u2514\u2500\u2500 foo2.pkl\n    \u2514\u2500\u2500 foo.py\n\nfoo_1 string: 'foo_1 initial string, with reduction modification!'\nfoo_1 export time: 9857706.650140837\nfoo_1 import time: 9857706.652698385\n\n```\n\n\n## Test in my source code whether or not it is executing inside a package?#\n\nAPackageImporterwill add the attribute__torch_package__to every module that it initializes. Your code can check for the\npresence of this attribute to determine whether it is executing in a packaged context or not.\nPackageImporter\n__torch_package__\n\n```python\n# In foo/bar.py:\n\nif \"__torch_package__\" in dir():  # true if the code is being loaded from a package\n    def is_in_package():\n        return True\n\n    UserException = Exception\nelse:\n    def is_in_package():\n        return False\n\n    UserException = UnpackageableException\n\n```\n\nNow, the code will behave differently depending on whether it\u2019s imported normally through your Python environment or imported from atorch.package.\ntorch.package\n\n```python\nfrom foo.bar import is_in_package\n\nprint(is_in_package())  # False\n\nloaded_module = PackageImporter(my_package).import_module(\"foo.bar\")\nloaded_module.is_in_package()  # True\n\n```\n\nWarning: in general, it\u2019s bad practice to have code that behaves differently depending on whether it\u2019s packaged or not. This can lead to\nhard-to-debug issues that are sensitive to how you imported your code. If your package is intended to be heavily used, consider restructuring\nyour code so that it behaves the same way no matter how it was loaded.\n\n## Patch code into a package?#\n\nPackageExporteroffers asave_source_string()method that allows one to save arbitrary Python source code to a module of your choosing.\nPackageExporter\nsave_source_string()\n\n```python\nwith PackageExporter(f) as exporter:\n    # Save the my_module.foo available in your current Python environment.\n    exporter.save_module(\"my_module.foo\")\n\n    # This saves the provided string to my_module/foo.py in the package archive.\n    # It will override the my_module.foo that was previously saved.\n    exporter.save_source_string(\"my_module.foo\", textwrap.dedent(\n        \"\"\"\\\n        def my_function():\n            print('hello world')\n        \"\"\"\n    ))\n\n    # If you want to treat my_module.bar as a package\n    # (e.g. save to `my_module/bar/__init__.py` instead of `my_module/bar.py)\n    # pass is_package=True,\n    exporter.save_source_string(\"my_module.bar\",\n                                \"def foo(): print('hello')\\n\",\n                                is_package=True)\n\nimporter = PackageImporter(f)\nimporter.import_module(\"my_module.foo\").my_function()  # prints 'hello world'\n\n```\n\n\n## Access package contents from packaged code?#\n\nPackageImporterimplements theimportlib.resourcesAPI for accessing resources from inside a package.\nPackageImporter\nimportlib.resources\n\n```python\nwith PackageExporter(f) as exporter:\n    # saves text to my_resource/a.txt in the archive\n    exporter.save_text(\"my_resource\", \"a.txt\", \"hello world!\")\n    # saves the tensor to my_pickle/obj.pkl\n    exporter.save_pickle(\"my_pickle\", \"obj.pkl\", torch.ones(2, 2))\n\n    # see below for module contents\n    exporter.save_module(\"foo\")\n    exporter.save_module(\"bar\")\n\n```\n\nTheimportlib.resourcesAPI allows access to resources from within packaged code.\nimportlib.resources\n\n```python\n# foo.py:\nimport importlib.resources\nimport my_resource\n\n# returns \"hello world!\"\ndef get_my_resource():\n    return importlib.resources.read_text(my_resource, \"a.txt\")\n\n```\n\nUsingimportlib.resourcesis the recommended way to access package contents from within packaged code, since it complies\nwith the Python standard. However, it is also possible to access the parent :class:PackageImporterinstance itself from within\npackaged code.\nimportlib.resources\nPackageImporter\n\n```python\n# bar.py:\nimport torch_package_importer # this is the PackageImporter that imported this module.\n\n# Prints \"hello world!\", equivalent to importlib.resources.read_text\ndef get_my_resource():\n    return torch_package_importer.load_text(\"my_resource\", \"a.txt\")\n\n# You also do things that the importlib.resources API does not support, like loading\n# a pickled object from the package.\ndef get_my_pickle():\n    return torch_package_importer.load_pickle(\"my_pickle\", \"obj.pkl\")\n\n```\n\n\n## Distinguish between packaged code and non-packaged code?#\n\nTo tell if an object\u2019s code is from atorch.package, use thetorch.package.is_from_package()function.\nNote: if an object is from a package but its definition is from a module markedexternor fromstdlib,\nthis check will returnFalse.\ntorch.package\ntorch.package.is_from_package()\nextern\nstdlib\nFalse\n\n```python\nimporter = PackageImporter(f)\nmod = importer.import_module('foo')\nobj = importer.load_pickle('model', 'model.pkl')\ntxt = importer.load_text('text', 'my_test.txt')\n\nassert is_from_package(mod)\nassert is_from_package(obj)\nassert not is_from_package(txt) # str is from stdlib, so this will return False\n\n```\n\n\n## Re-export an imported object?#\n\nTo re-export an object that was previously imported by aPackageImporter, you must make the newPackageExporteraware of the originalPackageImporterso that it can find source code for your object\u2019s dependencies.\nPackageImporter\nPackageExporter\nPackageImporter\n\n```python\nimporter = PackageImporter(f)\nobj = importer.load_pickle(\"model\", \"model.pkl\")\n\n# re-export obj in a new package\nwith PackageExporter(f2, importer=(importer, sys_importer)) as exporter:\n    exporter.save_pickle(\"model\", \"model.pkl\", obj)\n\n```\n\n\n## Explanation#\n\n\n## torch.packageFormat Overview#\n\ntorch.package\nAtorch.packagefile is a ZIP archive which conventionally uses the.ptextension. Inside the ZIP archive, there are two kinds of files:\ntorch.package\n.pt\nFramework files, which are placed in the.data/.\n.data/\nUser files, which is everything else.\nAs an example, this is what a fully packaged ResNet model fromtorchvisionlooks like:\ntorchvision\n\n```python\nresnet\n\u251c\u2500\u2500 .data  # All framework-specific data is stored here.\n\u2502   \u2502      # It's named to avoid conflicts with user-serialized code.\n\u2502   \u251c\u2500\u2500 94286146172688.storage  # tensor data\n\u2502   \u251c\u2500\u2500 94286146172784.storage\n\u2502   \u251c\u2500\u2500 extern_modules  # text file with names of extern modules (e.g. 'torch')\n\u2502   \u251c\u2500\u2500 version         # version metadata\n\u2502   \u251c\u2500\u2500 ...\n\u251c\u2500\u2500 model  # the pickled model\n\u2502   \u2514\u2500\u2500 model.pkl\n\u2514\u2500\u2500 torchvision  # all code dependencies are captured as source files\n    \u2514\u2500\u2500 models\n        \u251c\u2500\u2500 resnet.py\n        \u2514\u2500\u2500 utils.py\n\n```\n\nThe.data/directory is owned by torch.package, and its contents are considered to be a private implementation detail.\nThetorch.packageformat makes no guarantees about the contents of.data/, but any changes made will be backward compatible\n(that is, newer version of PyTorch will always be able to load oldertorch.packages).\n.data/\ntorch.package\n.data/\ntorch.packages\nCurrently, the.data/directory contains the following items:\n.data/\nversion: a version number for the serialized format, so that thetorch.packageimport infrastructures knows how to load this package.\nversion\ntorch.package\nextern_modules: a list of modules that are consideredextern.externmodules will be imported using the loading environment\u2019s system importer.\nextern_modules\nextern\nextern\n*.storage: serialized tensor data.\n*.storage\n\n```python\n.data\n\u251c\u2500\u2500 94286146172688.storage\n\u251c\u2500\u2500 94286146172784.storage\n\u251c\u2500\u2500 extern_modules\n\u251c\u2500\u2500 version\n\u251c\u2500\u2500 ...\n\n```\n\nAll other files in the archive were put there by a user. The layout is identical to a Pythonregular package. For a deeper dive in how Python packaging works,\nplease consultthis essay(it\u2019s slightly out of date, so double-check implementation details\nwith thePython reference documentation.\n\n```python\n<package root>\n\u251c\u2500\u2500 model  # the pickled model\n\u2502   \u2514\u2500\u2500 model.pkl\n\u251c\u2500\u2500 another_package\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 foo.txt         # a resource file , see importlib.resources\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 torchvision\n    \u2514\u2500\u2500 models\n        \u251c\u2500\u2500 resnet.py   # torchvision.models.resnet\n        \u2514\u2500\u2500 utils.py    # torchvision.models.utils\n\n```\n\n\n## Howtorch.packagefinds your code\u2019s dependencies#\n\ntorch.package\nWhen you issue asave_pickle(obj,...)call,PackageExporterwill pickle the object normally. Then, it uses thepickletoolsstandard library module to parse the pickle bytecode.\nsave_pickle(obj,...)\nPackageExporter\npickletools\nIn a pickle, an object is saved along with aGLOBALopcode that describes where to find the implementation of the object\u2019s type, like:\nGLOBAL\n\n```python\nGLOBAL 'torchvision.models.resnet Resnet`\n\n```\n\nThe dependency resolver will gather up allGLOBALops and mark them as dependencies of your pickled object.\nFor more information about pickling and the pickle format, please consultthe Python docs.\nGLOBAL\nWhen a Python module is identified as a dependency,torch.packagewalks the module\u2019s python AST representation and looks for import statements with\nfull support for the standard forms:fromximporty,importz,fromwimportvasu, etc. When one of these import statements are\nencountered,torch.packageregisters the imported modules as dependencies that are then themselves parsed in the same AST walking way.\ntorch.package\nfromximporty\nimportz\nfromwimportvasu\ntorch.package\nNote: AST parsing has limited support for the__import__(...)syntax and does not supportimportlib.import_modulecalls. In general, you should\nnot expect dynamic imports to be detected bytorch.package.\n__import__(...)\nimportlib.import_module\ntorch.package\n\n## Dependency Management#\n\ntorch.packageautomatically finds the Python modules that your code and objects depend on. This process is called dependency resolution.\nFor each module that the dependency resolver finds, you must specify anactionto take.\ntorch.package\nThe allowed actions are:\nintern: put this module into the package.\nintern\nextern: declare this module as an external dependency of the package.\nextern\nmock: stub out this module.\nmock\ndeny: depending on this module will raise an error during package export.\ndeny\nFinally, there is one more important action that is not technically part oftorch.package:\ntorch.package\nRefactoring: remove or change the dependencies in your code.\nNote that actions are only defined on entire Python modules. There is no way to package \u201cjust\u201d a function or class from a module and leave the rest out.\nThis is by design. Python does not offer clean boundaries between objects defined in a module. The only defined unit of dependency organization is a\nmodule, so that\u2019s whattorch.packageuses.\ntorch.package\nActions are applied to modules using patterns. Patterns can either be module names (\"foo.bar\") or globs (like\"foo.**\"). You associate a pattern\nwith an action using methods onPackageExporter, e.g.\n\"foo.bar\"\n\"foo.**\"\nPackageExporter\n\n```python\nmy_exporter.intern(\"torchvision.**\")\nmy_exporter.extern(\"numpy\")\n\n```\n\nIf a module matches a pattern, the corresponding action is applied to it. For a given module, patterns will be checked in the order that they were defined,\nand the first action will be taken.\nintern\nIf a module isintern-ed, it will be placed into the package.\nintern\nThis action is your model code, or any related code you want to package. For example, if you are trying to package a ResNet fromtorchvision,\nyou will need tointernthe module torchvision.models.resnet.\ntorchvision\nintern\nOn package import, when your packaged code tries to import anintern-ed module, PackageImporter will look inside your package for that module.\nIf it can\u2019t find that module, an error will be raised. This ensures that eachPackageImporteris isolated from the loading environment\u2014even\nif you havemy_interned_moduleavailable in both your package and the loading environment,PackageImporterwill only use the version in your\npackage.\nintern\nPackageImporter\nmy_interned_module\nPackageImporter\nNote: Only Python source modules can beintern-ed. Other kinds of modules, like C extension modules and bytecode modules, will raise an error if\nyou attempt tointernthem. These kinds of modules need to bemock-ed orextern-ed.\nintern\nintern\nmock\nextern\nextern\nIf a module isextern-ed, it will not be packaged. Instead, it will be added to a list of external dependencies for this package. You can find this\nlist onpackage_exporter.extern_modules.\nextern\npackage_exporter.extern_modules\nOn package import, when the packaged code tries to import anextern-ed module,PackageImporterwill use the default Python importer to find\nthat module, as if you didimportlib.import_module(\"my_externed_module\"). If it can\u2019t find that module, an error will be raised.\nextern\nPackageImporter\nimportlib.import_module(\"my_externed_module\")\nIn this way, you can depend on third-party libraries likenumpyandscipyfrom within your package without having to package them too.\nnumpy\nscipy\nWarning: If any external library changes in a backwards-incompatible way, your package may fail to load. If you need long-term reproducibility\nfor your package, try to limit your use ofextern.\nextern\nmock\nIf a module ismock-ed, it will not be packaged. Instead a stub module will be packaged in its place. The stub module will allow you to retrieve\nobjects from it (so thatfrommy_mocked_moduleimportfoowill not error), but any use of that object will raise aNotImplementedError.\nmock\nfrommy_mocked_moduleimportfoo\nNotImplementedError\nmockshould be used for code that you \u201cknow\u201d will not be needed in the loaded package, but you still want available for use in non-packaged contents.\nFor example, initialization/configuration code, or code only used for debugging/training.\nmock\nWarning: In general,mockshould be used as a last resort. It introduces behavioral differences between packaged code and non-packaged code,\nwhich may lead to later confusion. Prefer instead to refactor your code to remove unwanted dependencies.\nmock\nThe best way to manage dependencies is to not have dependencies at all! Often, code can be refactored to remove unnecessary dependencies. Here are some\nguidelines for writing code with clean dependencies (which are also generally good practices!):\nInclude only what you use. Do not leave unused imports in your code. The dependency resolver is not smart enough to tell that they are indeed unused,\nand will try to process them.\nQualify your imports. For example, instead of writing import foo and later usingfoo.bar.baz, prefer to writefromfoo.barimportbaz. This more\nprecisely specifies your real dependency (foo.bar) and lets the dependency resolver know you don\u2019t need all offoo.\nfoo.bar.baz\nfromfoo.barimportbaz\nfoo.bar\nfoo\nSplit up large files with unrelated functionality into smaller ones. If yourutilsmodule contains a hodge-podge of unrelated functionality, any module\nthat depends onutilswill need to pull in lots of unrelated dependencies, even if you only needed a small part of it. Prefer instead to define\nsingle-purpose modules that can be packaged independently of one another.\nutils\nutils\nPatterns allow you to specify groups of modules with a convenient syntax. The syntax and behavior of patterns follows the Bazel/Buckglob().\nA module that we are trying to match against a pattern is called a candidate. A candidate is composed of a list of segments separated by a\nseparator string, e.g.foo.bar.baz.\nfoo.bar.baz\nA pattern contains one or more segments. Segments can be:\nA literal string (e.g.foo), which matches exactly.\nfoo\nA string containing a wildcard (e.g.torch, orfoo*baz*). The wildcard matches any string, including the empty string.\ntorch\nfoo*baz*\nA double wildcard (**). This matches against zero or more complete segments.\n**\nExamples:\ntorch.**: matchestorchand all its submodules, e.g.torch.nnandtorch.nn.functional.\ntorch.**\ntorch\ntorch.nn\ntorch.nn.functional\ntorch.*: matchestorch.nnortorch.functional, but nottorch.nn.functionalortorch\ntorch.*\ntorch.nn\ntorch.functional\ntorch.nn.functional\ntorch\ntorch*.**: matchestorch,torchvision, and all of their submodules\ntorch*.**\ntorch\ntorchvision\nWhen specifying actions, you can pass multiple patterns, e.g.\n\n```python\nexporter.intern([\"torchvision.models.**\", \"torchvision.utils.**\"])\n\n```\n\nA module will match against this action if it matches any of the patterns.\nYou can also specify patterns to exclude, e.g.\n\n```python\nexporter.mock(\"**\", exclude=[\"torchvision.**\"])\n\n```\n\nA module will not match against this action if it matches any of the exclude patterns. In this example, we are mocking all modules excepttorchvisionand its submodules.\ntorchvision\nWhen a module could potentially match against multiple actions, the first action defined will be taken.\n\n## torch.packagesharp edges#\n\ntorch.package\nPython makes it really easy to bind objects and run code at module-level scope. This is generally fine\u2014after all, functions and classes are bound to\nnames this way. However, things become more complicated when you define an object at module scope with the intention of mutating it, introducing mutable\nglobal state.\nMutable global state is quite useful\u2014it can reduce boilerplate, allow for open registration into tables, etc. But unless employed very carefully, it can\ncause complications when used withtorch.package.\ntorch.package\nEveryPackageImportercreates an independent environment for its contents. This is nice because it means we load multiple packages and ensure\nthey are isolated from each other, but when modules are written in a way that assumes shared mutable global state, this behavior can create hard-to-debug\nerrors.\nPackageImporter\nAny class that you import from aPackageImporterwill be a version of the class specific to that importer. For example:\nPackageImporter\n\n```python\nfrom foo import MyClass\n\nmy_class_instance = MyClass()\n\nwith PackageExporter(f) as exporter:\n    exporter.save_module(\"foo\")\n\nimporter = PackageImporter(f)\nimported_MyClass = importer.import_module(\"foo\").MyClass\n\nassert isinstance(my_class_instance, MyClass)  # works\nassert isinstance(my_class_instance, imported_MyClass)  # ERROR!\n\n```\n\nIn this example,MyClassandimported_MyClassarenot the same type. In this specific example,MyClassandimported_MyClasshave exactly the\nsame implementation, so you might think it\u2019s okay to consider them the same class. But consider the situation whereimported_MyClassis coming from an\nolder package with an entirely different implementation ofMyClass\u2014 in that case, it\u2019s unsafe to consider them the same class.\nMyClass\nimported_MyClass\nMyClass\nimported_MyClass\nimported_MyClass\nMyClass\nUnder the hood, each importer has a prefix that allows it to uniquely identify classes:\n\n```python\nprint(MyClass.__name__)  # prints \"foo.MyClass\"\nprint(imported_MyClass.__name__)  # prints <torch_package_0>.foo.MyClass\n\n```\n\nThat means you should not expectisinstancechecks to work when one of the arguments is from a package and the other is not. If you need this\nfunctionality, consider the following options:\nisinstance\nDoing duck typing (just using the class instead of explicitly checking that it is of a given type).\nMake the typing relationship an explicit part of the class contract. For example, you can add an attribute tagself.handler=\"handle_me_this_way\"and have client code check for the value ofhandlerinstead of checking the type directly.\nself.handler=\"handle_me_this_way\"\nhandler\n\n## Howtorch.packagekeeps packages isolated from each other#\n\ntorch.package\nEachPackageImporterinstance creates an independent, isolated environment for its modules and objects. Modules in a package can only import\nother packaged modules, or modules markedextern. If you use multiplePackageImporterinstances to load a single package, you will get\nmultiple independent environments that do not interact.\nPackageImporter\nextern\nPackageImporter\nThis is achieved by extending Python\u2019s import infrastructure with a custom importer.PackageImporterprovides the same core API as theimportlibimporter; namely, it implements theimport_moduleand__import__methods.\nPackageImporter\nimportlib\nimport_module\n__import__\nWhen you invokePackageImporter.import_module(),PackageImporterwill construct and return a new module, much as the system importer does.\nHowever,PackageImporterpatches the returned module to useself(i.e. thatPackageImporterinstance) to fulfill future import\nrequests by looking in the package rather than searching the user\u2019s Python environment.\nPackageImporter.import_module()\nPackageImporter\nPackageImporter\nself\nPackageImporter\nTo avoid confusion (\u201cis thisfoo.barobject the one from my package, or the one from my Python environment?\u201d),PackageImportermangles the__name__and__file__of all imported modules, by adding amangle prefixto them.\nfoo.bar\nPackageImporter\n__name__\n__file__\nFor__name__, a name liketorchvision.models.resnet18becomes<torch_package_0>.torchvision.models.resnet18.\n__name__\ntorchvision.models.resnet18\n<torch_package_0>.torchvision.models.resnet18\nFor__file__, a name liketorchvision/models/resnet18.pybecomes<torch_package_0>.torchvision/modules/resnet18.py.\n__file__\ntorchvision/models/resnet18.py\n<torch_package_0>.torchvision/modules/resnet18.py\nName mangling helps avoid inadvertent punning of module names between different packages, and helps you debug by making stack traces and print\nstatements more clearly show whether they are referring to packaged code or not. For developer-facing details about mangling, consultmangling.mdintorch/package/.\nmangling.md\ntorch/package/\n\n## API Reference#\n\nThis exception is raised when there is an issue with exporting a package.PackageExporterwill attempt to gather up all the errors and present\nthem to you at once.\nPackageExporter\nThis is an exception that is thrown when a mock or extern is marked asallow_empty=False, and is not matched with any module during packaging.\nallow_empty=False\nExporters allow you to write packages of code, pickled Python data, and\narbitrary binary and text resources into a self-contained package.\nImports can load this code in a hermetic way, such that code is loaded\nfrom the package rather than the normal Python import system. This allows\nfor the packaging of PyTorch model code and data so that it can be run\non a server or used in the future for transfer learning.\nThe code contained in packages is copied file-by-file from the original\nsource when it is created, and the file format is a specially organized\nzip file. Future users of the package can unzip the package, and edit the code\nin order to perform custom modifications to it.\nThe importer for packages ensures that code in the module can only be loaded from\nwithin the package, except for modules explicitly listed as external usingextern().\nThe fileextern_modulesin the zip archive lists all the modules that a package externally depends on.\nThis prevents \u201cimplicit\u201d dependencies where the package runs locally because it is importing\na locally-installed package, but then fails when the package is copied to another machine.\nextern()\nextern_modules\nWhen source code is added to the package, the exporter can optionally scan it\nfor further code dependencies (dependencies=True). It looks for import statements,\nresolves relative references to qualified module names, and performs an action specified by the user\n(See:extern(),mock(), andintern()).\ndependencies=True\nextern()\nmock()\nintern()\nCreate an exporter.\nf(Union[str,PathLike[str],IO[bytes]]) \u2013 The location to export to. Can be astring/Pathobject containing a filename\nor a binary I/O object.\nstring\nPath\nimporter(Union[Importer,Sequence[Importer]]) \u2013 If a single Importer is passed, use that to search for modules.\nIf a sequence of importers are passed, anOrderedImporterwill be constructed out of them.\nOrderedImporter\ndebug(bool) \u2013 If set to True, add path of broken modules to PackagingErrors.\nGiven a module, add it to the dependency graph according to patterns\nspecified by the user.\nthat has all paths from src to dst.\nA dot representation containing all paths from src to dst.\n(https://graphviz.org/doc/info/lang.html)\nstr\nWrite the package to the filesystem. Any calls afterclose()are now invalid.\nIt is preferable to use resource guard syntax instead:\nclose()\n\n```python\nwith PackageExporter(\"file.zip\") as e:\n    ...\n\n```\n\nReturn all modules that are currently denied.\nA list containing the names of modules which will be\ndenied in this package.\nlist[str]\nBlocklist modules who names match the given glob patterns from the list of modules the package can import.\nIf a dependency on any matching packages is found, aPackagingErroris raised.\nPackagingError\ninclude(Union[List[str],str]) \u2013 A string e.g.\"my_package.my_subpackage\", or list of strings\nfor the names of the modules to be externed. This can also be a glob-style pattern, as described inmock().\n\"my_package.my_subpackage\"\nmock()\nexclude(Union[List[str],str]) \u2013 An optional pattern that excludes some patterns that match the include string.\nReturns digraph string representation of dependencies in package.\nA string representation of dependencies in package.\nstr\nIncludemodulein the list of external modules the package can import.\nThis will prevent dependency discovery from saving\nit in the package. The importer will load an external module directly from the standard import system.\nCode for extern modules must also exist in the process loading the package.\nmodule\ninclude(Union[List[str],str]) \u2013 A string e.g.\"my_package.my_subpackage\", or list of strings\nfor the names of the modules to be externed. This can also be a glob-style pattern, as\ndescribed inmock().\n\"my_package.my_subpackage\"\nmock()\nexclude(Union[List[str],str]) \u2013 An optional pattern that excludes some patterns that match the\ninclude string.\nallow_empty(bool) \u2013 An optional flag that specifies whether the extern modules specified by this call\nto theexternmethod must be matched to some module during packaging. If an extern module glob\npattern is added withallow_empty=False, andclose()is called (either explicitly or via__exit__) before any modules match that pattern, an exception is thrown. Ifallow_empty=True,\nno such exception is thrown.\nextern\nallow_empty=False\nclose()\n__exit__\nallow_empty=True\nReturn all modules that are currently externed.\nA list containing the names of modules which will be\nexterned in this package.\nlist[str]\nReturn a list of all modules which depend on the modulemodule_name.\nmodule_name\nA list containing the names of modules which depend onmodule_name.\nmodule_name\nlist[str]\nGet an id. This id is guaranteed to only be handed out once for this package.\nstr\nSpecify modules that should be packaged. A module must match someinternpattern in order to be\nincluded in the package and have its dependencies processed recursively.\nintern\ninclude(Union[List[str],str]) \u2013 A string e.g. \u201cmy_package.my_subpackage\u201d, or list of strings\nfor the names of the modules to be externed. This can also be a glob-style pattern, as described inmock().\nmock()\nexclude(Union[List[str],str]) \u2013 An optional pattern that excludes some patterns that match the include string.\nallow_empty(bool) \u2013 An optional flag that specifies whether the intern modules specified by this call\nto theinternmethod must be matched to some module during packaging. If aninternmodule glob\npattern is added withallow_empty=False, andclose()is called (either explicitly or via__exit__)\nbefore any modules match that pattern, an exception is thrown. Ifallow_empty=True, no such exception is thrown.\nintern\nintern\nallow_empty=False\nclose()\n__exit__\nallow_empty=True\nReturn all modules that are currently interned.\nA list containing the names of modules which will be\ninterned in this package.\nlist[str]\nReplace some required modules with a mock implementation.  Mocked modules will return a fake\nobject for any attribute accessed from it. Because we copy file-by-file, the dependency resolution will sometimes\nfind files that are imported by model files but whose functionality is never used\n(e.g. custom serialization code or training helpers).\nUse this function to mock this functionality out without having to modify the original code.\ninclude(Union[List[str],str]) \u2013A string e.g.\"my_package.my_subpackage\", or list of strings\nfor the names of the modules to be mocked out. Strings can also be a glob-style pattern\nstring that may match multiple modules. Any required dependencies that match this pattern\nstring will be mocked out automatically.Examples :'torch.**'\u2013 matchestorchand all submodules of torch, e.g.'torch.nn'and'torch.nn.functional''torch.*'\u2013 matches'torch.nn'or'torch.functional', but not'torch.nn.functional'\nA string e.g.\"my_package.my_subpackage\", or list of strings\nfor the names of the modules to be mocked out. Strings can also be a glob-style pattern\nstring that may match multiple modules. Any required dependencies that match this pattern\nstring will be mocked out automatically.\n\"my_package.my_subpackage\"\n'torch.**'\u2013 matchestorchand all submodules of torch, e.g.'torch.nn'and'torch.nn.functional'\n'torch.**'\ntorch\n'torch.nn'\n'torch.nn.functional'\n'torch.*'\u2013 matches'torch.nn'or'torch.functional', but not'torch.nn.functional'\n'torch.*'\n'torch.nn'\n'torch.functional'\n'torch.nn.functional'\nexclude(Union[List[str],str]) \u2013 An optional pattern that excludes some patterns that match the include string.\ne.g.include='torch.**',exclude='torch.foo'will mock all torch packages except'torch.foo',\nDefault: is[].\ninclude='torch.**',exclude='torch.foo'\n'torch.foo'\n[]\nallow_empty(bool) \u2013 An optional flag that specifies whether the mock implementation(s) specified by this call\nto themock()method must be matched to some module during packaging. If a mock is added withallow_empty=False, andclose()is called (either explicitly or via__exit__) and the mock has\nnot been matched to a module used by the package being exported, an exception is thrown.\nIfallow_empty=True, no such exception is thrown.\nmock()\nallow_empty=False\nclose()\n__exit__\nallow_empty=True\nReturn all modules that are currently mocked.\nA list containing the names of modules which will be\nmocked in this package.\nlist[str]\nRegisters an extern hook on the exporter.\nThe hook will be called each time a module matches against anextern()pattern.\nIt should have the following signature:\nextern()\n\n```python\nhook(exporter: PackageExporter, module_name: str) -> None\n\n```\n\nHooks will be called in order of registration.\nA handle that can be used to remove the added hook by callinghandle.remove().\nhandle.remove()\ntorch.utils.hooks.RemovableHandle\ntorch.utils.hooks.RemovableHandle\nRegisters an intern hook on the exporter.\nThe hook will be called each time a module matches against anintern()pattern.\nIt should have the following signature:\nintern()\n\n```python\nhook(exporter: PackageExporter, module_name: str) -> None\n\n```\n\nHooks will be called in order of registration.\nA handle that can be used to remove the added hook by callinghandle.remove().\nhandle.remove()\ntorch.utils.hooks.RemovableHandle\ntorch.utils.hooks.RemovableHandle\nRegisters a mock hook on the exporter.\nThe hook will be called each time a module matches against amock()pattern.\nIt should have the following signature:\nmock()\n\n```python\nhook(exporter: PackageExporter, module_name: str) -> None\n\n```\n\nHooks will be called in order of registration.\nA handle that can be used to remove the added hook by callinghandle.remove().\nhandle.remove()\ntorch.utils.hooks.RemovableHandle\ntorch.utils.hooks.RemovableHandle\nSave raw bytes to the package.\npackage(str) \u2013 The name of module package this resource should go it (e.g.\"my_package.my_subpackage\").\n\"my_package.my_subpackage\"\nresource(str) \u2013 A unique name for the resource, used to identify it to load.\nbinary(str) \u2013 The data to save.\nSave the code formoduleinto the package. Code for the module is resolved using theimporterspath to find the\nmodule object, and then using its__file__attribute to find the source code.\nmodule\nimporters\n__file__\nmodule_name(str) \u2013 e.g.my_package.my_subpackage, code will be saved to provide code\nfor this package.\nmy_package.my_subpackage\ndependencies(bool,optional) \u2013 IfTrue, we scan the source for dependencies.\nTrue\nSave a python object to the archive using pickle. Equivalent totorch.save()but saving into\nthe archive rather than a stand-alone file. Standard pickle does not save the code, only the objects.\nIfdependenciesis true, this method will also scan the pickled objects for which modules are required\nto reconstruct them and save the relevant code.\ntorch.save()\ndependencies\nTo be able to save an object wheretype(obj).__name__ismy_module.MyObject,my_module.MyObjectmust resolve to the class of the object according to theimporterorder. When saving objects that\nhave previously been packaged, the importer\u2019simport_modulemethod will need to be present in theimporterlist\nfor this to work.\ntype(obj).__name__\nmy_module.MyObject\nmy_module.MyObject\nimporter\nimport_module\nimporter\npackage(str) \u2013 The name of module package this resource should go in (e.g.\"my_package.my_subpackage\").\n\"my_package.my_subpackage\"\nresource(str) \u2013 A unique name for the resource, used to identify it to load.\nobj(Any) \u2013 The object to save, must be picklable.\ndependencies(bool,optional) \u2013 IfTrue, we scan the source for dependencies.\nTrue\nAdds the local file systemfile_or_directoryto the source package to provide the code\nformodule_name.\nfile_or_directory\nmodule_name\nmodule_name(str) \u2013 e.g.\"my_package.my_subpackage\", code will be saved to provide code for this package.\n\"my_package.my_subpackage\"\nfile_or_directory(str) \u2013 the path to a file or directory of code. When a directory, all python files in the directory\nare recursively copied usingsave_source_file(). If a file is named\"/__init__.py\"the code is treated\nas a package.\nsave_source_file()\n\"/__init__.py\"\ndependencies(bool,optional) \u2013 IfTrue, we scan the source for dependencies.\nTrue\nAddssrcas the source code formodule_namein the exported package.\nsrc\nmodule_name\nmodule_name(str) \u2013 e.g.my_package.my_subpackage, code will be saved to provide code for this package.\nmy_package.my_subpackage\nsrc(str) \u2013 The Python source code to save for this package.\nis_package(bool,optional) \u2013 IfTrue, this module is treated as a package. Packages are allowed to have submodules\n(e.g.my_package.my_subpackage.my_subsubpackage), and resources can be saved inside them. Defaults toFalse.\nTrue\nmy_package.my_subpackage.my_subsubpackage\nFalse\ndependencies(bool,optional) \u2013 IfTrue, we scan the source for dependencies.\nTrue\nSave text data to the package.\npackage(str) \u2013 The name of module package this resource should go it (e.g.\"my_package.my_subpackage\").\n\"my_package.my_subpackage\"\nresource(str) \u2013 A unique name for the resource, used to identify it to load.\ntext(str) \u2013 The contents to save.\nImporters allow you to load code written to packages byPackageExporter.\nCode is loaded in a hermetic way, using files from the package\nrather than the normal python import system. This allows\nfor the packaging of PyTorch model code and data so that it can be run\non a server or used in the future for transfer learning.\nPackageExporter\nThe importer for packages ensures that code in the module can only be loaded from\nwithin the package, except for modules explicitly listed as external during export.\nThe fileextern_modulesin the zip archive lists all the modules that a package externally depends on.\nThis prevents \u201cimplicit\u201d dependencies where the package runs locally because it is importing\na locally-installed package, but then fails when the package is copied to another machine.\nextern_modules\nOpenfile_or_bufferfor importing. This checks that the imported package only requires modules\nallowed bymodule_allowed\nfile_or_buffer\nmodule_allowed\nfile_or_buffer(Union[str,PathLike[str],IO[bytes],PyTorchFileReader]) \u2013 a file-like object (has to implementread(),readline(),tell(), andseek()),\na string, or anos.PathLikeobject containing a filename.\nread()\nreadline()\ntell()\nseek()\nos.PathLike\nmodule_allowed(Callable[[str],bool],optional) \u2013 A method to determine if a externally provided module\nshould be allowed. Can be used to ensure packages loaded do not depend on modules that the server\ndoes not support. Defaults to allowing anything.\nImportError\u2013 If the package will use a disallowed module.\nReturns a file structure representation of package\u2019s zipfile.\ninclude(Union[List[str],str]) \u2013 An optional string e.g.\"my_package.my_subpackage\", or optional list of strings\nfor the names of the files to be included in the zipfile representation. This can also be\na glob-style pattern, as described inPackageExporter.mock()\n\"my_package.my_subpackage\"\nPackageExporter.mock()\nexclude(Union[List[str],str]) \u2013 An optional pattern that excludes files whose name match the pattern.\nDirectory\nDirectory\nDirectory\nReturns internal identifier that torch.package uses to distinguishPackageImporterinstances.\nLooks like:\nPackageImporter\n\n```python\n<torch_package_0>\n\n```\n\nLoad a module from the package if it hasn\u2019t already been loaded, and then return\nthe module. Modules are loaded locally\nto the importer and will appear inself.modulesrather thansys.modules.\nself.modules\nsys.modules\nname(str) \u2013 Fully qualified name of the module to load.\npackage([type],optional) \u2013 Unused, but present to match the signature of importlib.import_module. Defaults toNone.\nNone\nThe (possibly already) loaded module.\ntypes.ModuleType\nLoad raw bytes.\npackage(str) \u2013 The name of module package (e.g.\"my_package.my_subpackage\").\n\"my_package.my_subpackage\"\nresource(str) \u2013 The unique name for the resource.\nThe loaded data.\nbytes\nUnpickles the resource from the package, loading any modules that are needed to construct the objects\nusingimport_module().\nimport_module()\npackage(str) \u2013 The name of module package (e.g.\"my_package.my_subpackage\").\n\"my_package.my_subpackage\"\nresource(str) \u2013 The unique name for the resource.\nmap_location\u2013 Passed totorch.loadto determine how tensors are mapped to devices. Defaults toNone.\nNone\nThe unpickled object.\nAny\nLoad a string.\npackage(str) \u2013 The name of module package (e.g.\"my_package.my_subpackage\").\n\"my_package.my_subpackage\"\nresource(str) \u2013 The unique name for the resource.\nencoding(str,optional) \u2013 Passed todecode. Defaults to'utf-8'.\ndecode\n'utf-8'\nerrors(str,optional) \u2013 Passed todecode. Defaults to'strict'.\ndecode\n'strict'\nThe loaded text.\nstr\nReturns the version of python that was used to create this package.\nNote: this function is experimental and not Forward Compatible. The plan is to move this into a lock\nfile later on.\nOptional[str]a python version e.g. 3.8.9 or None if no version was stored with this package\nOptional[str]\nA file structure representation. Organized as Directory nodes that have lists of\ntheir Directory children. Directories for a package are created by callingPackageImporter.file_structure().\nPackageImporter.file_structure()\nChecks if a file is present in aDirectory.\nDirectory\nfilename(str) \u2013 Path of file to search for.\nIf aDirectorycontains the specified file.\nDirectory\nbool",
  "url": "https://pytorch.org/docs/stable/package.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}