{
  "doc_id": "ee74c254fb9de1f2b2a510680c49f894",
  "source": "pytorch_docs",
  "title": "torch.futures \u2014 PyTorch 2.9 documentation",
  "text": "\n## torch.futures#\n\nCreated On: Jun 12, 2025 | Last Updated On: Jun 12, 2025\nThis package provides aFuturetype that encapsulates\nan asynchronous execution and a set of utility functions to simplify operations\nonFutureobjects. Currently, theFuturetype is primarily used by theDistributed RPC Framework.\nFuture\nFuture\nFuture\nWrapper around atorch._C.Futurewhich encapsulates an asynchronous\nexecution of a callable, e.g.rpc_async(). It\nalso exposes a set of APIs to add callback functions and set results.\ntorch._C.Future\nrpc_async()\nWarning\nGPU support is a beta feature, subject to changes.\nAppend the given callback function to thisFuture, which will be run\nwhen theFutureis completed.  Multiple callbacks can be added to\nthe sameFuture, but the order in which they will be executed cannot\nbe guaranteed. The callback must take one argument, which is the\nreference to thisFuture. The callback function can use thevalue()method to get the value. Note that if thisFutureis\nalready completed, the given callback will be run inline.\nFuture\nFuture\nFuture\nFuture\nvalue()\nFuture\nWe recommend that you use thethen()method as it provides a way\nto synchronize after your callback has completed.add_done_callbackcan be cheaper if your callback does not return anything. But boththen()andadd_done_callbackuse the same callback\nregistration API under the hood.\nthen()\nadd_done_callback\nthen()\nadd_done_callback\nWith respect to GPU tensors, this method behaves in the same way asthen().\nthen()\ncallback(Future) \u2013 aCallablethat takes in one argument,\nwhich is the reference to thisFuture.\nFuture\nCallable\nFuture\nNote\nNote that if the callback function throws, either\nthrough the original future being completed with an exception and\ncallingfut.wait(), or through other code in the callback,\nerror handling must be carefully taken care of. For example, if\nthis callback later completes additional futures, those futures are\nnot marked as completed with an error and the user is responsible\nfor handling completion/waiting on those futures independently.\nfut.wait()\nExample:\n\n```python\n>>> def callback(fut):\n...     print(\"This will run after the future has finished.\")\n...     print(fut.wait())\n>>> fut = torch.futures.Future()\n>>> fut.add_done_callback(callback)\n>>> fut.set_result(5)\nThis will run after the future has finished.\n5\n\n```\n\nReturnTrueif thisFutureis done. AFutureis done if it\nhas a result or an exception.\nTrue\nFuture\nFuture\nIf the value contains tensors that reside on GPUs,Future.done()will returnTrueeven if the asynchronous kernels that are\npopulating those tensors haven\u2019t yet completed running on the device,\nbecause at such stage the result is already usable, provided one\nperforms the appropriate synchronizations (seewait()).\nFuture.done()\nTrue\nwait()\nbool\nSet an exception for thisFuture, which will mark thisFutureas\ncompleted with an error and trigger all attached callbacks. Note that\nwhen calling wait()/value() on thisFuture, the exception set here\nwill be raised inline.\nFuture\nFuture\nFuture\nresult(BaseException) \u2013 the exception for thisFuture.\nFuture\nExample:\n\n```python\n>>> fut = torch.futures.Future()\n>>> fut.set_exception(ValueError(\"foo\"))\n>>> fut.wait()\nTraceback (most recent call last):\n...\nValueError: foo\n\n```\n\nSet the result for thisFuture, which will mark thisFutureas\ncompleted and trigger all attached callbacks. Note that aFuturecannot be marked completed twice.\nFuture\nFuture\nFuture\nIf the result contains tensors that reside on GPUs, this method can be\ncalled even if the asynchronous kernels that are populating those\ntensors haven\u2019t yet completed running on the device, provided that the\nstreams on which those kernels were enqueued are set as the current ones\nwhen this method is called. Put simply, it\u2019s safe to call this method\nimmediately after launching those kernels, without any additional\nsynchronization, as long as one doesn\u2019t change streams in between. This\nmethod will record events on all the relevant current streams and will\nuse them to ensure proper scheduling for all the consumers of thisFuture.\nFuture\nresult(object) \u2013 the result object of thisFuture.\nFuture\nExample:\n\n```python\n>>> import threading\n>>> import time\n>>> def slow_set_future(fut, value):\n...     time.sleep(0.5)\n...     fut.set_result(value)\n>>> fut = torch.futures.Future()\n>>> t = threading.Thread(\n...     target=slow_set_future,\n...     args=(fut, torch.ones(2) * 3)\n... )\n>>> t.start()\n>>> print(fut.wait())\ntensor([3., 3.])\n>>> t.join()\n\n```\n\nAppend the given callback function to thisFuture, which will be run\nwhen theFutureis completed.  Multiple callbacks can be added to\nthe sameFuture, but the order in which they will be executed cannot\nbe guaranteed (to enforce a certain order consider chaining:fut.then(cb1).then(cb2)). The callback must take one argument, which\nis the reference to thisFuture. The callback function can use thevalue()method to get the value. Note that if thisFutureis\nalready completed, the given callback will be run immediately inline.\nFuture\nFuture\nFuture\nfut.then(cb1).then(cb2)\nFuture\nvalue()\nFuture\nIf theFuture\u2019s value contains tensors that reside on GPUs, the\ncallback might be invoked while the async kernels that are populating\nthose tensors haven\u2019t yet finished executing on the device. However, the\ncallback will be invoked with some dedicated streams set as current\n(fetched from a global pool) which will be synchronized with those\nkernels. Hence any operation performed by the callback on these tensors\nwill be scheduled on the device after the kernels complete. In other\nwords, as long as the callback doesn\u2019t switch streams, it can safely\nmanipulate the result without any additional synchronization. This is\nsimilar to the non-blocking behavior ofwait().\nFuture\nwait()\nSimilarly, if the callback returns a value that contains tensors that\nreside on a GPU, it can do so even if the kernels that are producing\nthese tensors are still running on the device, as long as the callback\ndidn\u2019t change streams during its execution. If one wants to change\nstreams, one must be careful to re-synchronize them with the original\nstreams, that is, those that were current when the callback was invoked.\ncallback(Callable) \u2013 aCallablethat takes thisFutureas\nthe only argument.\nCallable\nCallable\nFuture\nA newFutureobject that holds the return value of thecallbackand will be marked as completed when the givencallbackfinishes.\nFuture\ncallback\ncallback\nFuture[S]\nNote\nNote that if the callback function throws, either\nthrough the original future being completed with an exception and\ncallingfut.wait(), or through other code in the callback, the\nfuture returned bythenwill be marked appropriately with the\nencountered error. However, if this callback later completes\nadditional futures, those futures are not marked as completed with\nan error and the user is responsible for handling completion/waiting\non those futures independently.\nfut.wait()\nthen\nExample:\n\n```python\n>>> def callback(fut):\n...     print(f\"RPC return value is {fut.wait()}.\")\n>>> fut = torch.futures.Future()\n>>> # The inserted callback will print the return value when\n>>> # receiving the response from \"worker1\"\n>>> cb_fut = fut.then(callback)\n>>> chain_cb_fut = cb_fut.then(\n...     lambda x : print(f\"Chained cb done. {x.wait()}\")\n... )\n>>> fut.set_result(5)\nRPC return value is 5.\nChained cb done. None\n\n```\n\nObtain the value of an already-completed future.\nThis method should only be called after a call towait()has\ncompleted, or inside a callback function passed tothen(). In\nother cases thisFuturemay not yet hold a value and callingvalue()could fail.\nwait()\nthen()\nFuture\nvalue()\nIf the value contains tensors that reside on GPUs, then this method willnotperform any additional synchronization. This should be done\nbeforehand, separately, through a call towait()(except within\ncallbacks, for which it\u2019s already being taken care of bythen()).\nwait()\nthen()\nThe value held by thisFuture. If the function (callback or RPC)\ncreating the value has thrown an error, thisvalue()method will\nalso throw an error.\nFuture\nvalue()\nT\nBlock until the value of thisFutureis ready.\nFuture\nIf the value contains tensors that reside on GPUs, then an additional\nsynchronization is performed with the kernels (executing on the device)\nwhich may be asynchronously populating those tensors. Such sync is\nnon-blocking, which means thatwait()will insert the necessary\ninstructions in the current streams to ensure that further operations\nenqueued on those streams will be properly scheduled after the async\nkernels but, once that is done,wait()will return, even if those\nkernels are still running. No further synchronization is required when\naccessing and using the values, as long as one doesn\u2019t change streams.\nwait()\nwait()\nThe value held by thisFuture. If the function (callback or RPC)\ncreating the value has thrown an error, thiswaitmethod will\nalso throw an error.\nFuture\nwait\nT\nCollects the providedFutureobjects into a single\ncombinedFuturethat is completed when all of the\nsub-futures are completed.\nFuture\nFuture\nfutures(list) \u2013 a list ofFutureobjects.\nFuture\nReturns aFutureobject to a list of the passed\nin Futures.\nFuture\nFuture[list[torch.jit.Future]]\n\n```python\n>>> fut0 = torch.futures.Future()\n>>> fut1 = torch.futures.Future()\n>>> fut = torch.futures.collect_all([fut0, fut1])\n>>> fut0.set_result(0)\n>>> fut1.set_result(1)\n>>> fut_list = fut.wait()\n>>> print(f\"fut0 result = {fut_list[0].wait()}\")\nfut0 result = 0\n>>> print(f\"fut1 result = {fut_list[1].wait()}\")\nfut1 result = 1\n\n```\n\nWaits for all provided futures to be complete, and returns\nthe list of completed values. If any of the futures encounters an error,\nthe method will exit early and report the error not waiting for other\nfutures to complete.\nfutures(list) \u2013 a list ofFutureobject.\nFuture\nA list of the completedFutureresults. This\nmethod will throw an error ifwaiton anyFuturethrows.\nFuture\nwait\nFuture\nlist",
  "url": "https://pytorch.org/docs/stable/futures.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}