{
  "doc_id": "e47998840b23e8b541818f75d68414df",
  "source": "pytorch_docs",
  "title": "CUDAGraph \u2014 PyTorch 2.9 documentation",
  "text": "\n## CUDAGraph#\n\nWrapper around a CUDA graph.\nkeep_graph(bool,optional) \u2013 Ifkeep_graph=False, the\ncudaGraphExec_t will be instantiated on GPU at the end ofcapture_endand the underlying cudaGraph_t will be\ndestroyed. Users who want to query or otherwise modify the\nunderlying cudaGraph_t before instantiation can setkeep_graph=Trueand access it viaraw_cuda_graphaftercapture_end. Note that the cudaGraphExec_t will not be\ninstantiated at the end ofcapture_endin this\ncase. Instead, it will be instantiated via an explicit called\ntoinstantiateor automatically on the first call toreplayifinstantiatewas not already called. Callinginstantiatemanually beforereplayis recommended to\nprevent increased latency on the first call toreplay. It\nis allowed to modify the raw cudaGraph_t after first callinginstantiate, but the user must callinstantiateagain\nmanually to make sure the instantiated graph has these\nchanges. Pytorch has no means of tracking these changes.\nkeep_graph=False\ncapture_end\nkeep_graph=True\nraw_cuda_graph\ncapture_end\ncapture_end\ninstantiate\nreplay\ninstantiate\ninstantiate\nreplay\nreplay\ninstantiate\ninstantiate\nSelf\nWarning\nThis API is in beta and may change in future releases.\nBegin capturing CUDA work on the current stream.\nTypically, you shouldn\u2019t callcapture_beginyourself.\nUsegraphormake_graphed_callables(),\nwhich callcapture_begininternally.\ncapture_begin\ngraph\nmake_graphed_callables()\ncapture_begin\npool(optional) \u2013 Token (returned bygraph_pool_handle()orother_Graph_instance.pool()) that hints this graph may share memory\nwith the indicated pool.  SeeGraph memory management.\ngraph_pool_handle()\nother_Graph_instance.pool()\ncapture_error_mode(str,optional) \u2013 specifies the cudaStreamCaptureMode for the graph capture stream.\nCan be \u201cglobal\u201d, \u201cthread_local\u201d or \u201crelaxed\u201d. During cuda graph capture, some actions, such as cudaMalloc,\nmay be unsafe. \u201cglobal\u201d will error on actions in other threads, \u201cthread_local\u201d will only error for\nactions in the current thread, and \u201crelaxed\u201d will not error on these actions. Do NOT change this setting\nunless you\u2019re familiar withcudaStreamCaptureMode\nEnd CUDA graph capture on the current stream.\nAftercapture_end,replaymay be called on this instance.\ncapture_end\nreplay\nTypically, you shouldn\u2019t callcapture_endyourself.\nUsegraphormake_graphed_callables(),\nwhich callcapture_endinternally.\ncapture_end\ngraph\nmake_graphed_callables()\ncapture_end\ndebug_path(required) \u2013 Path to dump the graph to.\nCalls a debugging function to dump the graph if the debugging is\nenabled via CUDAGraph.enable_debug_mode()\nEnable debugging mode for CUDAGraph.debug_dump.\nInstantiate the CUDA graph. Will be called bycapture_endifkeep_graph=False, or byreplayifkeep_graph=Trueandinstantiatehas not already been\nexplicitly called. Does not destroy the cudaGraph_t returned\nbyraw_cuda_graph.\ncapture_end\nkeep_graph=False\nreplay\nkeep_graph=True\ninstantiate\nraw_cuda_graph\nReturn an opaque token representing the id of this graph\u2019s memory pool.\nThis id can optionally be passed to another graph\u2019scapture_begin,\nwhich hints the other graph may share the same memory pool.\ncapture_begin\n_POOL_HANDLE\nReturns the underlying cudaGraph_t.keep_graphmust be True.\nkeep_graph\nSee the following for APIs for how to manipulate this object:Graph Managmementandcuda-python Graph Management bindings\nint\nReturns the underlying cudaGraphExec_t.instantiatemust have been called ifkeep_graphis True, orcapture_endmust have been called ifkeep_graphis False. If you callinstantiate()afterraw_cuda_graph_exec(), the previously returned cudaGraphExec_t will be destroyed. It is your responsibility not to use this object after destruction.\ninstantiate\nkeep_graph\ncapture_end\nkeep_graph\ninstantiate()\nraw_cuda_graph_exec()\nSee the following for APIs for how to manipulate this object:Graph Executionandcuda-python Graph Execution bindings\nint\nReplay the CUDA work captured by this graph.\nDelete the graph currently held by this instance.",
  "url": "https://pytorch.org/docs/stable/generated/torch.cuda.CUDAGraph.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}