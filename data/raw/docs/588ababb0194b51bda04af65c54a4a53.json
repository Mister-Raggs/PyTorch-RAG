{
  "doc_id": "588ababb0194b51bda04af65c54a4a53",
  "source": "pytorch_docs",
  "title": "torch.cuda \u2014 PyTorch 2.9 documentation",
  "text": "\n## torch.cuda#\n\nCreated On: Dec 23, 2016 | Last Updated On: Aug 19, 2025\nThis package adds support for CUDA tensor types.\nIt implements the same function as CPU tensors, but they utilize\nGPUs for computation.\nIt is lazily initialized, so you can always import it, and useis_available()to determine if your system supports CUDA.\nis_available()\nCUDA semanticshas more details about working with CUDA.\nStreamContext\n\nStreamContext\nContext-manager that selects a given stream.\ncan_device_access_peer\n\ncan_device_access_peer\nCheck if peer access between two devices is possible.\ncurrent_blas_handle\n\ncurrent_blas_handle\nReturn cublasHandle_t pointer to current cuBLAS handle\ncurrent_device\n\ncurrent_device\nReturn the index of a currently selected device.\ncurrent_stream\n\ncurrent_stream\nReturn the currently selectedStreamfor a given device.\nStream\ncudart\n\ncudart\nRetrieves the CUDA runtime API module.\ndefault_stream\n\ndefault_stream\nReturn the defaultStreamfor a given device.\nStream\ndevice\n\ndevice\nContext-manager that changes the selected device.\ndevice_count\n\ndevice_count\nReturn the number of GPUs available.\ndevice_memory_used\n\ndevice_memory_used\nReturn used global (device) memory in bytes as given bynvidia-smioramd-smi.\ndevice_of\n\ndevice_of\nContext-manager that changes the current device to that of given object.\nget_arch_list\n\nget_arch_list\nReturn list CUDA architectures this library was compiled for.\nget_device_capability\n\nget_device_capability\nGet the cuda capability of a device.\nget_device_name\n\nget_device_name\nGet the name of a device.\nget_device_properties\n\nget_device_properties\nGet the properties of a device.\nget_gencode_flags\n\nget_gencode_flags\nReturn NVCC gencode flags this library was compiled with.\nget_stream_from_external\n\nget_stream_from_external\nReturn aStreamfrom an externally allocated CUDA stream.\nStream\nget_sync_debug_mode\n\nget_sync_debug_mode\nReturn current value of debug mode for cuda synchronizing operations.\ninit\n\ninit\nInitialize PyTorch's CUDA state.\nipc_collect\n\nipc_collect\nForce collects GPU memory after it has been released by CUDA IPC.\nis_available\n\nis_available\nReturn a bool indicating if CUDA is currently available.\nis_initialized\n\nis_initialized\nReturn whether PyTorch's CUDA state has been initialized.\nis_tf32_supported\n\nis_tf32_supported\nReturn a bool indicating if the current CUDA/ROCm device supports dtype tf32.\nmemory_usage\n\nmemory_usage\nReturn the percent of time over the past sample period during which global (device) memory was being read or written as given bynvidia-smi.\nset_device\n\nset_device\nSet the current device.\nset_stream\n\nset_stream\nSet the current stream.This is a wrapper API to set the stream.\nset_sync_debug_mode\n\nset_sync_debug_mode\nSet the debug mode for cuda synchronizing operations.\nstream\n\nstream\nWrap around the Context-manager StreamContext that selects a given stream.\nsynchronize\n\nsynchronize\nWait for all kernels in all streams on a CUDA device to complete.\nutilization\n\nutilization\nReturn the percent of time over the past sample period during which one or more kernels was executing on the GPU as given bynvidia-smi.\ntemperature\n\ntemperature\nReturn the average temperature of the GPU sensor in Degrees C (Centigrades).\npower_draw\n\npower_draw\nReturn the average power draw of the GPU sensor in mW (MilliWatts)\nclock_rate\n\nclock_rate\nReturn the clock speed of the GPU SM in MHz (megahertz) over the past sample period as given bynvidia-smi.\nAcceleratorError\n\nAcceleratorError\nException raised while executing on device\nOutOfMemoryError\n\nOutOfMemoryError\nException raised when device is out of memory\n\n## Random Number Generator#\n\nget_rng_state\n\nget_rng_state\nReturn the random number generator state of the specified GPU as a ByteTensor.\nget_rng_state_all\n\nget_rng_state_all\nReturn a list of ByteTensor representing the random number states of all devices.\nset_rng_state\n\nset_rng_state\nSet the random number generator state of the specified GPU.\nset_rng_state_all\n\nset_rng_state_all\nSet the random number generator state of all devices.\nmanual_seed\n\nmanual_seed\nSet the seed for generating random numbers for the current GPU.\nmanual_seed_all\n\nmanual_seed_all\nSet the seed for generating random numbers on all GPUs.\nseed\n\nseed\nSet the seed for generating random numbers to a random number for the current GPU.\nseed_all\n\nseed_all\nSet the seed for generating random numbers to a random number on all GPUs.\ninitial_seed\n\ninitial_seed\nReturn the current random seed of the current GPU.\n\n## Communication collectives#\n\ncomm.broadcast\ncomm.broadcast\nBroadcasts a tensor to specified GPU devices.\ncomm.broadcast_coalesced\ncomm.broadcast_coalesced\nBroadcast a sequence of tensors to the specified GPUs.\ncomm.reduce_add\ncomm.reduce_add\nSum tensors from multiple GPUs.\ncomm.reduce_add_coalesced\ncomm.reduce_add_coalesced\nSum tensors from multiple GPUs.\ncomm.scatter\ncomm.scatter\nScatters tensor across multiple GPUs.\ncomm.gather\ncomm.gather\nGathers tensors from multiple GPU devices.\n\n## Streams and events#\n\nStream\n\nStream\nWrapper around a CUDA stream.\nExternalStream\n\nExternalStream\nWrapper around an externally allocated CUDA stream.\nEvent\n\nEvent\nWrapper around a CUDA event.\n\n## Graphs (beta)#\n\nis_current_stream_capturing\n\nis_current_stream_capturing\nReturn True if CUDA graph capture is underway on the current CUDA stream, False otherwise.\ngraph_pool_handle\n\ngraph_pool_handle\nReturn an opaque token representing the id of a graph memory pool.\nCUDAGraph\n\nCUDAGraph\nWrapper around a CUDA graph.\ngraph\n\ngraph\nContext-manager that captures CUDA work into atorch.cuda.CUDAGraphobject for later replay.\ntorch.cuda.CUDAGraph\nmake_graphed_callables\n\nmake_graphed_callables\nAccept callables (functions ornn.Modules) and returns graphed versions.\nnn.Module\nThis package adds support for device memory management implemented in CUDA.\n\n## Memory management#\n\nempty_cache\n\nempty_cache\nRelease all unoccupied cached memory currently held by the caching allocator so that those can be used in other GPU application and visible innvidia-smi.\nget_per_process_memory_fraction\n\nget_per_process_memory_fraction\nGet memory fraction for a process.\nlist_gpu_processes\n\nlist_gpu_processes\nReturn a human-readable printout of the running processes and their GPU memory use for a given device.\nmem_get_info\n\nmem_get_info\nReturn the global free and total GPU memory for a given device using cudaMemGetInfo.\nmemory_stats\n\nmemory_stats\nReturn a dictionary of CUDA memory allocator statistics for a given device.\nmemory_stats_as_nested_dict\n\nmemory_stats_as_nested_dict\nReturn the result ofmemory_stats()as a nested dictionary.\nmemory_stats()\nreset_accumulated_memory_stats\n\nreset_accumulated_memory_stats\nReset the \"accumulated\" (historical) stats tracked by the CUDA memory allocator.\nhost_memory_stats\n\nhost_memory_stats\nReturn a dictionary of CUDA memory allocator statistics for a given device.\nhost_memory_stats_as_nested_dict\n\nhost_memory_stats_as_nested_dict\nReturn the result ofhost_memory_stats()as a nested dictionary.\nhost_memory_stats()\nreset_accumulated_host_memory_stats\n\nreset_accumulated_host_memory_stats\nReset the \"accumulated\" (historical) stats tracked by the host memory allocator.\nmemory_summary\n\nmemory_summary\nReturn a human-readable printout of the current memory allocator statistics for a given device.\nmemory_snapshot\n\nmemory_snapshot\nReturn a snapshot of the CUDA memory allocator state across all devices.\nmemory_allocated\n\nmemory_allocated\nReturn the current GPU memory occupied by tensors in bytes for a given device.\nmax_memory_allocated\n\nmax_memory_allocated\nReturn the maximum GPU memory occupied by tensors in bytes for a given device.\nreset_max_memory_allocated\n\nreset_max_memory_allocated\nReset the starting point in tracking maximum GPU memory occupied by tensors for a given device.\nmemory_reserved\n\nmemory_reserved\nReturn the current GPU memory managed by the caching allocator in bytes for a given device.\nmax_memory_reserved\n\nmax_memory_reserved\nReturn the maximum GPU memory managed by the caching allocator in bytes for a given device.\nset_per_process_memory_fraction\n\nset_per_process_memory_fraction\nSet memory fraction for a process.\nmemory_cached\n\nmemory_cached\nDeprecated; seememory_reserved().\nmemory_reserved()\nmax_memory_cached\n\nmax_memory_cached\nDeprecated; seemax_memory_reserved().\nmax_memory_reserved()\nreset_max_memory_cached\n\nreset_max_memory_cached\nReset the starting point in tracking maximum GPU memory managed by the caching allocator for a given device.\nreset_peak_memory_stats\n\nreset_peak_memory_stats\nReset the \"peak\" stats tracked by the CUDA memory allocator.\nreset_peak_host_memory_stats\n\nreset_peak_host_memory_stats\nReset the \"peak\" stats tracked by the host memory allocator.\ncaching_allocator_alloc\n\ncaching_allocator_alloc\nPerform a memory allocation using the CUDA memory allocator.\ncaching_allocator_delete\n\ncaching_allocator_delete\nDelete memory allocated using the CUDA memory allocator.\nget_allocator_backend\n\nget_allocator_backend\nReturn a string describing the active allocator backend as set byPYTORCH_CUDA_ALLOC_CONF.\nPYTORCH_CUDA_ALLOC_CONF\nCUDAPluggableAllocator\n\nCUDAPluggableAllocator\nCUDA memory allocator loaded from a so file.\nchange_current_allocator\n\nchange_current_allocator\nChange the currently used memory allocator to be the one provided.\nMemPool\n\nMemPool\nMemPool represents a pool of memory in a caching allocator.\ncaching_allocator_enable\n\ncaching_allocator_enable\nEnable or disable the CUDA memory allocator.\nA context manager that routes allocations to a given pool.\npool(torch.cuda.MemPool) \u2013 a MemPool object to be made active so that\nallocations route to this pool.\ndevice(torch.deviceorint,optional) \u2013 selected device. Uses MemPool on\nthe current device, given bycurrent_device(),\nifdeviceisNone(default).\ncurrent_device()\ndevice\nNone\nNote\nThis context manager makes only current thread\u2019s allocations route to\nthe given pool. If a new thread is spawned inside the context manager\n(e.g. by calling backward) the allocations in that thread will not\nroute to the given pool.\n\n## NVIDIA Tools Extension (NVTX)#\n\nnvtx.mark\nnvtx.mark\nDescribe an instantaneous event that occurred at some point.\nnvtx.range_push\nnvtx.range_push\nPush a range onto a stack of nested range span.\nnvtx.range_pop\nnvtx.range_pop\nPop a range off of a stack of nested range spans.\nnvtx.range\nnvtx.range\nContext manager / decorator that pushes an NVTX range at the beginning of its scope, and pops it at the end.\n\n## Jiterator (beta)#\n\njiterator._create_jit_fn\njiterator._create_jit_fn\nCreate a jiterator-generated cuda kernel for an elementwise op.\njiterator._create_multi_output_jit_fn\njiterator._create_multi_output_jit_fn\nCreate a jiterator-generated cuda kernel for an elementwise op that supports returning one or more outputs.\n\n## TunableOp#\n\nSome operations could be implemented using more than one library or more than\none technique. For example, a GEMM could be implemented for CUDA or ROCm using\neither the cublas/cublasLt libraries or hipblas/hipblasLt libraries,\nrespectively. How does one know which implementation is the fastest and should\nbe chosen? That\u2019s what TunableOp provides. Certain operators have been\nimplemented using multiple strategies as Tunable Operators. At runtime, all\nstrategies are profiled and the fastest is selected for all subsequent\noperations.\nSee thedocumentationfor information on how to use it.\n\n## Stream Sanitizer (prototype)#\n\nCUDA Sanitizer is a prototype tool for detecting synchronization errors between streams in PyTorch.\nSee thedocumentationfor information on how to use it.\n\n## GPUDirect Storage (prototype)#\n\nThe APIs intorch.cuda.gdsprovide thin wrappers around certain cuFile APIs that allow\ndirect memory access transfers between GPU memory and storage, avoiding a bounce buffer in the CPU. See thecufile api documentationfor more details.\ntorch.cuda.gds\nThese APIs can be used in versions greater than or equal to CUDA 12.6. In order to use these APIs, one must\nensure that their system is appropriately configured to use GPUDirect Storage per theGPUDirect Storage documentation.\nSee the docs forGdsFilefor an example of how to use these.\nGdsFile\ngds_register_buffer\n\ngds_register_buffer\nRegisters a storage on a CUDA device as a cufile buffer.\ngds_deregister_buffer\n\ngds_deregister_buffer\nDeregisters a previously registered storage on a CUDA device as a cufile buffer.\nGdsFile\n\nGdsFile\nWrapper around cuFile.",
  "url": "https://pytorch.org/docs/stable/cuda.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}