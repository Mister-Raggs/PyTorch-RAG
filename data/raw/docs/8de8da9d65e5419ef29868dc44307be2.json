{
  "doc_id": "8de8da9d65e5419ef29868dc44307be2",
  "source": "pytorch_docs",
  "title": "PYTORCH ProcessGroupNCCL Environment Variables \u2014 PyTorch 2.9 documentation",
  "text": "\n## PYTORCH ProcessGroupNCCL Environment Variables#\n\nCreated On: Jun 10, 2025 | Last Updated On: Jun 10, 2025\nFor more information on the environment variables, seeProcessGroupNCCL Environment Variables.\nVariable\nDescription\nTORCH_NCCL_ASYNC_ERROR_HANDLING\nTORCH_NCCL_ASYNC_ERROR_HANDLING\nControl how we perform Async Error Handling with NCCL when an exception is observed in watchdog. If set to 0, no handling of asynchronous NCCL errors. If set to 1, aborting NCCL communicator and tearing down process upon error. If set to 2, only abort NCCL communicator and if set to 3, tearing down process without aborting NCCL communicator. By default, it is set to 3.\nTORCH_NCCL_HIGH_PRIORITY\nTORCH_NCCL_HIGH_PRIORITY\nControl whether to use high priority stream for the NCCL communicator.\nTORCH_NCCL_BLOCKING_WAIT\nTORCH_NCCL_BLOCKING_WAIT\nControl whether or not wait() is blocking or non-blocking.\nTORCH_NCCL_DUMP_ON_TIMEOUT\nTORCH_NCCL_DUMP_ON_TIMEOUT\nControl whether dumping debug info on watchdog timeout or exception is detected. This variable must be set together with TORCH_NCCL_TRACE_BUFFER_SIZE larger than 0.\nTORCH_NCCL_DESYNC_DEBUG\nTORCH_NCCL_DESYNC_DEBUG\nControl whether Desync Debug is enabled. This is helpful in figuring out the culprit rank of collective desync.\nTORCH_NCCL_ENABLE_TIMING\nTORCH_NCCL_ENABLE_TIMING\nIf set to1, enable recording start-events for all ProcessGroupNCCL collectives, and compute accurate collective timing per-collective.\n1\nTORCH_NCCL_ENABLE_MONITORING\nTORCH_NCCL_ENABLE_MONITORING\nIf set to1,enable monitoring thread which aborts the process when the ProcessGroupNCCL Watchdog thread gets stuck and no heartbeat is detected after TORCH_NCCL_HEARTBEAT_TIMEOUT_SEC. This can happen due to calling CUDA/NCCL APIs that may hang. It is Useful to prevent jobs being stuck for a prolonged time than necessary tying up cluster resources.\n1\nTORCH_NCCL_HEARTBEAT_TIMEOUT_SEC\nTORCH_NCCL_HEARTBEAT_TIMEOUT_SEC\nControl the watchdog heartbeat timeout period after which the monitoring thread will abort the process.\nTORCH_NCCL_TRACE_BUFFER_SIZE\nTORCH_NCCL_TRACE_BUFFER_SIZE\nThe maximum number of events we store in the flight recorder\u2019s ring buffer. One event could be the start or end of a collective, for example. Set to 0 to disable the tracebuffer and debugging info dump.\nTORCH_NCCL_TRACE_CPP_STACK\nTORCH_NCCL_TRACE_CPP_STACK\nWhether to collect cpp stack traces for flight recorder. Default value is False.\nTORCH_NCCL_COORD_CHECK_MILSEC\nTORCH_NCCL_COORD_CHECK_MILSEC\nControl the interval inside the monitoring thread to check the coordinated signal from other ranks, e.g. to dump the debugging information. Default value is 1000 ms.\nTORCH_NCCL_WAIT_TIMEOUT_DUMP_MILSEC\nTORCH_NCCL_WAIT_TIMEOUT_DUMP_MILSEC\nControl how much extra time we will wait for dumping the debugging info before we exit and throws timeout exception.\nTORCH_NCCL_DEBUG_INFO_TEMP_FILE\nTORCH_NCCL_DEBUG_INFO_TEMP_FILE\nThe file into which the debugging info would be dumped.\nTORCH_NCCL_DEBUG_INFO_PIPE_FILE\nTORCH_NCCL_DEBUG_INFO_PIPE_FILE\nThe pipe file to trigger debugging dump manually, write anything into the pipe would trigger the dump.\nTORCH_NCCL_NAN_CHECK\nTORCH_NCCL_NAN_CHECK\nControl whether to enable NAN check for the input, Error would be thrown if NAN is detected.",
  "url": "https://pytorch.org/docs/stable/torch_nccl_environment_variables.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}