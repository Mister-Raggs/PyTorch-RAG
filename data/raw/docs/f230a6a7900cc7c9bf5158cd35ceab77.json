{
  "doc_id": "f230a6a7900cc7c9bf5158cd35ceab77",
  "source": "pytorch_docs",
  "title": "Nested Graph Breaks \u2014 PyTorch 2.9 documentation",
  "text": "\n## Nested Graph Breaks#\n\nCreated On: Jul 28, 2025 | Last Updated On: Jul 28, 2025\nSummary:\nGraph breaks in nested functions can result in hard-to-understand compiler behavior, which we document below\nA nested graph break results inO(N)\\mathcal O(N)O(N)duplicate graph break behavior\nRecall that whentorch.compileis applied to a function, any nested function calls are also traced.\nAnested graph breakrefers to any graph break that happens in a nested function call.\ntorch.compile\n\n```python\ndef inner(x):\n    ...\n    torch._dynamo.graph_break()  # nested graph break\n    ...\n\n@torch.compile\ndef outer(x):\n    ...\n    y = inner(x)\n    ...\n\n```\n\nThe resumption semantics around nested graph breaks can be confusing, so we describe the behavior here.\nRecall that infullgraph=False,graph breaks are handledby compiling the FX graph that has been determined so far,\nrunning the unsupported code in regular Python, then resuming tracing after the unsupported code with a new FX graph.\nResuming a function is actually a fairly complicated technical feat, so resuming tracing is only supported on top-level functions.\nfullgraph=False\nWe can therefore resume tracing after a nested graph break with this restriction in the following way:\nFirst, consider the below example wheretorch.compiletraces fromfand traces all the way until the\ngraph break ininner1is encountered.\ntorch.compile\nf\ninner1\n\n```python\ndef inner1(x):\n    x = x + 1\n    torch._dynamo.graph_break()  # stop tracing due to graph break\n    return x + 2\n\ndef inner2(x):\n    x = x + 4\n    x = inner1(x)\n    x = x + 8\n\n@torch.compile\ndef f(x):\n    # start tracing from here\n    x = x + 16\n    x = inner2(x)\n    x = x + 32\n\nf(torch.randn(3))\n\n```\n\nSince we can only resume from top-level functions, we graph break on theinner2call inf.\ninner2\nf\n\n```python\n# The semantics of torch.compile(f)(x) is roughly this:\ndef compiled_f_semantics(x):\n    y = x + 16\n    z = inner2(y)\n    return torch.compile(resume_f_semantics)(z)\n\ndef resume_f_semantics(x):\n    return x + 32\n\ncompiled_f_semantics(torch.randn(3))\n\n```\n\ninner2is then automatically compiled as a top-level function.\nWe trace all the way until the graph break ininner1is encountered again.\ninner2\ninner1\n\n```python\ndef inner1(x):\n    x = x + 1\n    torch._dynamo.graph_break()  # stop tracing due to graph break\n    return x + 2\n\n# this torch.compile is automatically applied\n@torch.compile\ndef inner2(x):\n    # start tracing from here\n    x = x + 4\n    x = inner1(x)\n    x = x + 8\n\ndef compiled_f_semantics(x):\n    y = x + 16\n    z = inner2(y)\n    return torch.compile(resume_f_semantics)(z)\n\ndef resume_f_semantics(x):\n    return x + 32\n\ncompiled_f_semantics(torch.randn(3))\n\n```\n\nThen we graph break on theinner1call ininner2.\ninner1\ninner2\n\n```python\ndef compiled_inner2_semantics(x):\n    y = x + 4\n    z = inner1(y)\n    return torch.compile(resume_inner2_semantics)(z)\n\ndef resume_inner2_semantics(x):\n    return x + 8\n\n```\n\ninner1is then automatically compiled as a top-level function.\nThe graph break is frominner1, so we handle the graph break normally.\ninner1\ninner1\n\n```python\n# this torch.compile is automatically applied\n@torch.compile\ndef inner1(x):\n    # start tracing from here\n    x = x + 1\n    torch._dynamo.graph_break()  # stop tracing due to graph break\n    return x + 2\n\ndef compiled_f_semantics(x):\n    y = x + 16\n    z = compiled_inner2_semantics(y)\n    return torch.compile(resume_f_semantics)(z)\n\ndef resume_f_semantics(x):\n    return x + 32\n\ndef compiled_inner2_semantics(x):\n    y = x + 4\n    z = inner1(y)\n    return torch.compile(resume_inner2_semantics)(z)\n\ndef resume_inner2_semantics(x):\n    return x + 8\n\ncompiled_f_semantics(torch.randn(3))\n\n```\n\ninner1is handled normally:\ninner1\n\n```python\ndef compiled_inner1_semantics(x):\n    y = x + 1\n    torch._dynamo.graph_break()\n    return torch.compile(resume_inner1_semantics)(y)\n\ndef resume_inner1_semantics(x):\n    return x + 2\n\n```\n\nSo the initial code is semantically equivalent to\n\n```python\ndef compiled_f_semantics(x):\n    y = x + 16\n    z = compiled_inner2_semantics(y)\n    return torch.compile(resume_f_semantics)(z)\n\ndef resume_f_semantics(x):\n    return x + 32\n\ndef compiled_inner2_semantics(x):\n    y = x + 4\n    z = compiled_inner1_semantics(y)\n    return torch.compile(resume_inner2_semantics)(z)\n\ndef resume_inner2_semantics(x):\n    return x + 8\n\ndef compiled_inner1_semantics(x):\n    y = x + 1\n    torch._dynamo.graph_break()\n    return torch.compile(resume_inner1_semantics)(y)\n\ndef resume_inner1_semantics(x):\n    return x + 2\n\ncompiled_f_semantics(torch.randn(3))\n\n```\n\nNote in particular that we traced 3 top-level functions, and that we traced the same graph break 3 times.This explains why you may encounter duplicate graph breaks when usingtorch.compile.\ntorch.compile\nIn summary, nested graph breaks are handled by:\nTracing from the top-level function all the way to the nested graph break\nGraph breaking on the top-level function at the call to the second-level function\nCompiling the PyTorch ops tracked so far and running the compiled graph\nCalling the second-level function, which gets automatically compiled as a top-level function\nResuming tracing after the second-level function call\nNote that the runtime of handling this graph break isO(NK)\\mathcal O(NK)O(NK), whereNNNis the nesting depth,\nandKKKis the number of instructions from the top-level function to the graph break.\nWe end up tracingO(N2)\\mathcal O(N^2)O(N2)frames, and we trace the same graph breakO(N)\\mathcal O(N)O(N)times.",
  "url": "https://pytorch.org/docs/stable/compile/programming_model.nested_graph_breaks.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}