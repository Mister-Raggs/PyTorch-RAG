{
  "doc_id": "ffc046ebdc946b5578ac0f3812587ec5",
  "source": "pytorch_docs",
  "title": "Error Propagation \u2014 PyTorch 2.9 documentation",
  "text": "\n## Error Propagation#\n\nCreated On: May 04, 2021 | Last Updated On: Jul 08, 2021\nEach host in a distributed PyTorch job runs with a single TorchElastic agent,\nand multiple workers (as children processes of the TorchElastic agent).\nSince the workers are user-provided (your PyTorch script/job), TorchElastic\nhas a way to propagate errors on the trainers through the agent and up to the\nscheduler, which ultimately informs the end-user about the state of the job\nand applies any retry policies.\nTorchElastic categorizes errors into 3 categories:\nCategory\nSub-Category\nDescription\nUser Error\nInput Error\ninvalid inputs to TorchElastic APIs (e.g. min > max nodes)\nWorker Failure\nany failures on the worker child process\nPlatform Error\nn/a\nfailures caused by the agent\nInfra Error\nn/a\nfailures outside the domain of the agent and workers\n(e.g. host failures)\nAll errors other than \u201cWorker Failure\u201d are either raised canonically from the\nagent process or implicitly or explicitly crash the agent process. So the\nstandard language (python) provided exception handling strategies apply.\nWorker Failures are special because the exception/failure originates on a different\nprocess from the agent so the error needs to be propagated inter-process\n(e.g. the agent cannot simplytry-catchan exception raised on the worker process).\ntry-catch\nTorchElastic agents usetorch.distributed.elastic.multiprocessing.start_processes()to launch the workers which has a simple file based inter-process error propagation\nbuilt-in.\ntorch.distributed.elastic.multiprocessing.start_processes()\nAny function or binary entrypoint decorated withrecord()will write uncaught exceptions (with the trace information) to a file specified by the\nenvironment variableTORCHELASTIC_ERROR_FILE. The parent process (e.g. agent)\nsets this env var on each child it launches, then aggregates the error files for all\nchildren, and propagates the one with thesmallesttimestamp (e.g. thefirsterror).\nrecord()\nTORCHELASTIC_ERROR_FILE\n\n## Methods and Classes#\n\nSyntactic sugar to record errors/exceptions that happened in the decorated\nfunction using the providederror_handler.\nerror_handler\nUsing this decorator is equivalent to:\n\n```python\nerror_handler = get_error_handler()\nerror_handler.initialize()\ntry:\n    foobar()\nexcept ChildFailedError as e:\n    _, failure = e.get_first_failure()\n    error_handler.dump_error_file(failure.error_file, failure.exitcode)\n    raise\nexcept Exception as e:\n    error_handler.record_exception(e)\n    raise\n\n```\n\nImportant\nuse this decorator once per process at the top level method,\ntypically this is the main method.\nExample\n\n```python\n@record\ndef main():\n    pass\n\n\nif __name__ == \"__main__\":\n    main()\n\n```\n\nCallable[[~_P],Optional[_R]]\nSpecial exception type that can be raised from a function annotated with the@recorddecorator to have the child process\u2019 (root exception) propagate\nup the stack as-is (e.g. without being wrapped in the parent\u2019s traceback).\n@record\nUseful in cases where the parent is a simple nanny process\nand the child (worker) processes are actually doing meaningful compute.\nIn this case, errors typically occur on the child process as the parent\nis not doing anything non-trivial, and child errors should be propagated\nto the scheduler for accurate root cause diagnostics.\nNote\nThe propagation relies on error files rather than exception handling to\nsupport both function and binary launches.\nExample:\n\n```python\n# process tree on a host (container)\n0: scheduler-init-process:\n           |- 1: torchelastic_agent:\n                    |- 2: trainer_0 (ok)\n                    |- 3: trainer_1 (fail) -> error.json\n                    |- ...\n                    |- n+2: trainer_n (ok)\n           |- n+3: other processes\n           |- ...\n\n```\n\nIn the example above, trainer 1\u2019s failure (written into error.json) is\nthe root cause and should be reported to the scheduler\u2019s init process.\nThe torchelastic agent raises aChildFailedError(\"trainer\",{1:\"trainer_1/error.json\"})upon detecting trainer 1\u2019s failure which would propagate the contents\nof trainer 1\u2019s error file to the scheduler\u2019s init process.\nChildFailedError(\"trainer\",{1:\"trainer_1/error.json\"})\nWrite the provided exception object along with some other metadata about\nthe error in a structured way in JSON format to an error file specified by the\nenvironment variable:TORCHELASTIC_ERROR_FILE. If this environment\nvariable is not set, then simply logs the contents of what would have been\nwritten to the error file.\nTORCHELASTIC_ERROR_FILE\nThis handler may be subclassed to customize the handling of the error.\nSubclasses should overrideinitialize()andrecord_exception().\ninitialize()\nrecord_exception()\nRepresent the failed process result. When the worker process fails, it may record failure root cause into the file.\nTries to read the failure timestamp from the providederror_file,\nif theerror_filedoes not exist, the timestamp is the current\ntimestamp (seconds since epoch).\nerror_file\nerror_file\nThemessagefield is a concise explanation of the failure. If\nthe error file exists then the message is obtained from the error file.\nOtherwise one is generated based on the failure signature.\nmessage\nNote\nIt is assumed that theerror_fileis written bytorch.distributed.elastic.multiprocessing.errors.error_handler.ErrorHandler.\nOtherwise the behavior is undefined.\nerror_file\ntorch.distributed.elastic.multiprocessing.errors.error_handler.ErrorHandler",
  "url": "https://pytorch.org/docs/stable/elastic/errors.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}