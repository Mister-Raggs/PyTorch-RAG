{
  "doc_id": "939bdbcb9d4be5320cfb410b6c838989",
  "source": "pytorch_docs",
  "title": "Metrics \u2014 PyTorch 2.9 documentation",
  "text": "\n## Metrics#\n\nCreated On: May 04, 2021 | Last Updated On: May 04, 2021\nMetrics API.\nOverview:\nThe metrics API in torchelastic is used to publish telemetry metrics.\nIt is designed to be used by torchelastic\u2019s internal modules to\npublish metrics for the end user with the goal of increasing visibility\nand helping with debugging. However you may use the same API in your\njobs to publish metrics to the same metricssink.\nsink\nAmetriccan be thought of as timeseries data\nand is uniquely identified by the string-valued tuple(metric_group,metric_name).\nmetric\n(metric_group,metric_name)\ntorchelastic makes no assumptions about what ametric_groupis\nand what relationship it has withmetric_name. It is totally up\nto the user to use these two fields to uniquely identify a metric.\nmetric_group\nmetric_name\nNote\nThe metric grouptorchelasticis reserved by torchelastic for\nplatform level metrics that it produces.\nFor instance torchelastic may output the latency (in milliseconds)\nof a re-rendezvous operation from the agent as(torchelastic,agent.rendezvous.duration.ms)\ntorchelastic\n(torchelastic,agent.rendezvous.duration.ms)\nA sensible way to use metric groups is to map them to a stage or module\nin your job. You may also encode certain high level properties\nthe job such as the region or stage (dev vs prod).\nPublish Metrics:\nUsing torchelastic\u2019s metrics API is similar to using python\u2019s logging\nframework. You first have to configure a metrics handler before\ntrying to add metric data.\nThe example below measures the latency for thecalculate()function.\ncalculate()\n\n```python\nimport time\nimport torch.distributed.elastic.metrics as metrics\n\n# makes all metrics other than the one from \"my_module\" to go /dev/null\nmetrics.configure(metrics.NullMetricsHandler())\nmetrics.configure(metrics.ConsoleMetricsHandler(), \"my_module\")\n\n\ndef my_method():\n    start = time.time()\n    calculate()\n    end = time.time()\n    metrics.put_metric(\"calculate_latency\", int(end - start), \"my_module\")\n\n```\n\nYou may also use the torch.distributed.elastic.metrics.prof` decorator\nto conveniently and succinctly profile functions\n\n```python\n# -- in module examples.foobar --\n\nimport torch.distributed.elastic.metrics as metrics\n\nmetrics.configure(metrics.ConsoleMetricsHandler(), \"foobar\")\nmetrics.configure(metrics.ConsoleMetricsHandler(), \"Bar\")\n\n\n@metrics.prof\ndef foo():\n    pass\n\n\nclass Bar:\n    @metrics.prof\n    def baz():\n        pass\n\n```\n\n@metrics.profwill publish the following metrics\n@metrics.prof\n\n```python\n<leaf_module or classname>.success - 1 if the function finished successfully\n<leaf_module or classname>.failure - 1 if the function threw an exception\n<leaf_module or classname>.duration.ms - function duration in milliseconds\n\n```\n\nConfiguring Metrics Handler:\ntorch.distributed.elastic.metrics.MetricHandleris responsible for emitting\nthe added metric values to a particular destination. Metric groups can be\nconfigured with different metric handlers.\nBy default torchelastic emits all metrics to/dev/null.\nBy adding the following configuration metrics,torchelasticandmy_appmetric groups will be printed out to\nconsole.\n/dev/null\ntorchelastic\nmy_app\n\n```python\nimport torch.distributed.elastic.metrics as metrics\n\nmetrics.configure(metrics.ConsoleMetricHandler(), group=\"torchelastic\")\nmetrics.configure(metrics.ConsoleMetricHandler(), group=\"my_app\")\n\n```\n\nWriting a Custom Metric Handler:\nIf you want your metrics to be emitted to a custom location, implement\nthetorch.distributed.elastic.metrics.MetricHandlerinterface\nand configure your job to use your custom metric handler.\nBelow is a toy example that prints the metrics tostdout\nstdout\n\n```python\nimport torch.distributed.elastic.metrics as metrics\n\n\nclass StdoutMetricHandler(metrics.MetricHandler):\n    def emit(self, metric_data):\n        ts = metric_data.timestamp\n        group = metric_data.group_name\n        name = metric_data.name\n        value = metric_data.value\n        print(f\"[{ts}][{group}]: {name}={value}\")\n\n\nmetrics.configure(StdoutMetricHandler(), group=\"my_app\")\n\n```\n\nNow all metrics in the groupmy_appwill be printed to stdout as:\nmy_app\n\n```python\n[1574213883.4182858][my_app]: my_metric=<value>\n[1574213940.5237644][my_app]: my_metric=<value>\n\n```\n\n\n## Metric Handlers#\n\nBelow are the metric handlers that come included with torchelastic.\n\n## Methods#\n\n@profile decorator publishes duration.ms, count, success, failure metrics for the function that it decorates.\nThe metric name defaults to the qualified name (class_name.def_name) of the function.\nIf the function does not belong to a class, it uses the leaf module name instead.\nclass_name.def_name\nUsage\n\n```python\n@metrics.prof\ndef x():\n    pass\n\n\n@metrics.prof(group=\"agent\")\ndef y():\n    pass\n\n```\n\nPublish a metric data point.\nUsage\n\n```python\nput_metric(\"metric_name\", 1)\nput_metric(\"metric_name\", 1, \"metric_group_name\")\n\n```\n",
  "url": "https://pytorch.org/docs/stable/elastic/metrics.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}