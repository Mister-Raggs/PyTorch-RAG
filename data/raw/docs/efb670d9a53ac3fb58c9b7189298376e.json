{
  "doc_id": "efb670d9a53ac3fb58c9b7189298376e",
  "source": "pytorch_docs",
  "title": "PyTorch 2.0 Troubleshooting (old) \u2014 PyTorch 2.9 documentation",
  "text": "\n## PyTorch 2.0 Troubleshooting (old)#\n\nCreated On: Jun 06, 2025 | Last Updated On: Aug 02, 2025\nAuthor:Michael Lazos\nNote\nThis document is outdated and is now mainly a primary resource on how to run thetorch.compileminifier.\nPlease see theupdated troubleshooting document.\nThere is also a morecomprehensive manual for torch.compileavailable.\ntorch.compile\nWe are actively developing debug tools, profilers, and improving our\nerror and warning messages. Below is a table of the available\ntools and their typical usage. For additional help seeDiagnosing Runtime Errors.\nTool\nPurpose\nUsage\nInfo logging\nView summarized steps of compilation\ntorch._logging.set_logs(dynamo=logging.INFO)orTORCH_LOGS=\"dynamo\"\ntorch._logging.set_logs(dynamo=logging.INFO)\nTORCH_LOGS=\"dynamo\"\nDebug logging\nView detailed steps of compilation (print every instruction traced)\ntorch._logging.set_logs(dynamo=logging.DEBUG)andtorch._dynamo.config.verbose=True, orTORCH_LOGS=\"+dynamo\"TORCHDYNAMO_VERBOSE=1\ntorch._logging.set_logs(dynamo=logging.DEBUG)\ntorch._dynamo.config.verbose=True\nTORCH_LOGS=\"+dynamo\"TORCHDYNAMO_VERBOSE=1\nMinifier for any backend\nFind smallest subgraph which reproduces errors for any backend\nset environment variableTORCHDYNAMO_REPRO_AFTER=\"dynamo\"\nTORCHDYNAMO_REPRO_AFTER=\"dynamo\"\nMinifier forTorchInductor\nTorchInductor\nIf the error is known to occur afterAOTAutogradfind\nsmallest subgraph which reproduces errors duringTorchInductorlowering\nAOTAutograd\nTorchInductor\nset environment variableTORCHDYNAMO_REPRO_AFTER=\"aot\"\nTORCHDYNAMO_REPRO_AFTER=\"aot\"\nDynamo accuracy minifier\nFinds the smallest subgraph which reproduces an accuracy issue\nbetween an eager mode model and optimized model, when you\nsuspect the problem is inAOTAutograd\nAOTAutograd\nTORCHDYNAMO_REPRO_AFTER=\"dynamo\"TORCHDYNAMO_REPRO_LEVEL=4\nTORCHDYNAMO_REPRO_AFTER=\"dynamo\"TORCHDYNAMO_REPRO_LEVEL=4\nInductor accuracy minifier\nFinds the smallest subgraph which reproduces an accuracy issue\nbetween an eager mode model and optimized model, when you\nsuspect the problem is in the backend (e.g., inductor).\nIf this doesn\u2019t work, try the Dynamo accuracy minifier\ninstead.\nTORCHDYNAMO_REPRO_AFTER=\"aot\"TORCHDYNAMO_REPRO_LEVEL=4\nTORCHDYNAMO_REPRO_AFTER=\"aot\"TORCHDYNAMO_REPRO_LEVEL=4\ntorch._dynamo.explain\ntorch._dynamo.explain\nFind graph breaks and display reasoning for them\ntorch._dynamo.explain(fn)(*inputs)\ntorch._dynamo.explain(fn)(*inputs)\nRecord/Replay\nRecord and replay frames which to reproduce errors during graph capture\ntorch._dynamo.config.replay_record_enabled=True\ntorch._dynamo.config.replay_record_enabled=True\nTorchDynamo function name filtering\nOnly compile functions with the given name to reduce noise when\ndebugging an issue\nset environment variableTORCHDYNAMO_DEBUG_FUNCTION=<name>\nTORCHDYNAMO_DEBUG_FUNCTION=<name>\nTorchInductor Debug logging\nPrint general TorchInductor debug info and generated Triton/C++ code\ntorch._inductor.config.debug=True\ntorch._inductor.config.debug=True\nTorchInductor Tracing\nShow time taken in each TorchInductor stage + output code and graph\nvisualization\nset the environment variable TORCH_COMPILE_DEBUG=1 ortorch._inductor.config.trace.enabled=True\ntorch._inductor.config.trace.enabled=True\nIn addition to info and debug logging,\nyou can usetorch._loggingfor more fine-grained logging.\n\n## Diagnosing Runtime Errors#\n\nAt a high level, the TorchDynamo stack consists of a graph capture from\nPython code (TorchDynamo) and a backend compiler. For example, a\nbackend compiler may consist of backward graph tracing (AOTAutograd) and\ngraph lowering (TorchInductor)*. Errors can occur in any component of\nthe stack and will provide full stack traces.\nTo determine in which component an error occurred,\nyou may use info-level loggingtorch._logging.set_logs(dynamo=logging.INFO)orTORCH_LOGS=\"dynamo\"and look forStep#:...outputs. Logs are made at the beginning and end of\neach step, so the step that an error should correspond to is the most recently\nlogged step whose end has not yet been logged. The steps correspond to the\nfollowing parts of the stack:\ntorch._logging.set_logs(dynamo=logging.INFO)\nTORCH_LOGS=\"dynamo\"\nStep#:...\nStep\nComponent\n1\nTorchDynamo\n2\nCompiler Backend\n3\nTorchInductor\nIf info logging is insufficient, you can use available backend\noptions. These options include:\n\"eager\": only runs TorchDynamo forward graph capture and then\nruns the captured graph with PyTorch. This provides an indication as\nto whether TorchDynamo is raising the error.\n\"eager\"\n\"aot_eager\": runs TorchDynamo to capture a forward graph, and\nthen AOTAutograd to trace the backward graph without any additional\nbackend compiler steps. PyTorch eager will then be used to run the\nforward and backward graphs. This is useful to narrow down the issue\nto AOTAutograd.\n\"aot_eager\"\nThe general procedure to narrow down an issue is the following:\nRun your program with the\"eager\"backend. If the error no longer\noccurs, the issue is in the backend compiler that is being used (if\nusing TorchInductor, proceed to step 2. If not, seeMinifying Backend Compiler Errors). If the error still\noccurs with the\"eager\"backend, it is due toTorchdynamo Errors.\n\"eager\"\n\"eager\"\nThis step is only necessary ifTorchInductoris used as the backend\ncompiler. Run the model with the\"aot_eager\"backend. If this\nbackend raises an error then the error is occurring during\nAOTAutograd tracing. If the error no longer occurs with this backend,\nthenMinifying TorchInductor Errors.\nTorchInductor\n\"aot_eager\"\nEach of these cases are analyzed in the following sections.\nNote\nThe TorchInductor backend consists of\nboth AOTAutograd tracing and the TorchInductor compiler itself. We will\ndisambiguate by referring toTorchInductoras the backend, and\nTorchInductor lowering as the phase which lowers the graph traced by\nAOTAutograd.\nTorchInductor\n\n## Torchdynamo Errors#\n\nIf the error that is generated occurs with the\"eager\"backend, then\nTorchDynamo is most likely the source of the error. Here is a sample code\nwhich will generate an error.\n\"eager\"\n\n```python\nimport torch\n\nimport torch._dynamo as dynamo\n\n\ndef test_assertion_error():\n    y = torch.ones(200, 200)\n    z = {y: 5}\n    return z\n\ncompiled_test_assertion_error = torch.compile(test_assertion_error, backend=\"eager\")\n\ncompiled_test_assertion_error()\n\n```\n\nThe code above generates the following error:\n\n```python\ntorch._dynamo.convert_frame: [ERROR] WON'T CONVERT test_assertion_error /scratch/mlazos/torchdynamo/../test/errors.py line 26\ndue to:\nTraceback (most recent call last):\n  File \"/scratch/mlazos/torchdynamo/torchdynamo/symbolic_convert.py\", line 837, in BUILD_MAP\n    assert isinstance(k, ConstantVariable) or (\nAssertionError\n\nfrom user code:\n   File \"/scratch/mlazos/torchdynamo/../test/errors.py\", line 34, in test_assertion_error\n    z = {y: 5}\n\nSet torch._dynamo.config.verbose=True for more information\n==========\n\n```\n\nAs the message suggests you can settorch._dynamo.config.verbose=Trueto get a full stack trace to both\nthe error in TorchDynamo and the user code. In addition to this flag,\nyou can also set thelog_levelof TorchDynamo throughtorch._logging.set_logs(dynamo=logging.INFO)orTORCH_LOGS=\"dynamo\". These levels include:\ntorch._dynamo.config.verbose=True\nlog_level\ntorch._logging.set_logs(dynamo=logging.INFO)\nTORCH_LOGS=\"dynamo\"\nlogging.DEBUGorTORCH_LOGS=\"+dynamo\": Print every instruction that is\nencountered in addition to all the log levels listed below.\nlogging.DEBUG\nTORCH_LOGS=\"+dynamo\"\nlogging.INFO:\nPrint each function that is compiled (original and modified bytecode)\nand the graph that is captured in addition to all the log levels listed below.\nlogging.INFO\nlogging.WARNING(default): Print graph breaks in addition to all\nthe log levels listed below.\nlogging.WARNING\nlogging.ERROR: Print errors only.\nlogging.ERROR\nIf a model is very large, the logs can become overwhelming. If\nan error occurs deep within a model\u2019s Python code, it can be useful to\nexecute only the frame in which the error occurs to enable easier\ndebugging. There are two tools available to enable this:\nSetting the environment variableTORCHDYNAMO_DEBUG_FUNCTIONto the desired function name will only run torchdynamo on functions with that\nname.\nTORCHDYNAMO_DEBUG_FUNCTION\nEnabling the record/replay tool (settorch._dynamo.config.replay_record_enabled=True)\nwhich dumps an execution record when an error is encountered. This record can\nthen be replayed to run only the frame where an error occurred.\ntorch._dynamo.config.replay_record_enabled=True\n\n## Diagnosing TorchInductor Errors#\n\nIf the error does not occur with the\"eager\"backend, then the\nbackend compiler is the source of the error (example\nerror).\nThere aredifferent choicesfor backend compilers for TorchDynamo, with TorchInductor\nfitting the needs of most users. This section focuses on TorchInductor\nas the motivating example, but some tools can also be used with other\nbackend compilers.\n\"eager\"\nBelow is the portion of the stack which we are focusing on:\nWith TorchInductor as the chosen backend, AOTAutograd is used to\ngenerate the backward graph from the forward graph captured by\ntorchdynamo. It is important to note that errors can occur during this\ntracing and also while TorchInductor lowers the forward and backward\ngraphs to GPU code or C++. A model can often consist of hundreds or\nthousands of FX nodes, so narrowing the exact nodes where this problem\noccurred can be very difficult. Fortunately, there are tools available to\nautomatically minify these input graphs to the nodes which are causing\nthe issue. The first step is to determine whether the error occurs\nduring tracing of the backward graph with AOTAutograd or during\nTorchInductor lowering. As mentioned above in step 2, the\"aot_eager\"backend can be used to run only AOTAutograd in isolation\nwithout lowering. If the error still occurs with this backend, this\nindicates that the error is occurring during AOTAutograd tracing.\n\"aot_eager\"\nHere is an example:\n\n```python\nimport torch\n\nimport torch._dynamo as dynamo\n\nmodel = torch.nn.Sequential(*[torch.nn.Linear(200, 200) for _ in range(5)])\n\ndef test_backend_error():\n\n    y = torch.ones(200, 200)\n    x = torch.ones(200, 200)\n    z = x + y\n    a = torch.ops.aten._foobar(z)  # dummy function which errors\n    return model(a)\n\n\ncompiled_test_backend_error = torch.compile(test_backend_error, backend=\"inductor\")\ncompiled_test_backend_error()\n\n```\n\nRunning this should give you this error with a longer stack trace below\nit:\n\n```python\nTraceback (most recent call last):\n  File \"/scratch/mlazos/torchdynamo/torchinductor/graph.py\", line 246, in call_function\n    return lowerings[target](*args, **kwargs)\n  File \"/scratch/mlazos/torchdynamo/torchinductor/lowering.py\", line 185, in wrapped\n    return decomp_fn(*args, **kwargs)\n  File \"/scratch/mlazos/torchdynamo/torchinductor/lowering.py\", line 810, in _foobar\n    assert False\nAssertionError\n...\n\n```\n\nerror with full stack\ntrace\nIf you then changetorch.compile(backend=\"inductor\")totorch.compile(backend=\"aot_eager\"), it will run without error, becausethe\nissueis in the TorchInductor lowering process, not in AOTAutograd.\ntorch.compile(backend=\"inductor\")\ntorch.compile(backend=\"aot_eager\")\n\n## Minifying TorchInductor Errors#\n\nFrom here, let\u2019s run the minifier to get a minimal repro. Setting the\nenvironment variableTORCHDYNAMO_REPRO_AFTER=\"aot\"(or settingtorch._dynamo.config.repro_after=\"aot\"directly) will generate a\nPython program which reduces the graph produced by AOTAutograd to the\nsmallest subgraph which reproduces the error. (See below for an example\nwhere we minify the graph produced by TorchDynamo) Running the program\nwith this environment variable should show nearlyidentical\noutput,\nwith an additional line indicating whereminifier_launcher.pyhas\nbeen written to. The output directory is configurable by settingtorch._dynamo.config.base_dirto a valid directory name. The final\nstep is to run the minifier and check that it runs successfully. A\nsuccessful run looks likethis.\nIf the minifier runs successfully, it generates runnable python code\nwhich reproduces the exact error. For our example this is the following\ncode:\nTORCHDYNAMO_REPRO_AFTER=\"aot\"\ntorch._dynamo.config.repro_after=\"aot\"\nminifier_launcher.py\ntorch._dynamo.config.base_dir\n\n```python\nimport torch\nfrom torch import tensor, device\nimport torch.fx as fx\nfrom torch._dynamo.testing import rand_strided\nfrom math import inf\nfrom torch.fx.experimental.proxy_tensor import make_fx\n\n# torch version: 1.13.0a0+gitfddfc44\n# torch cuda version: 11.6\n# torch git version: fddfc4488afb207971c54ad4bf58130fdc8a4dc5\n\n\n# CUDA Info:\n# nvcc: NVIDIA (R) Cuda compiler driver\n# Copyright (c) 2005-2022 NVIDIA Corporation\n# Built on Thu_Feb_10_18:23:41_PST_2022\n# Cuda compilation tools, release 11.6, V11.6.112\n# Build cuda_11.6.r11.6/compiler.30978841_0\n\n# GPU Hardware Info:\n# NVIDIA A100-SXM4-40GB : 8\n\nfrom torch.nn import *\n\nclass Repro(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, add):\n        _foobar = torch.ops.aten._foobar.default(add);  add = None\n        return (_foobar,)\n\nargs = [((200, 200), (200, 1), torch.float32, 'cpu')]\nargs = [rand_strided(shape, stride, dtype, device) for shape, stride, dtype, device in args]\nmod = make_fx(Repro())(*args)\nfrom torch._inductor.compile_fx import compile_fx_inner\n\ncompiled = compile_fx_inner(mod, args)\ncompiled(*args)\n\n```\n\nTheforwardmethod of theRepromodule contains the exact op\nwhich causes the issue. When filing an issue, please include any\nminified repros to aid in debugging.\nforward\nRepro\n\n## Minifying Backend Compiler Errors#\n\nWith backend compilers other than TorchInductor the process for finding\nthe subgraph causing the error is nearly identical to the procedure inMinifying TorchInductor Errorswith one important\ncaveat. Namely, that the minifier will now be run on the graph that is\ntraced by TorchDynamo, not the output graph of AOTAutograd. Let\u2019s walk\nthrough an example.\n\n```python\nimport torch\n\nimport torch._dynamo as dynamo\n\nmodel = torch.nn.Sequential(*[torch.nn.Linear(200, 200) for _ in range(5)])\n# toy compiler which fails if graph contains relu\ndef toy_compiler(gm: torch.fx.GraphModule, _):\n    for node in gm.graph.nodes:\n        if node.target == torch.relu:\n            assert False\n\n    return gm\n\n\ndef test_backend_error():\n    y = torch.ones(200, 200)\n    x = torch.ones(200, 200)\n    z = x + y\n    a = torch.relu(z)\n    return model(a)\n\n\ncompiled_test_backend_error = torch.compile(test_backend_error, backend=toy_compiler)\ncompiled_test_backend_error()\n\n```\n\nIn order to run the code after TorchDynamo has traced the forward graph,\nyou can use theTORCHDYNAMO_REPRO_AFTERenvironment variable. Running\nthis program withTORCHDYNAMO_REPRO_AFTER=\"dynamo\"(ortorch._dynamo.config.repro_after=\"dynamo\") should producethis\noutputand\nthe following code in{torch._dynamo.config.base_dir}/repro.py.\nTORCHDYNAMO_REPRO_AFTER\nTORCHDYNAMO_REPRO_AFTER=\"dynamo\"\ntorch._dynamo.config.repro_after=\"dynamo\"\n{torch._dynamo.config.base_dir}/repro.py\nNote\nThe other option for TORCHDYNAMO_REPRO_AFTER is\"aot\", which\nwill run the minifier after the backward graph has been generated.\n\"aot\"\n\n```python\nimport torch\nimport torch._dynamo as dynamo\nfrom torch import tensor, device\nimport torch.fx as fx\nfrom torch._dynamo.testing import rand_strided\nfrom math import inf\nfrom torch._dynamo.debug_utils import run_fwd_maybe_bwd\n\nfrom torch.nn import *\n\nclass Repro(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n\n    def forward(self, add):\n        relu = torch.relu(add);  add = None\n        return (relu,)\n\n\nmod = Repro().cuda()\nopt_mod = torch.compile(mod, backend=\"None\")\n\n\nargs = [((200, 200), (200, 1), torch.float32, 'cpu', False)]\nargs = [rand_strided(sh, st, dt, dev).requires_grad_(rg) for (sh, st, dt, dev, rg) in args]\n\n\nwith torch.cuda.amp.autocast(enabled=False):\n    ref = run_fwd_maybe_bwd(mod, args)\n    res = run_fwd_maybe_bwd(opt_mod, args)\n\n```\n\nThe minifier successfully reduced the graph to the op that raises the\nerror intoy_compiler. The other difference from the procedure inMinifying TorchInductor Errorsis that the minifier is\nautomatically run after encountering a backend compiler error. After a\nsuccessful run, the minifier writesrepro.pytotorch._dynamo.config.base_dir.\ntoy_compiler\nrepro.py\ntorch._dynamo.config.base_dir\n\n## Performance Profiling#\n\n\n## Accessing TorchDynamo Profiler#\n\nTorchDynamo has a built-in stats function for collecting and displaying\nthe time spent in each compilation phase. These stats can be accessed by\ncallingtorch._dynamo.utils.compile_times()after executing\nTorch._Dynamo. By default, this returns a string representation of the\ncompile times spent in each TorchDynamo function by name.\ntorch._dynamo.utils.compile_times()\n\n## TorchInductor Debugging using TORCH_COMPILE_DEBUG#\n\nTorchInductor has a builtin stats and trace function for displaying time\nspent in each compilation phase, output code, output graph visualization\nand IR dump. This is a debugging tool designed to make it easier to\nunderstand and troubleshoot the internals of TorchInductor.\nLet\u2019s run an example with the following test program (repro.py):\nrepro.py\n\n```python\nimport torch\n\n@torch.compile()\ndef test_model(x):\n    model = torch.nn.Sequential(\n        torch.nn.Linear(10, 10),\n        torch.nn.LayerNorm(10),\n        torch.nn.ReLU(),\n    )\n    return model(x)\n\n\ny = test_model(torch.ones(10, 10))\n\n```\n\nSetting the environment variableTORCH_COMPILE_DEBUG=1will cause a\ndebug trace directory to be created, by default this directory will be in the\ncurrent directory and named torch_compile_debug (this can be overridden in\nthe torchdynamo configuration fielddebug_dir_rootand also theenvvarTORCH_COMPILE_DEBUG_DIR). Inside this directory, each run will\nhave a separate folder named with the timestamp and process id of the run:\nTORCH_COMPILE_DEBUG=1\ndebug_dir_root\nenvvarTORCH_COMPILE_DEBUG_DIR\n\n```python\n$ env TORCH_COMPILE_DEBUG=1 python repro.py\n$ cd torch_compile_debug\n$ ls\nrun_2023_03_01_08_20_52_143510-pid_180167\n\n```\n\nIn the run folder there will be atorchdynamodirectory which contains\ndebug logs, and antorchinductorfolder which contains a subfolder for each\ncompiled kernel with inductor debug artifacts.\ntorchdynamo\ntorchinductor\n\n```python\n$ cd\nrun_2023_03_01_08_20_52_143510-pid_180167\n$ ls\ntorchinductor  torchdynamo\n\n```\n\nMoving further into thetorchinductordirectory, the\\*.logfiles are\nlogs from the AOT Autograd phase of compilation,model__0_forward_1.0contains\nthe inductor debug artifacts.\ntorchinductor\n\\*.log\nmodel__0_forward_1.0\n\n```python\n$ cd torchinductor\n$ ls\naot_model___0_debug.log  model__0_forward_1.0\n$ cd model__0_forward_1.0\n$ ls\ndebug.log  fx_graph_readable.py  fx_graph_runnable.py  fx_graph_transformed.py  ir_post_fusion.txt  ir_pre_fusion.txt  output_code.py\n\n```\n\nHere is a summary of the contents:\nfx_graph_readable.pyandfx_graph_runnable.pyare the readable and\nrunnable versions of thefx_graphreceived by inductor.\nfx_graph_readable.py\nfx_graph_runnable.py\nfx_graph\nfx_graph_transformed.pyis the fx graph after inductor has run all fx passes.\nfx_graph_transformed.py\nir\\*.txtis the inductor ir pre and post fusion.\nir\\*.txt\noutput_code.pyis the compiled triton kernel for the subgraph.\noutput_code.py\nHere areexample debug directory contentsfor the test program:\n\n```python\nimport torch\n\n@torch.compile()\ndef test_model(x):\n    model = torch.nn.Sequential(\n        torch.nn.Linear(10, 10),\n        torch.nn.LayerNorm(10),\n        torch.nn.ReLU(),\n    )\n    return model(x)\n\n\ny = test_model(torch.ones(10, 10))\n\n```\n\nEach file in that debug trace can be enabled and disabled throughtorch._inductor.config.trace.*. The profile and the diagram are both\ndisabled by default since they are expensive to generate.\ntorch._inductor.config.trace.*\nA single node in this new debug format looks like:\n\n```python\nbuf1: SchedulerNode(ComputedBuffer)\nbuf1.writes =\n    {   MemoryDep(name='buf1', index=0, size=()),\n        MemoryDep(name='buf1', index=0, size=(s0,))}\nbuf1.unmet_dependencies = {MemoryDep(name='buf0', index=c0, size=(s0,))}\nbuf1.met_dependencies = {MemoryDep(name='primals_2', index=c0, size=(s0,))}\nbuf1.group.device = cuda:0\nbuf1.group.iteration = (1, s0)\nbuf1.sizes = ([], [s0])\nclass buf1_loop_body:\n    var_ranges = {z0: s0}\n    index0 = z0\n    index1 = 0\n    def body(self, ops):\n        get_index = self.get_index('index0')\n        load = ops.load('buf0', get_index, False)\n        get_index_1 = self.get_index('index0')\n        load_1 = ops.load('primals_2', get_index_1, False)\n        add = ops.add(load, load_1)\n        get_index_2 = self.get_index('index1')\n        reduction = ops.reduction('buf1', torch.float32, torch.float32, 'sum', get_index_2, add)\n        return reduction\n\n```\n\nSee theexample debug directory\noutputfor more examples.\n\n## Graph Breaks#\n\nGiven a program like this:\n\n```python\ndef some_fun(x):\n    ...\n\ncompiled_fun = torch.compile(some_fun, ...)\n...\n\n```\n\nTorchDynamo will attempt to compile all of the torch/tensor operations\nwithin some_fun into a single FX graph, but it may fail to capture\neverything into one graph.\nSome graph break reasons are insurmountable to TorchDynamo, and can\u2019t be\neasily fixed. - calling into a C extension other than torch is invisible\nto torchdynamo, and could do arbitrary things without TorchDynamo being\nable to introduce necessary guards (seeMaking Dynamo Sound: Guards)\nto ensure that the compiled program would be safe to reuse. Graph breaks\ncan hinder performance if the resulting fragments are small. To maximize\nperformance, it\u2019s important to have as few graph breaks as possible.\n\n## Identifying the Cause of a Graph Break#\n\nTo identify all graph breaks in a program and the associated reasons for\nthe breaks,torch._dynamo.explaincan be used. This tool runs\nTorchDynamo on the supplied function and aggregates the graph breaks\nthat are encountered. Here is an example usage:\ntorch._dynamo.explain\n\n```python\nimport torch\nimport torch._dynamo as dynamo\ndef toy_example(a, b):\n    x = a / (torch.abs(a) + 1)\n    print(\"woo\")\n    if b.sum() < 0:\n        b = b * -1\n    return x * b\nexplanation = dynamo.explain(toy_example)(torch.randn(10), torch.randn(10))\nprint(explanation_verbose)\n\"\"\"\nGraph Count: 3\nGraph Break Count: 2\nOp Count: 5\nBreak Reasons:\n  Break Reason 1:\n    Reason: builtin: print [<class 'torch._dynamo.variables.constant.ConstantVariable'>] False\n    User Stack:\n      <FrameSummary file foo.py, line 5 in toy_example>\n  Break Reason 2:\n    Reason: generic_jump TensorVariable()\n    User Stack:\n      <FrameSummary file foo.py, line 6 in torch_dynamo_resume_in_toy_example_at_5>\nOps per Graph:\n  ...\nOut Guards:\n  ...\n\"\"\"\n\n```\n\nOutputs include:\nout_guards- a list of lists where each sublist contains the guards that must pass to ensure the traced graphs are valid.\nout_guards\ngraphs- a list of graph modules which were successfully traced.\ngraphs\nops_per_graph- a list of lists where each sublist contains the ops that are run in the graph.\nops_per_graph\nTo throw an error on the first graph break encountered, use thefullgraphmode. This mode disables TorchDynamo\u2019s Python fallback, and only\nsucceeds if the entire program is convertible into a single graph. Example\nusage:\nfullgraph\n\n```python\ndef toy_example(a, b):\n   ...\n\ncompiled_toy = torch.compile(toy_example, fullgraph=True, backend=<compiler>)(a, b)\n\n```\n\n\n## Excessive Recompilation#\n\nWhen TorchDynamo compiles a function (or part of one), it makes certain\nassumptions about locals and globals in order to allow compiler\noptimizations, and expresses these assumptions as guards that check\nparticular values at runtime. If any of these guards fail, Dynamo will\nrecompile that function (or part) up totorch._dynamo.config.recompile_limittimes. If your program is\nhitting the cache limit, you will first need to determine which guard is\nfailing and what part of your program is triggering it.\ntorch._dynamo.config.recompile_limit\nIf your program exhibits a bounded amount of dynamism, you may be able\nto tune the TorchDynamo cache limit to allow for each variation to be\ncompiled and cached, but if the cache limit is too high you may find the\ncost of recompilation outweighs any optimization benefits.\n\n```python\ntorch._dynamo.config.recompile_limit = <your desired cache limit>\n\n```\n\nTorchDynamo plans to support many common cases of dynamic tensor shapes,\nsuch as varying batch size or sequence length. It does not plan to\nsupport rank-dynamism. In the meantime, setting a specific cache limit\ncan be used in coordination with bucketing techniques to achieve an\nacceptable number of recompilations for some dynamic models.\n\n## Accuracy Debugging#\n\nAccuracy issues can also be minified if you set the environment variableTORCHDYNAMO_REPRO_LEVEL=4, it operates with a similar git bisect\nmodel and a full repro might be something likeTORCHDYNAMO_REPRO_AFTER=\"aot\"TORCHDYNAMO_REPRO_LEVEL=4the reason\nwe need this is downstream compilers will codegen code whether it\u2019s\nTriton code or the C++ backend, the numerics from those downstream\ncompilers can be different in subtle ways yet have dramatic impact on\nyour training stability. So the accuracy debugger is very useful for us\nto detect bugs in our codegen or with a backend compiler.\nTORCHDYNAMO_REPRO_LEVEL=4\nTORCHDYNAMO_REPRO_AFTER=\"aot\"TORCHDYNAMO_REPRO_LEVEL=4\nIf you\u2019d like to ensure that random number generation is the same across both torch\nand triton then you can enabletorch._inductor.config.fallback_random=True\ntorch._inductor.config.fallback_random=True\n\n## Extended Debugging#\n\nExtended debugging can be enabled by using the following experimental flags.\nTORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED- provides extended debug information if the\nstring representation of a guard matches this flag value. For example, set it to\n\u201cNe(s0, 10)\u201d to generate full Python and C++ backtrace whenever guard was issued.TORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL- provides extended debug information when\na particular symbol is allocated. For example, set this to \u201cu2\u201d to generate full Python\nand C++ backtrace whenever this symbol was created.TORCHDYNAMO_EXTENDED_DEBUG_CPP- provides extended debug information (C++ backtrace)\nfor all extended debug settings as well as errors. For example, set this to \u201c1\u201d. The C++\nbacktrace is slow and very spammy so it is not included by default with extended debugging.\nTORCHDYNAMO_EXTENDED_DEBUG_GUARD_ADDED\nTORCHDYNAMO_EXTENDED_DEBUG_CREATE_SYMBOL\nTORCHDYNAMO_EXTENDED_DEBUG_CPP\n\n## Cold Start Timing and Cache Corruption Debugging#\n\nIn order to measure the cold start compilation time or debug a cache corruption,\nit is possible passTORCHINDUCTOR_FORCE_DISABLE_CACHES=1or settorch.compiler.config.force_disable_caches=Truewhich will override any\nother caching config option and disable all compile time caching.\nTORCHINDUCTOR_FORCE_DISABLE_CACHES=1\ntorch.compiler.config.force_disable_caches=True",
  "url": "https://pytorch.org/docs/stable/torch.compiler_troubleshooting_old.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}