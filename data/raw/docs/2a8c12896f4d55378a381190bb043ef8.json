{
  "doc_id": "2a8c12896f4d55378a381190bb043ef8",
  "source": "pytorch_docs",
  "title": "python.builtin \u2014 PyTorch 2.9 documentation",
  "text": "\n## python.builtin#\n\n\n## dynamic_shape_round#\n\nNote\nTags:python.builtin,torch.dynamic-shape\nSupport Level: NOT_SUPPORTED_YET\nOriginal source code:\n\n```python\n# mypy: allow-untyped-defs\nimport torch\n\nfrom torch._export.db.case import SupportLevel\nfrom torch.export import Dim\n\nclass DynamicShapeRound(torch.nn.Module):\n    \"\"\"\n    Calling round on dynamic shapes is not supported.\n    \"\"\"\n\n    def forward(self, x):\n        return x[: round(x.shape[0] / 2)]\n\nx = torch.randn(3, 2)\ndim0_x = Dim(\"dim0_x\")\nexample_args = (x,)\ntags = {\"torch.dynamic-shape\", \"python.builtin\"}\nsupport_level = SupportLevel.NOT_SUPPORTED_YET\ndynamic_shapes = {\"x\": {0: dim0_x}}\nmodel = DynamicShapeRound()\n\n\ntorch.export.export(model, example_args, dynamic_shapes=dynamic_shapes)\n\n```\n\nResult:\n\n```python\nUnsupported: Constraints violated (dim0_x)! For more information, run with TORCH_LOGS=\"+dynamic\".\n\n```\n\n\n## tensor_setattr#\n\nNote\nTags:python.builtin\nSupport Level: SUPPORTED\nOriginal source code:\n\n```python\n# mypy: allow-untyped-defs\nimport torch\n\n\nclass TensorSetattr(torch.nn.Module):\n    \"\"\"\n    setattr() call onto tensors is not supported.\n    \"\"\"\n    def forward(self, x, attr):\n        setattr(x, attr, torch.randn(3, 2))\n        return x + 4\n\nexample_args = (torch.randn(3, 2), \"attr\")\ntags = {\"python.builtin\"}\nmodel = TensorSetattr()\n\n\ntorch.export.export(model, example_args)\n\n```\n\nResult:\n\n```python\nExportedProgram:\n    class GraphModule(torch.nn.Module):\n        def forward(self, x: \"f32[3, 2]\", attr):\n                 randn: \"f32[3, 2]\" = torch.ops.aten.randn.default([3, 2], device = device(type='cpu'), pin_memory = False);  randn = None\n\n                 add: \"f32[3, 2]\" = torch.ops.aten.add.Tensor(x, 4);  x = None\n            return (add,)\n\nGraph signature:\n    # inputs\n    x: USER_INPUT\n    attr: USER_INPUT\n\n    # outputs\n    add: USER_OUTPUT\n\nRange constraints: {}\n\n```\n\n\n## type_reflection_method#\n\nNote\nTags:python.builtin\nSupport Level: SUPPORTED\nOriginal source code:\n\n```python\n# mypy: allow-untyped-defs\nimport torch\n\nclass A:\n    @classmethod\n    def func(cls, x):\n        return 1 + x\n\nclass TypeReflectionMethod(torch.nn.Module):\n    \"\"\"\n    type() calls on custom objects followed by attribute accesses are not allowed\n    due to its overly dynamic nature.\n    \"\"\"\n\n    def forward(self, x):\n        a = A()\n        return type(a).func(x)\n\n\nexample_args = (torch.randn(3, 4),)\ntags = {\"python.builtin\"}\nmodel = TypeReflectionMethod()\n\n\ntorch.export.export(model, example_args)\n\n```\n\nResult:\n\n```python\nExportedProgram:\n    class GraphModule(torch.nn.Module):\n        def forward(self, x: \"f32[3, 4]\"):\n                 add: \"f32[3, 4]\" = torch.ops.aten.add.Tensor(x, 1);  x = None\n            return (add,)\n\nGraph signature:\n    # inputs\n    x: USER_INPUT\n\n    # outputs\n    add: USER_OUTPUT\n\nRange constraints: {}\n\n```\n",
  "url": "https://pytorch.org/docs/stable/generated/exportdb/python.builtin.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}