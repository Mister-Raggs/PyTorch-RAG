{
  "doc_id": "8f43f1bc4b55d8503c9bbd394c2fc963",
  "source": "pytorch_docs",
  "title": "torch.load \u2014 PyTorch 2.9 documentation",
  "text": "\n## torch.load#\n\nLoads an object saved withtorch.save()from a file.\ntorch.save()\ntorch.load()uses Python\u2019s unpickling facilities but treats storages,\nwhich underlie tensors, specially. They are first deserialized on the\nCPU and are then moved to the device they were saved from. If this fails\n(e.g. because the run time system doesn\u2019t have certain devices), an exception\nis raised. However, storages can be dynamically remapped to an alternative\nset of devices using themap_locationargument.\ntorch.load()\nmap_location\nIfmap_locationis a callable, it will be called once for each serialized\nstorage with two arguments: storage and location. The storage argument\nwill be the initial deserialization of the storage, residing on the CPU.\nEach serialized storage has a location tag associated with it which\nidentifies the device it was saved from, and this tag is the second\nargument passed tomap_location. The builtin location tags are'cpu'for CPU tensors and'cuda:device_id'(e.g.'cuda:2') for CUDA tensors.map_locationshould return eitherNoneor a storage. Ifmap_locationreturns a storage, it will be used as the final deserialized\nobject, already moved to the right device. Otherwise,torch.load()will\nfall back to the default behavior, as ifmap_locationwasn\u2019t specified.\nmap_location\nmap_location\n'cpu'\n'cuda:device_id'\n'cuda:2'\nmap_location\nNone\nmap_location\ntorch.load()\nmap_location\nIfmap_locationis atorch.deviceobject or a string containing\na device tag, it indicates the location where all tensors should be loaded.\nmap_location\ntorch.device\nOtherwise, ifmap_locationis a dict, it will be used to remap location tags\nappearing in the file (keys), to ones that specify where to put the\nstorages (values).\nmap_location\nUser extensions can register their own location tags and tagging and\ndeserialization methods usingtorch.serialization.register_package().\ntorch.serialization.register_package()\nSeeLayout Controlfor more advanced tools to manipulate a checkpoint.\nf(Union[str,PathLike[str],IO[bytes]]) \u2013 a file-like object (has to implementread(),readline(),tell(), andseek()),\nor a string or os.PathLike object containing a file name\nread()\nreadline()\ntell()\nseek()\nmap_location(Optional[Union[Callable[[Storage,str],Storage],device,str,dict[str,str]]]) \u2013 a function,torch.device, string or a dict specifying how to remap storage\nlocations\ntorch.device\npickle_module(Optional[Any]) \u2013 module used for unpickling metadata and objects (has to\nmatch thepickle_moduleused to serialize file)\npickle_module\nweights_only(Optional[bool]) \u2013 Indicates whether unpickler should be restricted to\nloading only tensors, primitive types, dictionaries\nand any types added viatorch.serialization.add_safe_globals().\nSeetorch.load with weights_only=Truefor more details.\ntorch.serialization.add_safe_globals()\nmmap(Optional[bool]) \u2013 Indicates whether the file should be mapped rather than loading all the storages into memory.\nTypically, tensor storages in the file will first be moved from disk to CPU memory, after which they\nare moved to the location that they were tagged with when saving, or specified bymap_location. This\nsecond step is a no-op if the final location is CPU. When themmapflag is set, instead of copying the\ntensor storages from disk to CPU memory in the first step,fis mapped, which means tensor storages\nwill be lazily loaded when their data is accessed.\nmap_location\nmmap\nf\npickle_load_args(Any) \u2013 (Python 3 only) optional keyword arguments passed over topickle_module.load()andpickle_module.Unpickler(), e.g.,errors=....\npickle_module.load()\npickle_module.Unpickler()\nerrors=...\nAny\nWarning\ntorch.load()unlessweights_onlyparameter is set toTrue,\nusespicklemodule implicitly, which is known to be insecure.\nIt is possible to construct malicious pickle data which will execute arbitrary code\nduring unpickling. Never load data that could have come from an untrusted\nsource in an unsafe mode, or that could have been tampered with.Only load data you trust.\ntorch.load()\npickle\nNote\nWhen you calltorch.load()on a file which contains GPU tensors, those tensors\nwill be loaded to GPU by default. You can calltorch.load(..,map_location='cpu')and thenload_state_dict()to avoid GPU RAM surge when loading a model checkpoint.\ntorch.load()\ntorch.load(..,map_location='cpu')\nload_state_dict()\nNote\nBy default, we decode byte strings asutf-8.  This is to avoid a common error\ncaseUnicodeDecodeError:'ascii'codeccan'tdecodebyte0x...when loading files saved by Python 2 in Python 3.  If this default\nis incorrect, you may use an extraencodingkeyword argument to specify how\nthese objects should be loaded, e.g.,encoding='latin1'decodes them\nto strings usinglatin1encoding, andencoding='bytes'keeps them\nas byte arrays which can be decoded later withbyte_array.decode(...).\nutf-8\nUnicodeDecodeError:'ascii'codeccan'tdecodebyte0x...\nencoding\nencoding='latin1'\nlatin1\nencoding='bytes'\nbyte_array.decode(...)\nExample\n\n```python\n>>> torch.load(\"tensors.pt\", weights_only=True)\n# Load all tensors onto the CPU\n>>> torch.load(\n...     \"tensors.pt\",\n...     map_location=torch.device(\"cpu\"),\n...     weights_only=True,\n... )\n# Load all tensors onto the CPU, using a function\n>>> torch.load(\n...     \"tensors.pt\",\n...     map_location=lambda storage, loc: storage,\n...     weights_only=True,\n... )\n# Load all tensors onto GPU 1\n>>> torch.load(\n...     \"tensors.pt\",\n...     map_location=lambda storage, loc: storage.cuda(1),\n...     weights_only=True,\n... )  # type: ignore[attr-defined]\n# Map tensors from GPU 1 to GPU 0\n>>> torch.load(\n...     \"tensors.pt\",\n...     map_location={\"cuda:1\": \"cuda:0\"},\n...     weights_only=True,\n... )\n# Load tensor from io.BytesIO object\n# Loading from a buffer setting weights_only=False, warning this can be unsafe\n>>> with open(\"tensor.pt\", \"rb\") as f:\n...     buffer = io.BytesIO(f.read())\n>>> torch.load(buffer, weights_only=False)\n# Load a module with 'ascii' encoding for unpickling\n# Loading from a module setting weights_only=False, warning this can be unsafe\n>>> torch.load(\"module.pt\", encoding=\"ascii\", weights_only=False)\n\n```\n",
  "url": "https://pytorch.org/docs/stable/generated/torch.load.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}