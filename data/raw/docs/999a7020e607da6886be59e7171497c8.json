{
  "doc_id": "999a7020e607da6886be59e7171497c8",
  "source": "pytorch_docs",
  "title": "Getting Started on Intel GPU \u2014 PyTorch 2.9 documentation",
  "text": "\n## Getting Started on Intel GPU#\n\nCreated On: Jun 14, 2024 | Last Updated On: Sep 01, 2025\n\n## Hardware Prerequisite#\n\nFor Intel Data Center GPU\nDevice\nRed Hat* Enterprise Linux* 9.2\nSUSE Linux Enterprise Server* 15 SP5\nUbuntu* Server 22.04 (>= 5.15 LTS kernel)\nIntel\u00ae Data Center GPU Max Series (CodeName: Ponte Vecchio)\nyes\nyes\nyes\nFor Intel Client GPU\nSupported OS\nValidated Hardware\nIntel GPUs support (Prototype) is ready from PyTorch* 2.5 for Intel\u00ae Client GPUs and Intel\u00ae Data Center GPU Max Series on both Linux and Windows, which brings Intel GPUs and the SYCL* software stack into the official PyTorch stack with consistent user experience to embrace more AI application scenarios.\n\n## Software Prerequisite#\n\nTo use PyTorch on Intel GPUs, you need to install the Intel GPUs driver first. For installation guide, visitIntel GPUs Driver Installation.\nPlease skip the Intel\u00ae Deep Learning Essentials installation section if you install from binaries. For building from source, please refer toPyTorch Installation Prerequisites for Intel GPUsfor both Intel GPU Driver and Intel\u00ae Deep Learning Essentials Installation.\n\n## Installation#\n\n\n## Binaries#\n\nNow that we haveIntel GPU Driverinstalled, use the following commands to installpytorch,torchvision,torchaudio.\npytorch\ntorchvision\ntorchaudio\nFor release wheels\n\n```python\npip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/xpu\n\n```\n\nFor nightly wheels\n\n```python\npip3 install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/xpu\n\n```\n\n\n## From Source#\n\nNow that we haveIntel GPU Driver and Intel\u00ae Deep Learning Essentialsinstalled. Follow guides to buildpytorch,torchvision,torchaudiofrom source.\npytorch\ntorchvision\ntorchaudio\nBuild from source fortorchrefer toPyTorch Installation Build from source.\ntorch\nBuild from source fortorchvisionrefer toTorchvision Installation Build from source.\ntorchvision\nBuild from source fortorchaudiorefer toTorchaudio Installation Build from source.\ntorchaudio\n\n## Check availability for Intel GPU#\n\nTo check if your Intel GPU is available, you would typically use the following code:\n\n```python\nimport torch\nprint(torch.xpu.is_available())  # torch.xpu is the API for Intel GPU support\n\n```\n\nIf the output isFalse, double check driver installation for Intel GPUs.\nFalse\n\n## Minimum Code Change#\n\nIf you are migrating code fromcuda, you would change references fromcudatoxpu. For example:\ncuda\ncuda\nxpu\n\n```python\n# CUDA CODE\ntensor = torch.tensor([1.0, 2.0]).to(\"cuda\")\n\n# CODE for Intel GPU\ntensor = torch.tensor([1.0, 2.0]).to(\"xpu\")\n\n```\n\nThe following points outline the support and limitations for PyTorch with Intel GPU:\nBoth training and inference workflows are supported.\nBoth eager mode andtorch.compileis supported. The featuretorch.compileis also supported on Windows from PyTorch* 2.7 with Intel GPU, refer toHow to use torch.compile on Windows CPU/XPU.\ntorch.compile\ntorch.compile\nData types such as FP32, BF16, FP16, and Automatic Mixed Precision (AMP) are all supported.\n\n## Examples#\n\nThis section contains usage examples for both inference and training workflows.\n\n## Inference Examples#\n\nHere is a few inference workflow examples.\n\n```python\nimport torch\nimport torchvision.models as models\n\nmodel = models.resnet50(weights=\"ResNet50_Weights.DEFAULT\")\nmodel.eval()\ndata = torch.rand(1, 3, 224, 224)\n\nmodel = model.to(\"xpu\")\ndata = data.to(\"xpu\")\n\nwith torch.no_grad():\n    model(data)\n\nprint(\"Execution finished\")\n\n```\n\n\n```python\nimport torch\nimport torchvision.models as models\n\nmodel = models.resnet50(weights=\"ResNet50_Weights.DEFAULT\")\nmodel.eval()\ndata = torch.rand(1, 3, 224, 224)\n\nmodel = model.to(\"xpu\")\ndata = data.to(\"xpu\")\n\nwith torch.no_grad():\n    d = torch.rand(1, 3, 224, 224)\n    d = d.to(\"xpu\")\n    # set dtype=torch.bfloat16 for BF16\n    with torch.autocast(device_type=\"xpu\", dtype=torch.float16, enabled=True):\n        model(data)\n\nprint(\"Execution finished\")\n\n```\n\ntorch.compile\n\n```python\nimport torch\nimport torchvision.models as models\nimport time\n\nmodel = models.resnet50(weights=\"ResNet50_Weights.DEFAULT\")\nmodel.eval()\ndata = torch.rand(1, 3, 224, 224)\nITERS = 10\n\nmodel = model.to(\"xpu\")\ndata = data.to(\"xpu\")\n\nfor i in range(ITERS):\n    start = time.time()\n    with torch.no_grad():\n        model(data)\n        torch.xpu.synchronize()\n    end = time.time()\n    print(f\"Inference time before torch.compile for iteration {i}: {(end-start)*1000} ms\")\n\nmodel = torch.compile(model)\nfor i in range(ITERS):\n    start = time.time()\n    with torch.no_grad():\n        model(data)\n        torch.xpu.synchronize()\n    end = time.time()\n    print(f\"Inference time after torch.compile for iteration {i}: {(end-start)*1000} ms\")\n\nprint(\"Execution finished\")\n\n```\n\n\n## Training Examples#\n\nHere is a few training workflow examples.\n\n```python\nimport torch\nimport torchvision\n\nLR = 0.001\nDOWNLOAD = True\nDATA = \"datasets/cifar10/\"\n\ntransform = torchvision.transforms.Compose(\n    [\n        torchvision.transforms.Resize((224, 224)),\n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    ]\n)\ntrain_dataset = torchvision.datasets.CIFAR10(\n    root=DATA,\n    train=True,\n    transform=transform,\n    download=DOWNLOAD,\n)\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128)\ntrain_len = len(train_loader)\n\nmodel = torchvision.models.resnet50()\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\nmodel.train()\nmodel = model.to(\"xpu\")\ncriterion = criterion.to(\"xpu\")\n\nprint(f\"Initiating training\")\nfor batch_idx, (data, target) in enumerate(train_loader):\n    data = data.to(\"xpu\")\n    target = target.to(\"xpu\")\n    optimizer.zero_grad()\n    output = model(data)\n    loss = criterion(output, target)\n    loss.backward()\n    optimizer.step()\n    if (batch_idx + 1) % 10 == 0:\n         iteration_loss = loss.item()\n         print(f\"Iteration [{batch_idx+1}/{train_len}], Loss: {iteration_loss:.4f}\")\ntorch.save(\n    {\n        \"model_state_dict\": model.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n    },\n    \"checkpoint.pth\",\n)\n\nprint(\"Execution finished\")\n\n```\n\nNote: Training withGradScalerrequires hardware support forFP64.FP64is not natively supported by the Intel\u00ae Arc\u2122 A-Series Graphics. If you run your workloads on Intel\u00ae Arc\u2122 A-Series Graphics, please disableGradScaler.\nGradScaler\nFP64\nFP64\nGradScaler\n\n```python\nimport torch\nimport torchvision\n\nLR = 0.001\nDOWNLOAD = True\nDATA = \"datasets/cifar10/\"\n\nuse_amp=True\n\ntransform = torchvision.transforms.Compose(\n    [\n        torchvision.transforms.Resize((224, 224)),\n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    ]\n)\ntrain_dataset = torchvision.datasets.CIFAR10(\n    root=DATA,\n    train=True,\n    transform=transform,\n    download=DOWNLOAD,\n)\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128)\ntrain_len = len(train_loader)\n\nmodel = torchvision.models.resnet50()\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\nscaler = torch.amp.GradScaler(device=\"xpu\", enabled=use_amp)\n\nmodel.train()\nmodel = model.to(\"xpu\")\ncriterion = criterion.to(\"xpu\")\n\nprint(f\"Initiating training\")\nfor batch_idx, (data, target) in enumerate(train_loader):\n    data = data.to(\"xpu\")\n    target = target.to(\"xpu\")\n    # set dtype=torch.bfloat16 for BF16\n    with torch.autocast(device_type=\"xpu\", dtype=torch.float16, enabled=use_amp):\n        output = model(data)\n        loss = criterion(output, target)\n    scaler.scale(loss).backward()\n    scaler.step(optimizer)\n    scaler.update()\n    optimizer.zero_grad()\n    if (batch_idx + 1) % 10 == 0:\n         iteration_loss = loss.item()\n         print(f\"Iteration [{batch_idx+1}/{train_len}], Loss: {iteration_loss:.4f}\")\n\ntorch.save(\n    {\n        \"model_state_dict\": model.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n    },\n    \"checkpoint.pth\",\n)\n\nprint(\"Execution finished\")\n\n```\n\ntorch.compile\n\n```python\nimport torch\nimport torchvision\n\nLR = 0.001\nDOWNLOAD = True\nDATA = \"datasets/cifar10/\"\n\ntransform = torchvision.transforms.Compose(\n    [\n        torchvision.transforms.Resize((224, 224)),\n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n    ]\n)\ntrain_dataset = torchvision.datasets.CIFAR10(\n    root=DATA,\n    train=True,\n    transform=transform,\n    download=DOWNLOAD,\n)\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=128)\ntrain_len = len(train_loader)\n\nmodel = torchvision.models.resnet50()\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=LR, momentum=0.9)\nmodel.train()\nmodel = model.to(\"xpu\")\ncriterion = criterion.to(\"xpu\")\nmodel = torch.compile(model)\n\nprint(f\"Initiating training with torch compile\")\nfor batch_idx, (data, target) in enumerate(train_loader):\n    data = data.to(\"xpu\")\n    target = target.to(\"xpu\")\n    optimizer.zero_grad()\n    output = model(data)\n    loss = criterion(output, target)\n    loss.backward()\n    optimizer.step()\n    if (batch_idx + 1) % 10 == 0:\n         iteration_loss = loss.item()\n         print(f\"Iteration [{batch_idx+1}/{train_len}], Loss: {iteration_loss:.4f}\")\ntorch.save(\n    {\n        \"model_state_dict\": model.state_dict(),\n        \"optimizer_state_dict\": optimizer.state_dict(),\n    },\n    \"checkpoint.pth\",\n)\n\nprint(\"Execution finished\")\n\n```\n",
  "url": "https://pytorch.org/docs/stable/notes/get_start_xpu.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}