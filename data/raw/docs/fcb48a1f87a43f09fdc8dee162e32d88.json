{
  "doc_id": "fcb48a1f87a43f09fdc8dee162e32d88",
  "source": "pytorch_docs",
  "title": "torch.utils.tensorboard \u2014 PyTorch 2.9 documentation",
  "text": "\n## torch.utils.tensorboard#\n\nCreated On: Apr 25, 2019 | Last Updated On: Mar 10, 2022\nBefore going further, more details on TensorBoard can be found athttps://www.tensorflow.org/tensorboard/\nOnce you\u2019ve installed TensorBoard, these utilities let you log PyTorch models\nand metrics into a directory for visualization within the TensorBoard UI.\nScalars, images, histograms, graphs, and embedding visualizations are all\nsupported for PyTorch models and tensors as well as Caffe2 nets and blobs.\nThe SummaryWriter class is your main entry to log data for consumption\nand visualization by TensorBoard. For example:\n\n```python\nimport torch\nimport torchvision\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchvision import datasets, transforms\n\n# Writer will output to ./runs/ directory by default\nwriter = SummaryWriter()\n\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\ntrainset = datasets.MNIST('mnist_train', train=True, download=True, transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\nmodel = torchvision.models.resnet50(False)\n# Have ResNet model take in grayscale rather than RGB\nmodel.conv1 = torch.nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\nimages, labels = next(iter(trainloader))\n\ngrid = torchvision.utils.make_grid(images)\nwriter.add_image('images', grid, 0)\nwriter.add_graph(model, images)\nwriter.close()\n\n```\n\nThis can then be visualized with TensorBoard, which should be installable\nand runnable with:\n\n```python\npip install tensorboard\ntensorboard --logdir=runs\n\n```\n\nLots of information can be logged for one experiment. To avoid cluttering\nthe UI and have better result clustering, we can group plots by naming them\nhierarchically. For example, \u201cLoss/train\u201d and \u201cLoss/test\u201d will be grouped\ntogether, while \u201cAccuracy/train\u201d and \u201cAccuracy/test\u201d will be grouped separately\nin the TensorBoard interface.\n\n```python\nfrom torch.utils.tensorboard import SummaryWriter\nimport numpy as np\n\nwriter = SummaryWriter()\n\nfor n_iter in range(100):\n    writer.add_scalar('Loss/train', np.random.random(), n_iter)\n    writer.add_scalar('Loss/test', np.random.random(), n_iter)\n    writer.add_scalar('Accuracy/train', np.random.random(), n_iter)\n    writer.add_scalar('Accuracy/test', np.random.random(), n_iter)\n\n```\n\nExpected result:\nWrites entries directly to event files in the log_dir to be consumed by TensorBoard.\nTheSummaryWriterclass provides a high-level API to create an event file\nin a given directory and add summaries and events to it. The class updates the\nfile contents asynchronously. This allows a training program to call methods\nto add data to the file directly from the training loop, without slowing down\ntraining.\nCreate aSummaryWriterthat will write out events and summaries to the event file.\nlog_dir(str) \u2013 Save directory location. Default is\nruns/CURRENT_DATETIME_HOSTNAME, which changes after each run.\nUse hierarchical folder structure to compare\nbetween runs easily. e.g. pass in \u2018runs/exp1\u2019, \u2018runs/exp2\u2019, etc.\nfor each new experiment to compare across them.\ncomment(str) \u2013 Comment log_dir suffix appended to the defaultlog_dir. Iflog_diris assigned, this argument has no effect.\nlog_dir\nlog_dir\npurge_step(int) \u2013 When logging crashes at stepT+XT+XT+Xand restarts at stepTTT,\nany events whose global_step larger or equal toTTTwill be\npurged and hidden from TensorBoard.\nNote that crashed and resumed experiments should have the samelog_dir.\nlog_dir\nmax_queue(int) \u2013 Size of the queue for pending events and\nsummaries before one of the \u2018add\u2019 calls forces a flush to disk.\nDefault is ten items.\nflush_secs(int) \u2013 How often, in seconds, to flush the\npending events and summaries to disk. Default is every two minutes.\nfilename_suffix(str) \u2013 Suffix added to all event filenames in\nthe log_dir directory. More details on filename construction in\ntensorboard.summary.writer.event_file_writer.EventFileWriter.\nExamples:\n\n```python\nfrom torch.utils.tensorboard import SummaryWriter\n\n# create a summary writer with automatically generated folder name.\nwriter = SummaryWriter()\n# folder location: runs/May04_22-14-54_s-MacBook-Pro.local/\n\n# create a summary writer using the specified folder name.\nwriter = SummaryWriter(\"my_experiment\")\n# folder location: my_experiment\n\n# create a summary writer with comment appended.\nwriter = SummaryWriter(comment=\"LR_0.1_BATCH_16\")\n# folder location: runs/May04_22-14-54_s-MacBook-Pro.localLR_0.1_BATCH_16/\n\n```\n\nAdd scalar data to summary.\ntag(str) \u2013 Data identifier\nscalar_value(floatorstring/blobname) \u2013 Value to save\nglobal_step(int) \u2013 Global step value to record\nwalltime(float) \u2013 Optional override default walltime (time.time())\nwith seconds after epoch of event\nnew_style(boolean) \u2013 Whether to use new style (tensor field) or old\nstyle (simple_value field). New style could lead to faster data loading.\nExamples:\n\n```python\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()\nx = range(100)\nfor i in x:\n    writer.add_scalar('y=2x', i * 2, i)\nwriter.close()\n\n```\n\nExpected result:\nAdd many scalar data to summary.\nmain_tag(str) \u2013 The parent name for the tags\ntag_scalar_dict(dict) \u2013 Key-value pair storing the tag and corresponding values\nglobal_step(int) \u2013 Global step value to record\nwalltime(float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\nExamples:\n\n```python\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()\nr = 5\nfor i in range(100):\n    writer.add_scalars('run_14h', {'xsinx':i*np.sin(i/r),\n                                    'xcosx':i*np.cos(i/r),\n                                    'tanx': np.tan(i/r)}, i)\nwriter.close()\n# This call adds three values to the same scalar plot with the tag\n# 'run_14h' in TensorBoard's scalar section.\n\n```\n\nExpected result:\nAdd histogram to summary.\ntag(str) \u2013 Data identifier\nvalues(torch.Tensor,numpy.ndarray, orstring/blobname) \u2013 Values to build histogram\nglobal_step(int) \u2013 Global step value to record\nbins(str) \u2013 One of {\u2018tensorflow\u2019,\u2019auto\u2019, \u2018fd\u2019, \u2026}. This determines how the bins are made. You can find\nother options in:https://numpy.org/doc/stable/reference/generated/numpy.histogram.html\nwalltime(float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\nExamples:\n\n```python\nfrom torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nwriter = SummaryWriter()\nfor i in range(10):\n    x = np.random.random(1000)\n    writer.add_histogram('distribution centers', x + i, i)\nwriter.close()\n\n```\n\nExpected result:\nAdd image data to summary.\nNote that this requires thepillowpackage.\npillow\ntag(str) \u2013 Data identifier\nimg_tensor(torch.Tensor,numpy.ndarray, orstring/blobname) \u2013 Image data\nglobal_step(int) \u2013 Global step value to record\nwalltime(float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\ndataformats(str) \u2013 Image data format specification of the form\nCHW, HWC, HW, WH, etc.\nimg_tensor: Default is(3,H,W)(3, H, W)(3,H,W). You can usetorchvision.utils.make_grid()to\nconvert a batch of tensor into 3xHxW format or calladd_imagesand let us do the job.\nTensor with(1,H,W)(1, H, W)(1,H,W),(H,W)(H, W)(H,W),(H,W,3)(H, W, 3)(H,W,3)is also suitable as long as\ncorrespondingdataformatsargument is passed, e.g.CHW,HWC,HW.\ntorchvision.utils.make_grid()\nadd_images\ndataformats\nCHW\nHWC\nHW\nExamples:\n\n```python\nfrom torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nimg = np.zeros((3, 100, 100))\nimg[0] = np.arange(0, 10000).reshape(100, 100) / 10000\nimg[1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n\nimg_HWC = np.zeros((100, 100, 3))\nimg_HWC[:, :, 0] = np.arange(0, 10000).reshape(100, 100) / 10000\nimg_HWC[:, :, 1] = 1 - np.arange(0, 10000).reshape(100, 100) / 10000\n\nwriter = SummaryWriter()\nwriter.add_image('my_image', img, 0)\n\n# If you have non-default dimension setting, set the dataformats argument.\nwriter.add_image('my_image_HWC', img_HWC, 0, dataformats='HWC')\nwriter.close()\n\n```\n\nExpected result:\nAdd batched image data to summary.\nNote that this requires thepillowpackage.\npillow\ntag(str) \u2013 Data identifier\nimg_tensor(torch.Tensor,numpy.ndarray, orstring/blobname) \u2013 Image data\nglobal_step(int) \u2013 Global step value to record\nwalltime(float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\ndataformats(str) \u2013 Image data format specification of the form\nNCHW, NHWC, CHW, HWC, HW, WH, etc.\nimg_tensor: Default is(N,3,H,W)(N, 3, H, W)(N,3,H,W). Ifdataformatsis specified, other shape will be\naccepted. e.g. NCHW or NHWC.\ndataformats\nExamples:\n\n```python\nfrom torch.utils.tensorboard import SummaryWriter\nimport numpy as np\n\nimg_batch = np.zeros((16, 3, 100, 100))\nfor i in range(16):\n    img_batch[i, 0] = np.arange(0, 10000).reshape(100, 100) / 10000 / 16 * i\n    img_batch[i, 1] = (1 - np.arange(0, 10000).reshape(100, 100) / 10000) / 16 * i\n\nwriter = SummaryWriter()\nwriter.add_images('my_image_batch', img_batch, 0)\nwriter.close()\n\n```\n\nExpected result:\nRender matplotlib figure into an image and add it to summary.\nNote that this requires thematplotlibpackage.\nmatplotlib\ntag(str) \u2013 Data identifier\nfigure(Union[Figure,list['Figure']]) \u2013 Figure or a list of figures\nglobal_step(Optional[int]) \u2013 Global step value to record\nclose(bool) \u2013 Flag to automatically close the figure\nwalltime(Optional[float]) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\nAdd video data to summary.\nNote that this requires themoviepypackage.\nmoviepy\ntag(str) \u2013 Data identifier\nvid_tensor(torch.Tensor) \u2013 Video data\nglobal_step(int) \u2013 Global step value to record\nfps(floatorint) \u2013 Frames per second\nwalltime(float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\nvid_tensor:(N,T,C,H,W)(N, T, C, H, W)(N,T,C,H,W). The values should lie in [0, 255] for typeuint8or [0, 1] for typefloat.\nAdd audio data to summary.\ntag(str) \u2013 Data identifier\nsnd_tensor(torch.Tensor) \u2013 Sound data\nglobal_step(int) \u2013 Global step value to record\nsample_rate(int) \u2013 sample rate in Hz\nwalltime(float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\nsnd_tensor:(1,L)(1, L)(1,L). The values should lie between [-1, 1].\nAdd text data to summary.\ntag(str) \u2013 Data identifier\ntext_string(str) \u2013 String to save\nglobal_step(int) \u2013 Global step value to record\nwalltime(float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\nExamples:\n\n```python\nwriter.add_text('lstm', 'This is an lstm', 0)\nwriter.add_text('rnn', 'This is an rnn', 10)\n\n```\n\nAdd graph data to summary.\nmodel(torch.nn.Module) \u2013 Model to draw.\ninput_to_model(torch.Tensororlistoftorch.Tensor) \u2013 A variable or a tuple of\nvariables to be fed.\nverbose(bool) \u2013 Whether to print graph structure in console.\nuse_strict_trace(bool) \u2013 Whether to pass keyword argumentstricttotorch.jit.trace. Pass False when you want the tracer to\nrecord your mutable container types (list, dict)\nAdd embedding projector data to summary.\nmat(torch.Tensorornumpy.ndarray) \u2013 A matrix which each row is the feature vector of the data point\nmetadata(list) \u2013 A list of labels, each element will be converted to string\nlabel_img(torch.Tensor) \u2013 Images correspond to each data point\nglobal_step(int) \u2013 Global step value to record\ntag(str) \u2013 Name for the embedding\nmetadata_header(list) \u2013 A list of headers for multi-column metadata. If given, each metadata must be\na list with values corresponding to headers.\nmat:(N,D)(N, D)(N,D), where N is number of data and D is feature dimension\nlabel_img:(N,C,H,W)(N, C, H, W)(N,C,H,W)\nExamples:\n\n```python\nimport keyword\nimport torch\nmeta = []\nwhile len(meta)<100:\n    meta = meta+keyword.kwlist # get some strings\nmeta = meta[:100]\n\nfor i, v in enumerate(meta):\n    meta[i] = v+str(i)\n\nlabel_img = torch.rand(100, 3, 10, 32)\nfor i in range(100):\n    label_img[i]*=i/100.0\n\nwriter.add_embedding(torch.randn(100, 5), metadata=meta, label_img=label_img)\nwriter.add_embedding(torch.randn(100, 5), label_img=label_img)\nwriter.add_embedding(torch.randn(100, 5), metadata=meta)\n\n```\n\nNote\nCategorical (i.e. non-numeric) metadata cannot have more than 50 unique values if they are to be used for\ncoloring in the embedding projector.\nAdd precision recall curve.\nPlotting a precision-recall curve lets you understand your model\u2019s\nperformance under different threshold settings. With this function,\nyou provide the ground truth labeling (T/F) and prediction confidence\n(usually the output of your model) for each target. The TensorBoard UI\nwill let you choose the threshold interactively.\ntag(str) \u2013 Data identifier\nlabels(torch.Tensor,numpy.ndarray, orstring/blobname) \u2013 Ground truth data. Binary label for each element.\npredictions(torch.Tensor,numpy.ndarray, orstring/blobname) \u2013 The probability that an element be classified as true.\nValue should be in [0, 1]\nglobal_step(int) \u2013 Global step value to record\nnum_thresholds(int) \u2013 Number of thresholds used to draw the curve.\nwalltime(float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\nExamples:\n\n```python\nfrom torch.utils.tensorboard import SummaryWriter\nimport numpy as np\nlabels = np.random.randint(2, size=100)  # binary label\npredictions = np.random.rand(100)\nwriter = SummaryWriter()\nwriter.add_pr_curve('pr_curve', labels, predictions, 0)\nwriter.close()\n\n```\n\nCreate special chart by collecting charts tags in \u2018scalars\u2019.\nNOTE: This function can only be called once for each SummaryWriter() object.\nBecause it only provides metadata to tensorboard, the function can be called before or after the training loop.\nlayout(dict) \u2013 {categoryName:charts}, wherechartsis also a dictionary\n{chartName:ListOfProperties}. The first element inListOfPropertiesis the chart\u2019s type\n(one ofMultilineorMargin) and the second element should be a list containing the tags\nyou have used in add_scalar function, which will be collected into the new chart.\nExamples:\n\n```python\nlayout = {'Taiwan':{'twse':['Multiline',['twse/0050', 'twse/2330']]},\n             'USA':{ 'dow':['Margin',   ['dow/aaa', 'dow/bbb', 'dow/ccc']],\n                  'nasdaq':['Margin',   ['nasdaq/aaa', 'nasdaq/bbb', 'nasdaq/ccc']]}}\n\nwriter.add_custom_scalars(layout)\n\n```\n\nAdd meshes or 3D point clouds to TensorBoard.\nThe visualization is based on Three.js,\nso it allows users to interact with the rendered object. Besides the basic definitions\nsuch as vertices, faces, users can further provide camera parameter, lighting condition, etc.\nPlease checkhttps://threejs.org/docs/index.html#manual/en/introduction/Creating-a-scenefor\nadvanced usage.\ntag(str) \u2013 Data identifier\nvertices(torch.Tensor) \u2013 List of the 3D coordinates of vertices.\ncolors(torch.Tensor) \u2013 Colors for each vertex\nfaces(torch.Tensor) \u2013 Indices of vertices within each triangle. (Optional)\nconfig_dict\u2013 Dictionary with ThreeJS classes names and configuration.\nglobal_step(int) \u2013 Global step value to record\nwalltime(float) \u2013 Optional override default walltime (time.time())\nseconds after epoch of event\nvertices:(B,N,3)(B, N, 3)(B,N,3). (batch, number_of_vertices, channels)\ncolors:(B,N,3)(B, N, 3)(B,N,3). The values should lie in [0, 255] for typeuint8or [0, 1] for typefloat.\nfaces:(B,N,3)(B, N, 3)(B,N,3). The values should lie in [0, number_of_vertices] for typeuint8.\nExamples:\n\n```python\nfrom torch.utils.tensorboard import SummaryWriter\nvertices_tensor = torch.as_tensor([\n    [1, 1, 1],\n    [-1, -1, 1],\n    [1, -1, -1],\n    [-1, 1, -1],\n], dtype=torch.float).unsqueeze(0)\ncolors_tensor = torch.as_tensor([\n    [255, 0, 0],\n    [0, 255, 0],\n    [0, 0, 255],\n    [255, 0, 255],\n], dtype=torch.int).unsqueeze(0)\nfaces_tensor = torch.as_tensor([\n    [0, 2, 3],\n    [0, 3, 1],\n    [0, 1, 2],\n    [1, 3, 2],\n], dtype=torch.int).unsqueeze(0)\n\nwriter = SummaryWriter()\nwriter.add_mesh('my_mesh', vertices=vertices_tensor, colors=colors_tensor, faces=faces_tensor)\n\nwriter.close()\n\n```\n\nAdd a set of hyperparameters to be compared in TensorBoard.\nhparam_dict(dict) \u2013 Each key-value pair in the dictionary is the\nname of the hyper parameter and it\u2019s corresponding value.\nThe type of the value can be one ofbool,string,float,int, orNone.\nmetric_dict(dict) \u2013 Each key-value pair in the dictionary is the\nname of the metric and it\u2019s corresponding value. Note that the key used\nhere should be unique in the tensorboard record. Otherwise the value\nyou added byadd_scalarwill be displayed in hparam plugin. In most\ncases, this is unwanted.\nadd_scalar\nhparam_domain_discrete\u2013 (Optional[Dict[str, List[Any]]]) A dictionary that\ncontains names of the hyperparameters and all discrete values they can hold\nrun_name(str) \u2013 Name of the run, to be included as part of the logdir.\nIf unspecified, will use current timestamp.\nglobal_step(int) \u2013 Global step value to record\nExamples:\n\n```python\nfrom torch.utils.tensorboard import SummaryWriter\nwith SummaryWriter() as w:\n    for i in range(5):\n        w.add_hparams({'lr': 0.1*i, 'bsize': i},\n                      {'hparam/accuracy': 10*i, 'hparam/loss': 10*i})\n\n```\n\nExpected result:\nFlushes the event file to disk.\nCall this method to make sure that all pending events have been written to\ndisk.",
  "url": "https://pytorch.org/docs/stable/tensorboard.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}