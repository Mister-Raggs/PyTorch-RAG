{
  "doc_id": "3e1494c70fc943814d3120282c24c5de",
  "source": "pytorch_docs",
  "title": "Features for large-scale deployments \u2014 PyTorch 2.9 documentation",
  "text": "\n## Features for large-scale deployments#\n\nCreated On: Jul 24, 2019 | Last Updated On: Jul 15, 2025\nFleet-wide operator profiling\nAPI usage logging\nCommon extension points\nThis note talks about several extension points and tricks that might be useful\nwhen running PyTorch within a larger system or operating multiple systems using\nPyTorch in a larger organization.\nThe note assumes that you either build PyTorch from source in your\norganization or have an ability to statically link additional code to be loaded\nwhen PyTorch is used. Therefore, many of the hooks are exposed as C++ APIs that\ncan be triggered once in a centralized place, e.g. in static initialization\ncode.\n\n## Fleet-wide operator profiling#\n\nPyTorch comes withtorch.autograd.profilercapable of measuring time\ntaken by individual operators on demand. One can use the same mechanism to do\n\u201calways ON\u201d measurements for any process running PyTorch. It might be useful for\ngathering information about PyTorch workloads running in a given process or\nacross the entire set of machines.\ntorch.autograd.profiler\nNew callbacks for any operator invocation can be added withtorch::addGlobalCallback. Hooks will be called withtorch::RecordFunctionstruct that describes invocation\ncontext (e.g.name). If enabled,RecordFunction::inputs()contains arguments\nof the function represented astorch::IValuevariant type. Note, that inputs\nlogging is relatively expensive and thus has to be enabled explicitly.\ntorch::addGlobalCallback\ntorch::RecordFunction\nRecordFunction::inputs()\ntorch::IValue\nThe operator callbacks also have access toc10::ThreadLocalDebugInfo::get()interface that returns a pointer to the struct holding the debug information.\nThis debug information can be set earlier by usingat::DebugInfoGuardobject.\nDebug information is propagated through the forward (including asyncforktasks) and backward passes and can be useful for passing some extra information\nabout execution environment (e.g. model id) from the higher layers of the\napplication down to the operator callbacks.\nc10::ThreadLocalDebugInfo::get()\nat::DebugInfoGuard\nfork\nInvoking callbacks adds some overhead, so usually it\u2019s useful to just randomly\nsample operator invocations. This can be enabled on per-callback basis with an\noptional sampling rate passed intotorch::addGlobalCallback.\ntorch::addGlobalCallback\nNote, thataddGlobalCallbackis not thread-safe and can be called only when no\nPyTorch operator is running. Usually, it\u2019s a good idea to call them once during\ninitialization.\naddGlobalCallback\nHere\u2019s an example:\n\n```python\n// Called somewhere in the program beginning\nvoid init() {\n    // Sample one in a hundred operator runs randomly\n    addGlobalCallback(\n      RecordFunctionCallback(\n        &onFunctionEnter,\n        &onFunctionExit)\n      .needsInputs(true)\n      .samplingProb(0.01)\n    );\n    // Note, to enable observers in the model calling thread,\n    // call enableRecordFunction() in the thread before running a model\n}\n\nvoid onFunctionEnter(const RecordFunction& fn) {\n    std::cerr << \"Before function \" << fn.name()\n              << \" with \" << fn.inputs().size() << \" inputs\" << std::endl;\n}\n\nvoid onFunctionExit(const RecordFunction& fn) {\n    std::cerr << \"After function \" << fn.name();\n}\n\n```\n\n\n## API usage logging#\n\nWhen running in a broader ecosystem, for example in managed job scheduler, it\u2019s\noften useful to track which binaries invoke particular PyTorch APIs. There\nexists simple instrumentation injected at several important API points that\ntriggers a given callback. Because usually PyTorch is invoked in one-off python\nscripts, the callback fires only once for a given process for each of the APIs.\nc10::SetAPIUsageHandlercan be used to register API usage instrumentation\nhandler. Passed argument is going to be an \u201capi key\u201d identifying used point, for\nexamplepython.importfor PyTorch extension import.\nc10::SetAPIUsageHandler\npython.import\n\n```python\nSetAPIUsageLogger([](const std::string& event_name) {\n    std::cerr << \"API was used: \" << event_name << std::endl;\n});\n\n```\n\nNote for developers: new API trigger points can be added in code withC10_LOG_API_USAGE_ONCE(\"my_api\")in C++ ortorch._C._log_api_usage_once(\"my.api\")in Python.\nC10_LOG_API_USAGE_ONCE(\"my_api\")\ntorch._C._log_api_usage_once(\"my.api\")\n\n## Common extension points#\n\nPyTorch APIs are generally loosely coupled and it\u2019s easy to replace a component\nwith specialized version. Common extension points include:\nCustom operators implemented in C++ - seetutorial for more details.\nCustom data reading can be often integrated directly by invoking corresponding python library. Existing functionality oftorch.utils.datacan be utilized by extendingDatasetorIterableDataset.\ntorch.utils.data\nDataset\nIterableDataset",
  "url": "https://pytorch.org/docs/stable/notes/large_scale_deployments.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}