{
  "doc_id": "55cff3adab1655d464e4768878299e24",
  "source": "pytorch_docs",
  "title": "CUDA Stream Sanitizer \u2014 PyTorch 2.9 documentation",
  "text": "\n## CUDA Stream Sanitizer#\n\nCreated On: Sep 09, 2022 | Last Updated On: Oct 31, 2022\nNote\nThis is a prototype feature, which means it is at an early stage\nfor feedback and testing, and its components are subject to change.\n\n## Overview#\n\nThis module introduces CUDA Sanitizer, a tool for detecting synchronization errors between kernels ran on different streams.\nIt stores information on accesses to tensors to determine if they are synchronized\nor not. When enabled in a python program and a possible data race is detected, a\ndetailed warning will be printed and the program will exit.\nIt can be enabled either by importing this module and callingenable_cuda_sanitizer()or by exporting theTORCH_CUDA_SANITIZERenvironment variable.\nenable_cuda_sanitizer()\nTORCH_CUDA_SANITIZER\n\n## Usage#\n\nHere is an example of a simple synchronization error in PyTorch:\n\n```python\nimport torch\n\na = torch.rand(4, 2, device=\"cuda\")\n\nwith torch.cuda.stream(torch.cuda.Stream()):\n    torch.mul(a, 5, out=a)\n\n```\n\nTheatensor is initialized on the default stream and, without any synchronization\nmethods, modified on a new stream. The two kernels will run concurrently on the same tensor,\nwhich might cause the second kernel to read uninitialized data before the first one was able\nto write it, or the first kernel might overwrite part of the result of the second.\nWhen this script is run on the commandline with:\na\n\n```python\nTORCH_CUDA_SANITIZER=1 python example_error.py\n\n```\n\nthe following output is printed by CSAN:\n\n```python\n============================\nCSAN detected a possible data race on tensor with data pointer 139719969079296\nAccess by stream 94646435460352 during kernel:\naten::mul.out(Tensor self, Tensor other, *, Tensor(a!) out) -> Tensor(a!)\nwriting to argument(s) self, out, and to the output\nWith stack trace:\n  File \"example_error.py\", line 6, in <module>\n    torch.mul(a, 5, out=a)\n  ...\n  File \"pytorch/torch/cuda/_sanitizer.py\", line 364, in _handle_kernel_launch\n    stack_trace = traceback.StackSummary.extract(\n\nPrevious access by stream 0 during kernel:\naten::rand(int[] size, *, int? dtype=None, Device? device=None) -> Tensor\nwriting to the output\nWith stack trace:\n  File \"example_error.py\", line 3, in <module>\n    a = torch.rand(10000, device=\"cuda\")\n  ...\n  File \"pytorch/torch/cuda/_sanitizer.py\", line 364, in _handle_kernel_launch\n    stack_trace = traceback.StackSummary.extract(\n\nTensor was allocated with stack trace:\n  File \"example_error.py\", line 3, in <module>\n    a = torch.rand(10000, device=\"cuda\")\n  ...\n  File \"pytorch/torch/cuda/_sanitizer.py\", line 420, in _handle_memory_allocation\n    traceback.StackSummary.extract(\n\n```\n\nThis gives extensive insight into the origin of the error:\nA tensor was incorrectly accessed from streams with ids: 0 (default stream) and 94646435460352 (new stream)\nThe tensor was allocated by invokinga=torch.rand(10000,device=\"cuda\")\na=torch.rand(10000,device=\"cuda\")\na=torch.rand(10000,device=\"cuda\")on stream 0\na=torch.rand(10000,device=\"cuda\")\ntorch.mul(a,5,out=a)on stream 94646435460352\ntorch.mul(a,5,out=a)\nThe error message also displays the schemas of the invoked operators, along with a note\nshowing which arguments of the operators correspond to the affected tensor.\nIn the example, it can be seen that tensoracorresponds to argumentsself,outand theoutputvalue of the invoked operatortorch.mul.\na\nself\nout\noutput\ntorch.mul\nSee also\nThe list of supported torch operators and their schemas can be viewedhere.\nThe bug can be fixed by forcing the new stream to wait for the default stream:\n\n```python\nwith torch.cuda.stream(torch.cuda.Stream()):\n    torch.cuda.current_stream().wait_stream(torch.cuda.default_stream())\n    torch.mul(a, 5, out=a)\n\n```\n\nWhen the script is run again, there are no errors reported.\n\n## API Reference#\n\nEnable CUDA Sanitizer.\nThe sanitizer will begin to analyze low-level CUDA calls invoked by torch functions\nfor synchronization errors. All data races found will be printed to the standard\nerror output along with stack traces of suspected causes. For best results, the\nsanitizer should be enabled at the very beginning of the program.",
  "url": "https://pytorch.org/docs/stable/cuda._sanitizer.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}