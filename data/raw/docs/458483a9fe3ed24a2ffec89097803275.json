{
  "doc_id": "458483a9fe3ed24a2ffec89097803275",
  "source": "pytorch_docs",
  "title": "Customization \u2014 PyTorch 2.9 documentation",
  "text": "\n## Customization#\n\nCreated On: May 04, 2021 | Last Updated On: May 04, 2021\nThis section describes how to customize TorchElastic to fit your needs.\n\n## Launcher#\n\nThe launcher program that ships with TorchElastic\nshould be sufficient for most use-cases (seetorchrun (Elastic Launch)).\nYou can implement a custom launcher by\nprogrammatically creating an agent and passing it specs for your workers as\nshown below.\n\n```python\n# my_launcher.py\n\nif __name__ == \"__main__\":\n  args = parse_args(sys.argv[1:])\n  rdzv_handler = RendezvousHandler(...)\n  spec = WorkerSpec(\n      local_world_size=args.nproc_per_node,\n      fn=trainer_entrypoint_fn,\n      args=(trainer_entrypoint_fn args.fn_args,...),\n      rdzv_handler=rdzv_handler,\n      max_restarts=args.max_restarts,\n      monitor_interval=args.monitor_interval,\n  )\n\n  agent = LocalElasticAgent(spec, start_method=\"spawn\")\n  try:\n      run_result = agent.run()\n      if run_result.is_failed():\n          print(f\"worker 0 failed with: run_result.failures[0]\")\n      else:\n          print(f\"worker 0 return value is: run_result.return_values[0]\")\n  except Exception ex:\n      # handle exception\n\n```\n\n\n## Rendezvous Handler#\n\nTo implement your own rendezvous, extendtorch.distributed.elastic.rendezvous.RendezvousHandlerand implement its methods.\ntorch.distributed.elastic.rendezvous.RendezvousHandler\nWarning\nRendezvous handlers are tricky to implement. Before you begin\nmake sure you completely understand the properties of rendezvous.\nPlease refer toRendezvousfor more information.\nOnce implemented you can pass your custom rendezvous handler to the worker\nspec when creating the agent.\n\n```python\nspec = WorkerSpec(\n    rdzv_handler=MyRendezvousHandler(params),\n    ...\n)\nelastic_agent = LocalElasticAgent(spec, start_method=start_method)\nelastic_agent.run(spec.role)\n\n```\n\n\n## Metric Handler#\n\nTorchElastic emits platform level metrics (seeMetrics).\nBy default metrics are emitted to/dev/nullso you will not see them.\nTo have the metrics pushed to a metric handling service in your infrastructure,\nimplement atorch.distributed.elastic.metrics.MetricHandlerandconfigureit in your\ncustom launcher.\n\n```python\n# my_launcher.py\n\nimport torch.distributed.elastic.metrics as metrics\n\nclass MyMetricHandler(metrics.MetricHandler):\n    def emit(self, metric_data: metrics.MetricData):\n        # push metric_data to your metric sink\n\ndef main():\n  metrics.configure(MyMetricHandler())\n\n  spec = WorkerSpec(...)\n  agent = LocalElasticAgent(spec)\n  agent.run()\n\n```\n\n\n## Events Handler#\n\nTorchElastic supports events recording (seeEvents).\nThe events module defines API that allows you to record events and\nimplement custom EventHandler. EventHandler is used for publishing events\nproduced during torchelastic execution to different sources, e.g.  AWS CloudWatch.\nBy default it usestorch.distributed.elastic.events.NullEventHandlerthat ignores\nevents. To configure custom events handler you need to implementtorch.distributed.elastic.events.EventHandlerinterface andconfigureit\nin your custom launcher.\n\n```python\n# my_launcher.py\n\nimport torch.distributed.elastic.events as events\n\nclass MyEventHandler(events.EventHandler):\n    def record(self, event: events.Event):\n        # process event\n\ndef main():\n  events.configure(MyEventHandler())\n\n  spec = WorkerSpec(...)\n  agent = LocalElasticAgent(spec)\n  agent.run()\n\n```\n",
  "url": "https://pytorch.org/docs/stable/elastic/customization.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}