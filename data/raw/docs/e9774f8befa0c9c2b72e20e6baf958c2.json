{
  "doc_id": "e9774f8befa0c9c2b72e20e6baf958c2",
  "source": "pytorch_docs",
  "title": "DDP Communication Hooks \u2014 PyTorch 2.9 documentation",
  "text": "\n## DDP Communication Hooks#\n\nCreated On: Jun 06, 2025 | Last Updated On: Jun 06, 2025\nDDP communication hook is a generic interface to control how to communicate\ngradients across workers by overriding the vanilla allreduce inDistributedDataParallel.\nA few built-in communication hooks are provided,\nand users can easily apply any of these hooks to optimize communication.\nBesides, the hook interface can also support user-defined communication\nstrategies for more advanced use cases.\n\n## How to Use a Communication Hook?#\n\nTo use a communication hook, the user just needs to let the DDP model register\nthe hook before the training loop as below.\ntorch.nn.parallel.DistributedDataParallel.register_comm_hook()\ntorch.nn.parallel.DistributedDataParallel.register_comm_hook()\n\n## What Does a Communication Hook Operate On?#\n\nA communication hook provides a flexible way to allreduce gradients.\nTherefore, it mainly operates on the gradients on each replica before allreduce,\nwhich are bucketized to increase the overlap between communication and computation.\nParticularly,torch.distributed.GradBucketrepresents a bucket of gradient tensors to be allreduced.\ntorch.distributed.GradBucket\nThis class mainly passes a flattened gradient tensor\n(returned bybuffer())\nto DDP communication hook.\nThis tensor can be further decomposed into a list of per-parameter tensors within this bucket\n(returned byget_per_parameter_tensors())\nto apply layer-wise operations.\nbuffer()\nget_per_parameter_tensors()\nWarning\nSince the buckets are rebuilt after the first iteration, should not rely on the indices at the beginning of training.\nThe index of a bucket that stores gradients of a few contiguous layers.\nAll the gradients are bucketized.\nA flattened 1Dtorch.Tensorbuffer,\nwhich can be further decomposed into a list of per-parameter tensors within this bucket.\ntorch.Tensor\nA list oftorch.Tensor. Each tensor in the list corresponds to a gradient.\ntorch.Tensor\nWhether this bucket is the last bucket to allreduce in an iteration.\nThis also means that this bucket corresponds to the first few layers in the forward pass.\nReplaces the tensor in the bucket with the input tensor buffer.\nA list oftorch.Tensor. Each tensor in the list corresponds to a model\nparameter.\ntorch.Tensor\n\n## Default Communication Hooks#\n\nDefault communication hooks are simplestatelesshooks, so the input state\ninregister_comm_hookis either a process group orNone.\nThe inputbucketis atorch.distributed.GradBucketobject.\nregister_comm_hook\nNone\nbucket\ntorch.distributed.GradBucket\nCallallreduceusingGradBuckettensors.\nallreduce\nGradBucket\nOnce gradient tensors are aggregated across all workers, itsthencallback takes the mean and returns the result.\nthen\nIf user registers this DDP communication hook,\nDDP results is expected to be same as the case where no hook was registered.\nHence, this won\u2019t change behavior of DDP and user can use this as a reference\nor modify this hook to log useful information or any other purposes while\nunaffecting DDP behavior.\n\n```python\n>>> ddp_model.register_comm_hook(process_group, allreduce_hook)\n\n```\n\nFuture[Tensor]\nCompress by castingGradBuckettotorch.float16divided by process group size.\nGradBucket\ntorch.float16\nThis DDP communication hook implements a simple gradient compression\napproach that castsGradBuckettensor to half-precision floating-point format (torch.float16)\nand then divides it by the process group size.\nIt allreduces thosefloat16gradient tensors. Once compressed gradient\ntensors are allreduced, the chained callbackdecompresscasts it back to the input data type (such asfloat32).\nGradBucket\ntorch.float16\nfloat16\ndecompress\nfloat32\n\n```python\n>>> ddp_model.register_comm_hook(process_group, fp16_compress_hook)\n\n```\n\nFuture[Tensor]\nWarning: This API is experimental, and it requires NCCL version later than 2.9.6.\nThis DDP communication hook implements a simple gradient compression\napproach that castsGradBuckettensor to half-precisionBrain floating point format(torch.bfloat16)\nand then divides it by the process group size.\nIt allreduces thosebfloat16gradient tensors. Once compressed gradient\ntensors are allreduced, the chained callbackdecompresscasts it back to the input data type (such asfloat32).\nGradBucket\ntorch.bfloat16\nbfloat16\ndecompress\nfloat32\n\n```python\n>>> ddp_model.register_comm_hook(process_group, bf16_compress_hook)\n\n```\n\nFuture[Tensor]\nAdditionally, a communication hook wrapper is provided to supportfp16_compress_hook()orbf16_compress_hook()as a wrapper,\nwhich can be combined with other communication hooks.\nfp16_compress_hook()\nbf16_compress_hook()\nCast input tensor totorch.float16, cast result of hook back to input dtype.\ntorch.float16\nThis wrapper casts the input gradient tensor of a given DDP communication hook to half-precision\nfloating point format (torch.float16), and casts the resulting tensor of the given hook back to\nthe input data type, such asfloat32.\nTherefore,fp16_compress_hookis equivalent tofp16_compress_wrapper(allreduce_hook).\ntorch.float16\nfloat32\nfp16_compress_hook\nfp16_compress_wrapper(allreduce_hook)\n\n```python\n>>> state = PowerSGDState(process_group=process_group, matrix_approximation_rank=1, start_powerSGD_iter=10)\n>>> ddp_model.register_comm_hook(state, fp16_compress_wrapper(powerSGD_hook))\n\n```\n\nCallable[[Any,GradBucket],Future[Tensor]]\nWarning: This API is experimental, and it requires NCCL version later than 2.9.6.\nThis wrapper casts the input gradient tensor of a given DDP communication hook to half-precisionBrain floating point format(torch.bfloat16),\nand casts the resulting tensor of the given hook back to the input data type, such asfloat32.\ntorch.bfloat16\nfloat32\nTherefore,bf16_compress_hookis equivalent tobf16_compress_wrapper(allreduce_hook).\nbf16_compress_hook\nbf16_compress_wrapper(allreduce_hook)\n\n```python\n>>> state = PowerSGDState(process_group=process_group, matrix_approximation_rank=1, start_powerSGD_iter=10)\n>>> ddp_model.register_comm_hook(state, bf16_compress_wrapper(powerSGD_hook))\n\n```\n\nCallable[[Any,GradBucket],Future[Tensor]]\n\n## PowerSGD Communication Hook#\n\nPowerSGD (Vogels et al., NeurIPS 2019)\nis a gradient compression algorithm, which can provide very high compression\nrates and accelerate bandwidth-bound distributed training.\nThis algorithm needs to maintain both some hyperparameters and the internal\nstate. Therefore, PowerSGD communication hook is astatefulhook,\nand the user needs to provide a state object defined as below.\n\n## PowerSGD State#\n\nStore both the algorithm\u2019s hyperparameters and internal state for all gradients during training.\nParticularly,matrix_approximation_rankandstart_powerSGD_iterare the main hyperparameters that should be tuned by the user.\nFor performance, we suggest to keep binary hyperparametersuse_error_feedbackandwarm_starton.\nmatrix_approximation_rank\nstart_powerSGD_iter\nuse_error_feedback\nwarm_start\nmatrix_approximation_rankcontrols the size of compressed low-rank tensors, which determines the compression rate. The lower the rank, the stronger the compression.\nmatrix_approximation_rank\n1.1. Ifmatrix_approximation_rankis too low, the full model quality will need more training steps to reach or will never reach and yield loss in accuracy.\nmatrix_approximation_rank\n1.2. The increase ofmatrix_approximation_rankcan substantially increase the computation costs of the compression, and the accuracy may not be further improved beyond a certainmatrix_approximation_rankthreshold.\nmatrix_approximation_rank\nmatrix_approximation_rank\nTo tunematrix_approximation_rank, we suggest to start from 1 and increase by factors of 2 (like an exponential grid search, 1, 2, 4, \u2026), until a satisfactory accuracy is reached. Typically only a small value 1-4 is used. For some NLP tasks (as shown in Appendix D of the original paper), this value has been increased to 32.\nmatrix_approximation_rank\nstart_powerSGD_iterdefers PowerSGD compression until stepstart_powerSGD_iter, and vanilla allreduce runs prior to stepstart_powerSGD_iter. This hybrid scheme ofvanilla allreduce + PowerSGDcan effectively improve the accuracy, even a relatively smallmatrix_approximation_rankis used. This is because that, the beginning of training phase is usually very sensitive to inaccurate gradients, and compressing gradients too early may make the training quickly take a suboptimal trajectory, which can result in an irrecoverable impact on the accuracy.\nstart_powerSGD_iter\nstart_powerSGD_iter\nstart_powerSGD_iter\nmatrix_approximation_rank\nTo tunestart_powerSGD_iter, we suggest to start with 10% of total training steps, and increase it until a satisfactory accuracy is reached. If there is a warm-up stage in the training,start_powerSGD_itertypically should be no less than the number of warm-up steps.\nstart_powerSGD_iter\nstart_powerSGD_iter\nmin_compression_rateis the minimum compression rate required when a layer is compressed. Due to the computation overheads incurred by the compression, a tensor is worth compressing only if there can be sufficient saving in bandwidth, where(num_rows+num_cols)*matrix_approximation_rank*min_compression_rate<num_rows*num_cols. If the specified compression rate threshold cannot be satisfied, the tensor will be directly allreduced without compression.\nmin_compression_rate\n(num_rows+num_cols)*matrix_approximation_rank*min_compression_rate<num_rows*num_cols\nCompression statistics are logged everycompression_stats_logging_frequencyiterations once PowerSGD compression starts.\ncompression_stats_logging_frequency\northogonalization_epsiloncan be a very small value (e.g., 1e-8) added to every normalized matrix column in orthogonalization step, to prevent div-by-zero error if any column has all 0s. If this can already be prevented (e.g., by batch normalization), an epsilon of 0 is recommended for accuracy.\northogonalization_epsilon\nbatch_tensors_with_same_shapecontrols whether to compress and decompress tensors with same shape in a batched operation to achieve higher parallelism. Note that you should also increase the bucket size (i.e.,bucket_cap_mbarg in DDP constructor) to make more same-shaped tensors appear in the same bucket, however this may reduce the overlap between computation and communication, and increase the memory footprint due to stacking the tensors of the same shape. Set toTrueif the compression / decompression computation is a bottleneck.\nbatch_tensors_with_same_shape\nbucket_cap_mb\nTrue\nWarning\nIf error feedback or warm-up is enabled, the minimum value ofstart_powerSGD_iterallowed in DDP is 2.\nThis is because there is another internal optimization that rebuilds buckets at iteration 1 in DDP,\nand this can conflict with any tensor memorized before the rebuild process.\nstart_powerSGD_iter\n\n## PowerSGD Hooks#\n\nWarning\nPowerSGD typically requires extra memory of the same size as the model\u2019s\ngradients to enable error feedback, which can compensate for biased\ncompressed communication and improve accuracy.\nWarning\nPowerSGD hooks may conflict withApex automatic mixed precision package.\nPlease use PyTorchnative automatic mixed precision packageinstead.\nImplement PowerSGD algorithm.\nThis DDP communication hook implements PowerSGD gradient compression\nalgorithm described in thepaper.\nOnce gradient tensors are aggregated across all workers, this hook applies\ncompression as follows:\nViews the input flattened 1D gradient tensor as a list of per-parameter tensors, and divides all the tensors into two groups:\n1.1 The tensors that should be compressed before allreduce, because the compression can give enough saving in bandwidth.\n1.2 Rest of the tensors will be directly allreduced without compression, including all the vector tensors (for biases).\nHandles uncompressed tensors:\n2.1. Allocate contiguous memory for those uncompressed tensors, and allreduces all the uncompressed tensors as a batch, without compression;\n2.2. Copies the individual uncompressed tensors from the contiguous memory back to the input tensor.\nHandles the tensors that should be compressed by PowerSGD compression:\n3.1. For each tensor M, creates two low-rank tensors P and Q for decomposing M,\nsuch that M = PQ^T, where Q is initialized from a standard normal distribution and orthogonalized;\n3.2. Computes each P in Ps, which is equal to MQ;\n3.3. Allreduces Ps as a batch;\n3.4. Orthogonalizes each P in Ps;\n3.5. Computes each Q in Qs, which is approximately equal to M^TP;\n3.6. Allreduces Qs as a batch;\n3.7. Computes each M among all the compressed tensors, which is approximately equal to PQ^T.\nNote that this communication hook enforces vanilla allreduce for the firststate.start_powerSGD_iteriterations.\nThis not only gives the user more control over the tradeoff between speedup and accuracy,\nbut also helps abstract away some complexity of the internal optimization of DDP for future communication hook developers.\nstate.start_powerSGD_iter\nstate(PowerSGDState) \u2013 State information to configure the compression rate and support error feedback, warm start, etc.\nTo tune the compression configs, mainly need to tunematrix_approximation_rank,start_powerSGD_iterandmin_compression_rate.\nmatrix_approximation_rank\nstart_powerSGD_iter\nmin_compression_rate\nbucket(dist.GradBucket) \u2013 Bucket that stores a 1D flattened gradient tensor that batches multiple per-variable tensors.\nNote that since DDP comm hook only supports single process single device mode,\nonly exactly one tensor is stored in this bucket.\nFuture handler of the communication, which updates the gradients in place.\nFuture[Tensor]\n\n```python\n>>> state = PowerSGDState(process_group=process_group, matrix_approximation_rank=1,\n                          start_powerSGD_iter=10, min_compression_rate=0.5)\n>>> ddp_model.register_comm_hook(state, powerSGD_hook)\n\n```\n\nImplement simplified PowerSGD algorithm.\nThis DDP communication hook implements a simplified PowerSGD gradient compression\nalgorithm described in thepaper.\nThis variant does not compress the gradients layer by layer,\nbut instead compresses the flattened input tensor that batches all the gradients.\nTherefore, it isfasterthanpowerSGD_hook(),\nbut usually results in amuch lower accuracy, unlessmatrix_approximation_rankis 1.\npowerSGD_hook()\nmatrix_approximation_rank\nWarning\nIncreasingmatrix_approximation_rankhere may not necessarily increase the accuracy,\nbecause batching per-parameter tensors without column/row alignment can destroy low-rank structure.\nTherefore, the user should always considerpowerSGD_hook()first,\nand only consider this variant when a satisfactory accuracy can be achieved whenmatrix_approximation_rankis 1.\nmatrix_approximation_rank\npowerSGD_hook()\nmatrix_approximation_rank\nOnce gradient tensors are aggregated across all workers, this hook applies\ncompression as follows:\nViews the input flattened 1D gradient tensor as a square-shaped tensor M with 0 paddings;\nCreates two low-rank tensors P and Q for decomposing M, such that M = PQ^T, where Q is initialized from a standard normal distribution and orthogonalized;\nComputes P, which is equal to MQ;\nAllreduces P;\nOrthogonalizes P;\nComputes Q, which is approximately equal to M^TP;\nAllreduces Q;\nComputes M, which is approximately equal to PQ^T.\nTruncates the input tensor to the original length.\nNote that this communication hook enforces vanilla allreduce for the firststate.start_powerSGD_iteriterations.\nThis not only gives the user more control over the tradeoff between speedup and accuracy,\nbut also helps abstract away some complexity of the internal optimization of DDP for future communication hook developers.\nstate.start_powerSGD_iter\nstate(PowerSGDState) \u2013 State information to configure the compression rate and support error feedback, warm start, etc.\nTo tune the compression configs, mainly need to tunematrix_approximation_rankandstart_powerSGD_iter.\nmatrix_approximation_rank\nstart_powerSGD_iter\nbucket(dist.GradBucket) \u2013 Bucket that stores a 1D flattened gradient tensor that batches multiple per-variable tensors.\nNote that since DDP comm hook only supports single process single device mode,\nonly exactly one tensor is stored in this bucket.\nFuture handler of the communication, which updates the gradients in place.\nFuture[Tensor]\n\n```python\n>>> state = PowerSGDState(process_group=process_group, matrix_approximation_rank=1)\n>>> ddp_model.register_comm_hook(state, batched_powerSGD_hook)\n\n```\n\n\n## Debugging Communication Hooks#\n\nAs the name implies, debugging communication hooks areonlyused for debugging and performance optimization purpose.\nWarning\nDebugging communication hooks do not necessarily output the correct results.\nReturn a future that wraps the input, so it is a no-op that does not incur any communication overheads.\nThis hook shouldonlybe used for headroom analysis of allreduce optimization,\ninstead of the normal gradient synchronization.\nFor example, if only less than 10% speedup of training time can be observed after this hook is registered,\nit usually implies that allreduce is not a performance bottleneck for this case.\nSuch instrumentation can be particularly useful\nif GPU traces cannot be easily retrieved or the trace analysis is complicated\nsome factors such as the overlap between allreduce and computation or the desynchronization across ranks.\n\n```python\n>>> ddp_model.register_comm_hook(None, noop_hook)\n\n```\n\nFuture[Tensor]\n\n## Checkpointing of Communication Hooks#\n\nA stateful communication hook can be saved as a part of model checkpointing to enable trainer restarts.\nTo make a hook serializable,__setstate__and__getstate__should be defined.\n__setstate__\n__getstate__\nWarning\n__getstate__should exclude non-serializable attributes from a returned dictionary.\n__getstate__\nWarning\n__setstate__should properly initialize non-serializable attributes, excluded from a providedstate.\n__setstate__\nstate\nPowerSGDStatehas__setstate__and__getstate__implemented and can be used as a reference.\nPowerSGDState\n__setstate__\n__getstate__\nReturn aDict[str,Any]which will be pickled and saved.\nDict[str,Any]\nprocess_groupis not serializable and excluded from\na returned state.\nprocess_group\nTake a providedstateand set to thisPowerSGDStateinstance.\nstate\nPowerSGDState\nprocess_groupis set to default.\nprocess_group\nHere is a simple, end-to-end example of saving and reloading PowerSGD state and hook.\n\n```python\n\nimport os\nimport sys\nimport tempfile\nimport torch\nimport torch.distributed as dist\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.multiprocessing as mp\n\nfrom torch.nn.parallel import DistributedDataParallel\nfrom torch.distributed.algorithms.ddp_comm_hooks import powerSGD_hook as powerSGD\n\nclass SimpleModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.fc1 = nn.Linear(24,24)\n        self.relu = nn.ReLU()\n        self.fc2 = nn.Linear(24,12)\n\n    def forward(self, x):\n        return self.fc2(self.relu(self.fc1(x)))\n\ndef setup(rank, world_size):\n    os.environ['MASTER_ADDR'] = 'localhost'\n    os.environ['MASTER_PORT'] = '12355'\n\n    # initialize the process group\n    dist.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n\ndef cleanup():\n    dist.destroy_process_group()\n\ndef run_demo(demo_fn, world_size):\n    mp.spawn(\n        demo_fn,\n        args=(world_size,),\n        nprocs=world_size,\n        join=True)\n\ndef demo_serialization(rank, world_size):\n    setup(rank, world_size)\n\n    CHECKPOINT = tempfile.gettempdir() + \"/checkpoint.pt\"\n\n    model = SimpleModel().to(rank)\n    ddp_model = DistributedDataParallel(model, device_ids=[rank])\n\n    powersgd_hook = powerSGD.powerSGD_hook\n    powersgd_state = powerSGD.PowerSGDState(process_group=None)\n\n    optimizer = optim.SGD(ddp_model.parameters(), lr=0.001)\n    ddp_model.register_comm_hook(powersgd_state, powersgd_hook)\n\n    state = {\n        'state_dict': ddp_model.state_dict(),\n        'comm_hook': powersgd_hook,\n        'comm_hook_state': powersgd_state}\n\n    if rank == 0:\n        torch.save(state, CHECKPOINT)\n\n    dist.barrier()\n    map_location = {'cuda:%d' % 0: 'cuda:%d' % rank}\n    checkpoint = torch.load(CHECKPOINT, map_location=map_location)\n\n    new_ddp_model = DistributedDataParallel(SimpleModel().to(rank), device_ids=[rank])\n    new_ddp_model.load_state_dict(checkpoint['state_dict'])\n    powersgd_hook = checkpoint['comm_hook']\n    powersgd_state = checkpoint['comm_hook_state']\n\n    new_ddp_model.register_comm_hook(powersgd_state, powersgd_hook)\n\n    if rank == 0:\n        os.remove(CHECKPOINT)\n\n    cleanup()\n\nif __name__ == \"__main__\":\n    n_gpus = torch.cuda.device_count()\n    assert n_gpus >= 2, f\"Requires at least 2 GPUs to run, but got {n_gpus}\"\n    world_size = n_gpus\n    run_demo(demo_serialization, world_size)\n\n```\n\n\n## Acknowledgements#\n\nMany thanks to PowerSGD paper authorThijs Vogelsfor the code review on\nPowerSGD communication hook, as well as thecomparison experiments,\nwhich show that the performance of PowerSGD communication hook is on par with\nthe implementation in the originalpaper.",
  "url": "https://pytorch.org/docs/stable/ddp_comm_hooks.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}