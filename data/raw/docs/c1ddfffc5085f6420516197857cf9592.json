{
  "doc_id": "c1ddfffc5085f6420516197857cf9592",
  "source": "pytorch_docs",
  "title": "torch.escape-hatch \u2014 PyTorch 2.9 documentation",
  "text": "\n## torch.escape-hatch#\n\n\n## assume_constant_result#\n\nNote\nTags:torch.escape-hatch\nSupport Level: SUPPORTED\nOriginal source code:\n\n```python\n# mypy: allow-untyped-defs\nimport torch\nimport torch._dynamo as torchdynamo\n\n\nclass AssumeConstantResult(torch.nn.Module):\n    \"\"\"\n    Applying `assume_constant_result` decorator to burn make non-tracable code as constant.\n    \"\"\"\n\n    @torchdynamo.assume_constant_result\n    def get_item(self, y):\n        return y.int().item()\n\n    def forward(self, x, y):\n        return x[: self.get_item(y)]\n\nexample_args = (torch.randn(3, 2), torch.tensor(4))\ntags = {\"torch.escape-hatch\"}\nmodel = AssumeConstantResult()\n\n\ntorch.export.export(model, example_args)\n\n```\n\nResult:\n\n```python\nExportedProgram:\n    class GraphModule(torch.nn.Module):\n        def forward(self, x: \"f32[3, 2]\", y: \"i64[]\"):\n                 slice_1: \"f32[3, 2]\" = torch.ops.aten.slice.Tensor(x, 0, 0, 4);  x = None\n            return (slice_1,)\n\nGraph signature:\n    # inputs\n    x: USER_INPUT\n    y: USER_INPUT\n\n    # outputs\n    slice_1: USER_OUTPUT\n\nRange constraints: {}\n\n```\n\n\n## constrain_as_size_example#\n\nNote\nTags:torch.dynamic-value,torch.escape-hatch\nSupport Level: SUPPORTED\nOriginal source code:\n\n```python\n# mypy: allow-untyped-defs\nimport torch\n\n\nclass ConstrainAsSizeExample(torch.nn.Module):\n    \"\"\"\n    If the value is not known at tracing time, you can provide hint so that we\n    can trace further. Please look at torch._check and torch._check_is_size APIs.\n    torch._check_is_size is used for values that NEED to be used for constructing\n    tensor.\n    \"\"\"\n\n    def forward(self, x):\n        a = x.item()\n        torch._check_is_size(a)\n        torch._check(a <= 5)\n        return torch.zeros((a, 5))\n\n\nexample_args = (torch.tensor(4),)\ntags = {\n    \"torch.dynamic-value\",\n    \"torch.escape-hatch\",\n}\nmodel = ConstrainAsSizeExample()\n\n\ntorch.export.export(model, example_args)\n\n```\n\nResult:\n\n```python\nExportedProgram:\n    class GraphModule(torch.nn.Module):\n        def forward(self, x: \"i64[]\"):\n                 item: \"Sym(u0)\" = torch.ops.aten.item.default(x);  x = None\n\n             #\n            sym_constrain_range_for_size_default = torch.ops.aten.sym_constrain_range_for_size.default(item);  sym_constrain_range_for_size_default = None\n\n                 ge_1: \"Sym(u0 >= 0)\" = item >= 0\n            _assert_scalar_default = torch.ops.aten._assert_scalar.default(ge_1, \"Runtime assertion failed for expression u0 >= 0 on node 'ge_1'\");  ge_1 = _assert_scalar_default = None\n            le_1: \"Sym(u0 <= 5)\" = item <= 5\n            _assert_scalar_default_1 = torch.ops.aten._assert_scalar.default(le_1, \"Runtime assertion failed for expression u0 <= 5 on node 'le_1'\");  le_1 = _assert_scalar_default_1 = None\n\n                 zeros: \"f32[u0, 5]\" = torch.ops.aten.zeros.default([item, 5], device = device(type='cpu'), pin_memory = False);  item = None\n            return (zeros,)\n\nGraph signature:\n    # inputs\n    x: USER_INPUT\n\n    # outputs\n    zeros: USER_OUTPUT\n\nRange constraints: {u0: VR[0, 5], u1: VR[0, 5]}\n\n```\n\n\n## constrain_as_value_example#\n\nNote\nTags:torch.dynamic-value,torch.escape-hatch\nSupport Level: SUPPORTED\nOriginal source code:\n\n```python\n# mypy: allow-untyped-defs\nimport torch\n\n\nclass ConstrainAsValueExample(torch.nn.Module):\n    \"\"\"\n    If the value is not known at tracing time, you can provide hint so that we\n    can trace further. Please look at torch._check and torch._check_is_size APIs.\n    torch._check is used for values that don't need to be used for constructing\n    tensor.\n    \"\"\"\n\n    def forward(self, x, y):\n        a = x.item()\n        torch._check(a >= 0)\n        torch._check(a <= 5)\n\n        if a < 6:\n            return y.sin()\n        return y.cos()\n\n\nexample_args = (torch.tensor(4), torch.randn(5, 5))\ntags = {\n    \"torch.dynamic-value\",\n    \"torch.escape-hatch\",\n}\nmodel = ConstrainAsValueExample()\n\n\ntorch.export.export(model, example_args)\n\n```\n\nResult:\n\n```python\nExportedProgram:\n    class GraphModule(torch.nn.Module):\n        def forward(self, x: \"i64[]\", y: \"f32[5, 5]\"):\n                 item: \"Sym(u0)\" = torch.ops.aten.item.default(x);  x = None\n            ge_1: \"Sym(u0 >= 0)\" = item >= 0\n            _assert_scalar_default = torch.ops.aten._assert_scalar.default(ge_1, \"Runtime assertion failed for expression u0 >= 0 on node 'ge_1'\");  ge_1 = _assert_scalar_default = None\n            le_1: \"Sym(u0 <= 5)\" = item <= 5;  item = None\n            _assert_scalar_default_1 = torch.ops.aten._assert_scalar.default(le_1, \"Runtime assertion failed for expression u0 <= 5 on node 'le_1'\");  le_1 = _assert_scalar_default_1 = None\n\n                 sin: \"f32[5, 5]\" = torch.ops.aten.sin.default(y);  y = None\n            return (sin,)\n\nGraph signature:\n    # inputs\n    x: USER_INPUT\n    y: USER_INPUT\n\n    # outputs\n    sin: USER_OUTPUT\n\nRange constraints: {u0: VR[0, 5], u1: VR[0, 5]}\n\n```\n",
  "url": "https://pytorch.org/docs/stable/generated/exportdb/torch.escape-hatch.html",
  "metadata": {
    "section": null,
    "issue_number": null,
    "labels": null,
    "answer_author": null
  }
}